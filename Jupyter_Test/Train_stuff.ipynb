{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "all_data = pd.read_csv('../../Data/Mixed_HGP/True_Label/scans_used_all_info.csv')\n",
    "all_labels = all_data['HGP_Type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_split.split(all_data, all_labels)\n",
    "\n",
    "for train_index, test_index in stratified_split.split(all_data, all_labels):\n",
    "    strat_train_set = all_data.loc[train_index]\n",
    "    strat_test_set = all_data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.reset_index(drop=True, inplace=True)\n",
    "strat_train_set.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.to_csv('../../Data/Mixed_HGP/True_Label/test_set.csv', index=False)\n",
    "strat_train_set.to_csv('../../Data/Mixed_HGP/True_Label/train_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_0 = 'CILM_'\n",
    "name_1 = '_0000.nii.gz'\n",
    "train_name = strat_train_set.Experiment.tolist()\n",
    "test_name = strat_test_set.Experiment.tolist()\n",
    "train_name = [name_0  + str(i) + '0' + name_1 for i in train_name]\n",
    "test_name = [name_0  + str(i) + '0' + name_1 for i in test_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Scan</th>\n",
       "      <th>pHGP</th>\n",
       "      <th>dHGP</th>\n",
       "      <th>rHGP</th>\n",
       "      <th>HGP_Type</th>\n",
       "      <th>Series_description</th>\n",
       "      <th>acquisition_time</th>\n",
       "      <th>...</th>\n",
       "      <th>kvp</th>\n",
       "      <th>scan_options</th>\n",
       "      <th>seriesdate_y</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>model_name</th>\n",
       "      <th>patient_position</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>slice_thickness</th>\n",
       "      <th>convolution_kernel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7152829</td>\n",
       "      <td>CRLM_248</td>\n",
       "      <td>CT_29172</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>94.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>ABD. 5/5</td>\n",
       "      <td>114902.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>079Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"5.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292285</td>\n",
       "      <td>CRLM_005</td>\n",
       "      <td>CT_18862</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93655.75000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>066Y</td>\n",
       "      <td>Asteion</td>\n",
       "      <td>HFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"3.0\"</td>\n",
       "      <td>FC10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1820851</td>\n",
       "      <td>CRLM_081</td>\n",
       "      <td>CT_29966</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>68.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>Thx-lever 5.0 B30f</td>\n",
       "      <td>113904.38850</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20040419.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Volume Zoom</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B30f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4932909</td>\n",
       "      <td>CRLM_169</td>\n",
       "      <td>CT_16877</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>98.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>th.abd. alg.  5.0  B31f</td>\n",
       "      <td>104110.53570</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20050506.0</td>\n",
       "      <td>M</td>\n",
       "      <td>057Y</td>\n",
       "      <td>Sensation 16</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2489453</td>\n",
       "      <td>CRLM_101</td>\n",
       "      <td>CT_87243</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133834.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>072Y</td>\n",
       "      <td>Mx8000 IDT 16</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"2.0\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7739333</td>\n",
       "      <td>CRLM_264</td>\n",
       "      <td>CT_33728</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Abdomen  5.0  B31s</td>\n",
       "      <td>114908.97490</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20140409.0</td>\n",
       "      <td>M</td>\n",
       "      <td>084Y</td>\n",
       "      <td>Sensation 40</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B31s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8859793</td>\n",
       "      <td>CRLM_300</td>\n",
       "      <td>CT_21114</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3F Lever port.  5.0  B31f</td>\n",
       "      <td>84356.95843</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20040604.0</td>\n",
       "      <td>M</td>\n",
       "      <td>067Y</td>\n",
       "      <td>Sensation 16</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6643893</td>\n",
       "      <td>CRLM_223</td>\n",
       "      <td>CT_33488</td>\n",
       "      <td>3</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Abdomen 6.0 B40s</td>\n",
       "      <td>92112.62500</td>\n",
       "      <td>...</td>\n",
       "      <td>\"110\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20111129.0</td>\n",
       "      <td>M</td>\n",
       "      <td>081Y</td>\n",
       "      <td>Emotion Duo</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"6\"</td>\n",
       "      <td>B40s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6431015</td>\n",
       "      <td>CRLM_214</td>\n",
       "      <td>CT_26150</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>ABD. 5MM</td>\n",
       "      <td>180527.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>066Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"5.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>121369</td>\n",
       "      <td>CRLM_001</td>\n",
       "      <td>CT_33891</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101443.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>20100730.0</td>\n",
       "      <td>M</td>\n",
       "      <td>077Y</td>\n",
       "      <td>Aquilion</td>\n",
       "      <td>FFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"3.0\"</td>\n",
       "      <td>FC02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6019571</td>\n",
       "      <td>CRLM_203</td>\n",
       "      <td>CT_14359</td>\n",
       "      <td>10</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135724.40000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>074Y</td>\n",
       "      <td>Aquilion</td>\n",
       "      <td>HFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"3.0\"</td>\n",
       "      <td>FC10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5879354</td>\n",
       "      <td>CRLM_197</td>\n",
       "      <td>CT_76657</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.041667</td>\n",
       "      <td>58.958333</td>\n",
       "      <td>0</td>\n",
       "      <td>C+rectaal Body 5.0 CE +C 60s C+rectaal  Axial</td>\n",
       "      <td>181913.25000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>20150501.0</td>\n",
       "      <td>F</td>\n",
       "      <td>061Y</td>\n",
       "      <td>Aquilion ONE</td>\n",
       "      <td>FFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"5.0\"</td>\n",
       "      <td>FC09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8065953</td>\n",
       "      <td>CRLM_277</td>\n",
       "      <td>CT_94912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Thx-lever 5.0 B30f</td>\n",
       "      <td>115353.33800</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20040108.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Volume Zoom</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B30f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1637698</td>\n",
       "      <td>CRLM_071</td>\n",
       "      <td>CT_17713</td>\n",
       "      <td>4</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111412.15000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"135\"</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>079Y</td>\n",
       "      <td>Asteion</td>\n",
       "      <td>HFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"5.0\"</td>\n",
       "      <td>FC10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>521867</td>\n",
       "      <td>CRLM_017</td>\n",
       "      <td>CT_27354</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>ABD. 5MM</td>\n",
       "      <td>110231.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>052Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"5.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8205683</td>\n",
       "      <td>CRLM_283</td>\n",
       "      <td>CT_12575</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>Thx Med/Abd 5/5</td>\n",
       "      <td>102012.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>065Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"5.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1094923</td>\n",
       "      <td>CRLM_047</td>\n",
       "      <td>CT_32703</td>\n",
       "      <td>22</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>96.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Dyn 4D Lever  1.5  Br36 16</td>\n",
       "      <td>120926.90800</td>\n",
       "      <td>...</td>\n",
       "      <td>\"80\"</td>\n",
       "      <td>['XOP', 'A4DS', '0001', 'CONT', 'RSER000001', ...</td>\n",
       "      <td>20180215.0</td>\n",
       "      <td>M</td>\n",
       "      <td>068Y</td>\n",
       "      <td>SOMATOM Force</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"1.5\"</td>\n",
       "      <td>Br36f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>788823</td>\n",
       "      <td>CRLM_031</td>\n",
       "      <td>CT_25273</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>C+ Body 5.0 CE C+ 60s C+  Axial</td>\n",
       "      <td>141336.75000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>20141203.0</td>\n",
       "      <td>M</td>\n",
       "      <td>084Y</td>\n",
       "      <td>Aquilion ONE</td>\n",
       "      <td>FFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"5.0\"</td>\n",
       "      <td>FC09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2259297</td>\n",
       "      <td>CRLM_099</td>\n",
       "      <td>CT_29977</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>ONCO Th/Abd.  3.0  B31f</td>\n",
       "      <td>140937.45300</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20140610.0</td>\n",
       "      <td>M</td>\n",
       "      <td>069Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6746373</td>\n",
       "      <td>CRLM_230</td>\n",
       "      <td>CT_31053</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Th.abd.alg  5.0  B31f</td>\n",
       "      <td>85631.47327</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20070524.0</td>\n",
       "      <td>M</td>\n",
       "      <td>060Y</td>\n",
       "      <td>Sensation 16</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6370665</td>\n",
       "      <td>CRLM_211</td>\n",
       "      <td>CT_63505</td>\n",
       "      <td>6</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110435.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>057Y</td>\n",
       "      <td>Mx8000 IDT 16</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"2.0\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9801055</td>\n",
       "      <td>CRLM_334</td>\n",
       "      <td>CT_89320</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Abd  ThorAbd  2.0  I41f  3</td>\n",
       "      <td>113700.46300</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20150202.0</td>\n",
       "      <td>M</td>\n",
       "      <td>060Y</td>\n",
       "      <td>SOMATOM Definition Flash</td>\n",
       "      <td>FFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>['I41f', '3']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4335562</td>\n",
       "      <td>CRLM_148</td>\n",
       "      <td>CT_26026</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Abd 5.0 mm</td>\n",
       "      <td>83455.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>067Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"5.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7845187</td>\n",
       "      <td>CRLM_265</td>\n",
       "      <td>CT_19439</td>\n",
       "      <td>6</td>\n",
       "      <td>21.944444</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>40.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>ONCO ThAbd  1.5  B70f</td>\n",
       "      <td>152048.30750</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20151001.0</td>\n",
       "      <td>M</td>\n",
       "      <td>074Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"1.5\"</td>\n",
       "      <td>B70f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6874007</td>\n",
       "      <td>CRLM_240</td>\n",
       "      <td>CT_32665</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>Abd 5.0 mm</td>\n",
       "      <td>141349.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"100\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>054Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"5.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2995387</td>\n",
       "      <td>CRLM_106</td>\n",
       "      <td>CT_26568</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>ABD AX 4MM</td>\n",
       "      <td>155645.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>054Y</td>\n",
       "      <td>Brilliance 40</td>\n",
       "      <td>HFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"4.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6676629</td>\n",
       "      <td>CRLM_225</td>\n",
       "      <td>CT_50926</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Abd 5.0 mm</td>\n",
       "      <td>125838.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"100\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>067Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"5.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9203144</td>\n",
       "      <td>CRLM_315</td>\n",
       "      <td>CT_63660</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Th. tumor 5.0 B30f</td>\n",
       "      <td>135349.43150</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20040129.0</td>\n",
       "      <td>F</td>\n",
       "      <td>067Y</td>\n",
       "      <td>Volume Zoom</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B30f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2469868</td>\n",
       "      <td>CRLM_100</td>\n",
       "      <td>CT_26579</td>\n",
       "      <td>4</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>thorax-lever 5.0 B30f</td>\n",
       "      <td>94926.99051</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20060426.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Volume Zoom</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B30f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4327749</td>\n",
       "      <td>CRLM_147</td>\n",
       "      <td>CT_10043</td>\n",
       "      <td>2</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>ABDOMEN 2/2</td>\n",
       "      <td>141238.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mx8000 IDT 10</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"2.00\"</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1079460</td>\n",
       "      <td>CRLM_045</td>\n",
       "      <td>CT_80259</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>D70 Abd. alg.  3.0  Br40  3</td>\n",
       "      <td>102158.15000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"110\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20180123.0</td>\n",
       "      <td>M</td>\n",
       "      <td>064Y</td>\n",
       "      <td>SOMATOM Edge Plus</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>['Br40f', '3']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4033021</td>\n",
       "      <td>CRLM_141</td>\n",
       "      <td>CT_12276</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144225.95000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>083Y</td>\n",
       "      <td>Aquilion</td>\n",
       "      <td>HFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"3.0\"</td>\n",
       "      <td>FC10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8408989</td>\n",
       "      <td>CRLM_290</td>\n",
       "      <td>CT_99400</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>th abd  3.0  B31f</td>\n",
       "      <td>155048.40080</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20130301.0</td>\n",
       "      <td>M</td>\n",
       "      <td>073Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3092569</td>\n",
       "      <td>CRLM_110</td>\n",
       "      <td>CT_82801</td>\n",
       "      <td>1497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113831.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>086Y</td>\n",
       "      <td>Mx8000</td>\n",
       "      <td>HFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"6.5\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3227315</td>\n",
       "      <td>CRLM_114</td>\n",
       "      <td>CT_22889</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Sft Tissue 3.0 VISIPAQUE/320 90CC CE</td>\n",
       "      <td>122732.45000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>20090106.0</td>\n",
       "      <td>M</td>\n",
       "      <td>054Y</td>\n",
       "      <td>Aquilion</td>\n",
       "      <td>FFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"3.0\"</td>\n",
       "      <td>FC13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2006537</td>\n",
       "      <td>CRLM_088</td>\n",
       "      <td>CT_24329</td>\n",
       "      <td>2-CT2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Thx/Abd   c.m 4.0 B40f</td>\n",
       "      <td>115624.97100</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20100119.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Volume Zoom</td>\n",
       "      <td>FFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>B40f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2972809</td>\n",
       "      <td>CRLM_105</td>\n",
       "      <td>CT_21529</td>\n",
       "      <td>2</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Thorax 3mm</td>\n",
       "      <td>133916.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"100\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>046Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"3.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4358305</td>\n",
       "      <td>CRLM_151</td>\n",
       "      <td>CT_10954</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>ONCO Th/Abd.  1.5  B70f</td>\n",
       "      <td>85505.58880</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20121219.0</td>\n",
       "      <td>M</td>\n",
       "      <td>073Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"1.5\"</td>\n",
       "      <td>B70f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5562239</td>\n",
       "      <td>CRLM_185</td>\n",
       "      <td>CT_27741</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>THO/ABD 70SEC PI</td>\n",
       "      <td>92356.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"100\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>073Y</td>\n",
       "      <td>iCT 256</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"2.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7326641</td>\n",
       "      <td>CRLM_254</td>\n",
       "      <td>CT_19187</td>\n",
       "      <td>5</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91231.15000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>20120601.0</td>\n",
       "      <td>M</td>\n",
       "      <td>076Y</td>\n",
       "      <td>Aquilion</td>\n",
       "      <td>FFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"3.0\"</td>\n",
       "      <td>FC02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9247015</td>\n",
       "      <td>CRLM_317</td>\n",
       "      <td>CT_94131</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>ONCO Th/Abd.  3.0  B31f</td>\n",
       "      <td>120739.99420</td>\n",
       "      <td>...</td>\n",
       "      <td>\"100\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20140214.0</td>\n",
       "      <td>M</td>\n",
       "      <td>070Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3429629</td>\n",
       "      <td>CRLM_121</td>\n",
       "      <td>CT_12724</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Abd 5.0 mm</td>\n",
       "      <td>91304.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"100\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>069Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"5.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6818250</td>\n",
       "      <td>CRLM_234</td>\n",
       "      <td>CT_11656</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3F Panc. ven.  5.0  B20f</td>\n",
       "      <td>102104.97440</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20040728.0</td>\n",
       "      <td>F</td>\n",
       "      <td>065Y</td>\n",
       "      <td>Sensation 16</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B20f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6562966</td>\n",
       "      <td>CRLM_221</td>\n",
       "      <td>CT_80994</td>\n",
       "      <td>2</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>Abd. algemeen  3.0  B31f</td>\n",
       "      <td>211154.92100</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120416.0</td>\n",
       "      <td>F</td>\n",
       "      <td>054Y</td>\n",
       "      <td>SOMATOM Definition Flash</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4892516</td>\n",
       "      <td>CRLM_166</td>\n",
       "      <td>CT_26366</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>ONCO Th/Abd.  1.5  B70f</td>\n",
       "      <td>95224.49210</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20130214.0</td>\n",
       "      <td>F</td>\n",
       "      <td>052Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"1.5\"</td>\n",
       "      <td>B70f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5800783</td>\n",
       "      <td>CRLM_192</td>\n",
       "      <td>CT_23433</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>th.tum-abd alg.  2.0  B31f</td>\n",
       "      <td>102029.80000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20040929.0</td>\n",
       "      <td>M</td>\n",
       "      <td>057Y</td>\n",
       "      <td>Sensation 16</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>B31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9759331</td>\n",
       "      <td>CRLM_333</td>\n",
       "      <td>CT_40034</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>Abd 5.0 mm</td>\n",
       "      <td>92656.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"100\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>072Y</td>\n",
       "      <td>Brilliance 64</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"5.00\"</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>9278300</td>\n",
       "      <td>CRLM_318</td>\n",
       "      <td>CT_23332</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>D70 Onco ThAb  3.0  I70f  3</td>\n",
       "      <td>161956.41600</td>\n",
       "      <td>...</td>\n",
       "      <td>\"100\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160921.0</td>\n",
       "      <td>F</td>\n",
       "      <td>064Y</td>\n",
       "      <td>SOMATOM Definition Edge</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>['I70f', '3']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6455598</td>\n",
       "      <td>CRLM_216</td>\n",
       "      <td>CT_18041</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>99.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>ABDOMEN 2/2</td>\n",
       "      <td>143237.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>058Y</td>\n",
       "      <td>Mx8000 IDT 10</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"2.00\"</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3563254</td>\n",
       "      <td>CRLM_125</td>\n",
       "      <td>CT_20191</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>ONCO Th/Abd.  3.0  B31f</td>\n",
       "      <td>81611.65119</td>\n",
       "      <td>...</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20131004.0</td>\n",
       "      <td>F</td>\n",
       "      <td>049Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PID   Subject Experiment   Scan       pHGP        dHGP        rHGP  \\\n",
       "0   7152829  CRLM_248   CT_29172      4   0.000000    5.833333   94.166667   \n",
       "1    292285  CRLM_005   CT_18862      4   0.000000    3.333333   96.666667   \n",
       "2   1820851  CRLM_081   CT_29966      2   0.000000   31.666667   68.333333   \n",
       "3   4932909  CRLM_169   CT_16877      2   0.000000    1.428571   98.571429   \n",
       "4   2489453  CRLM_101   CT_87243      7   0.000000   41.666667   58.333333   \n",
       "5   7739333  CRLM_264   CT_33728      7   0.000000  100.000000    0.000000   \n",
       "6   8859793  CRLM_300   CT_21114      4   0.000000   30.000000   70.000000   \n",
       "7   6643893  CRLM_223   CT_33488      3   5.000000   95.000000    0.000000   \n",
       "8   6431015  CRLM_214   CT_26150      2   0.000000   56.666667   43.333333   \n",
       "9    121369  CRLM_001   CT_33891      5   0.000000    7.500000   92.500000   \n",
       "10  6019571  CRLM_203   CT_14359     10  15.000000    0.000000   85.000000   \n",
       "11  5879354  CRLM_197   CT_76657      2   0.000000   41.041667   58.958333   \n",
       "12  8065953  CRLM_277   CT_94912      2   0.000000  100.000000    0.000000   \n",
       "13  1637698  CRLM_071   CT_17713      4  65.000000    0.000000   35.000000   \n",
       "14   521867  CRLM_017   CT_27354      2   0.000000  100.000000    0.000000   \n",
       "15  8205683  CRLM_283   CT_12575      2   0.000000   12.500000   87.500000   \n",
       "16  1094923  CRLM_047   CT_32703     22   3.125000   96.875000    0.000000   \n",
       "17   788823  CRLM_031   CT_25273      5   0.000000    0.000000  100.000000   \n",
       "18  2259297  CRLM_099   CT_29977      3   0.000000   95.000000    5.000000   \n",
       "19  6746373  CRLM_230   CT_31053      3   0.000000    0.000000  100.000000   \n",
       "20  6370665  CRLM_211   CT_63505      6   1.250000   70.000000   28.750000   \n",
       "21  9801055  CRLM_334   CT_89320      3   0.000000   65.000000   35.000000   \n",
       "22  4335562  CRLM_148   CT_26026      3   0.000000  100.000000    0.000000   \n",
       "23  7845187  CRLM_265   CT_19439      6  21.944444   37.500000   40.555556   \n",
       "24  6874007  CRLM_240   CT_32665      3   0.000000   12.500000   87.500000   \n",
       "25  2995387  CRLM_106   CT_26568      3   0.000000   76.666667   23.333333   \n",
       "26  6676629  CRLM_225   CT_50926      3   0.000000    5.000000   95.000000   \n",
       "27  9203144  CRLM_315   CT_63660      2   0.000000   30.000000   70.000000   \n",
       "28  2469868  CRLM_100   CT_26579      4   1.666667   36.666667   61.666667   \n",
       "29  4327749  CRLM_147   CT_10043      2  32.500000   22.500000   45.000000   \n",
       "30  1079460  CRLM_045   CT_80259      6   0.000000   96.666667    3.333333   \n",
       "31  4033021  CRLM_141   CT_12276      9   0.000000   95.000000    5.000000   \n",
       "32  8408989  CRLM_290   CT_99400      9   0.000000  100.000000    0.000000   \n",
       "33  3092569  CRLM_110   CT_82801   1497   0.000000  100.000000    0.000000   \n",
       "34  3227315  CRLM_114   CT_22889      3   0.000000  100.000000    0.000000   \n",
       "35  2006537  CRLM_088   CT_24329  2-CT2   0.000000    0.000000  100.000000   \n",
       "36  2972809  CRLM_105   CT_21529      2   5.000000   90.000000    5.000000   \n",
       "37  4358305  CRLM_151   CT_10954      6   0.000000  100.000000    0.000000   \n",
       "38  5562239  CRLM_185   CT_27741      2   0.000000    2.500000   97.500000   \n",
       "39  7326641  CRLM_254   CT_19187      5   3.333333   37.500000   59.166667   \n",
       "40  9247015  CRLM_317   CT_94131      3   0.000000  100.000000    0.000000   \n",
       "41  3429629  CRLM_121   CT_12724      2   0.000000  100.000000    0.000000   \n",
       "42  6818250  CRLM_234   CT_11656      4   0.000000    5.000000   95.000000   \n",
       "43  6562966  CRLM_221   CT_80994      2  67.500000   26.250000    6.250000   \n",
       "44  4892516  CRLM_166   CT_26366      6   0.000000    0.000000  100.000000   \n",
       "45  5800783  CRLM_192   CT_23433      4   5.000000   80.000000   15.000000   \n",
       "46  9759331  CRLM_333   CT_40034      5   0.000000    6.666667   93.333333   \n",
       "47  9278300  CRLM_318   CT_23332      4   0.000000   13.750000   86.250000   \n",
       "48  6455598  CRLM_216   CT_18041      5   0.000000    0.833333   99.166667   \n",
       "49  3563254  CRLM_125   CT_20191      3   0.000000   32.500000   67.500000   \n",
       "\n",
       "    HGP_Type                             Series_description  acquisition_time  \\\n",
       "0          0                                       ABD. 5/5      114902.00000   \n",
       "1          0                                            NaN       93655.75000   \n",
       "2          0                             Thx-lever 5.0 B30f      113904.38850   \n",
       "3          0                        th.abd. alg.  5.0  B31f      104110.53570   \n",
       "4          0                                            NaN      133834.00000   \n",
       "5          1                             Abdomen  5.0  B31s      114908.97490   \n",
       "6          0                      3F Lever port.  5.0  B31f       84356.95843   \n",
       "7          0                               Abdomen 6.0 B40s       92112.62500   \n",
       "8          0                                       ABD. 5MM      180527.00000   \n",
       "9          0                                            NaN      101443.00000   \n",
       "10         0                                            NaN      135724.40000   \n",
       "11         0  C+rectaal Body 5.0 CE +C 60s C+rectaal  Axial      181913.25000   \n",
       "12         1                             Thx-lever 5.0 B30f      115353.33800   \n",
       "13         0                                            NaN      111412.15000   \n",
       "14         1                                       ABD. 5MM      110231.00000   \n",
       "15         0                                Thx Med/Abd 5/5      102012.00000   \n",
       "16         0                     Dyn 4D Lever  1.5  Br36 16      120926.90800   \n",
       "17         0                C+ Body 5.0 CE C+ 60s C+  Axial      141336.75000   \n",
       "18         0                        ONCO Th/Abd.  3.0  B31f      140937.45300   \n",
       "19         0                          Th.abd.alg  5.0  B31f       85631.47327   \n",
       "20         0                                            NaN      110435.00000   \n",
       "21         0                     Abd  ThorAbd  2.0  I41f  3      113700.46300   \n",
       "22         1                                     Abd 5.0 mm       83455.00000   \n",
       "23         0                          ONCO ThAbd  1.5  B70f      152048.30750   \n",
       "24         0                                     Abd 5.0 mm      141349.00000   \n",
       "25         0                                     ABD AX 4MM      155645.00000   \n",
       "26         0                                     Abd 5.0 mm      125838.00000   \n",
       "27         0                             Th. tumor 5.0 B30f      135349.43150   \n",
       "28         0                          thorax-lever 5.0 B30f       94926.99051   \n",
       "29         0                                    ABDOMEN 2/2      141238.00000   \n",
       "30         0                    D70 Abd. alg.  3.0  Br40  3      102158.15000   \n",
       "31         0                                            NaN      144225.95000   \n",
       "32         1                              th abd  3.0  B31f      155048.40080   \n",
       "33         1                                            NaN      113831.00000   \n",
       "34         1           Sft Tissue 3.0 VISIPAQUE/320 90CC CE      122732.45000   \n",
       "35         0                         Thx/Abd   c.m 4.0 B40f      115624.97100   \n",
       "36         0                                     Thorax 3mm      133916.00000   \n",
       "37         1                        ONCO Th/Abd.  1.5  B70f       85505.58880   \n",
       "38         0                               THO/ABD 70SEC PI       92356.00000   \n",
       "39         0                                            NaN       91231.15000   \n",
       "40         1                        ONCO Th/Abd.  3.0  B31f      120739.99420   \n",
       "41         1                                     Abd 5.0 mm       91304.00000   \n",
       "42         0                       3F Panc. ven.  5.0  B20f      102104.97440   \n",
       "43         0                       Abd. algemeen  3.0  B31f      211154.92100   \n",
       "44         0                        ONCO Th/Abd.  1.5  B70f       95224.49210   \n",
       "45         0                     th.tum-abd alg.  2.0  B31f      102029.80000   \n",
       "46         0                                     Abd 5.0 mm       92656.00000   \n",
       "47         0                    D70 Onco ThAb  3.0  I70f  3      161956.41600   \n",
       "48         0                                    ABDOMEN 2/2      143237.00000   \n",
       "49         0                        ONCO Th/Abd.  3.0  B31f       81611.65119   \n",
       "\n",
       "    ...    kvp                                       scan_options  \\\n",
       "0   ...  \"120\"                                              HELIX   \n",
       "1   ...  \"120\"                                         HELICAL_CT   \n",
       "2   ...  \"120\"                                                NaN   \n",
       "3   ...  \"120\"                                                NaN   \n",
       "4   ...  \"120\"                                              HELIX   \n",
       "5   ...  \"120\"                                                NaN   \n",
       "6   ...  \"120\"                                                NaN   \n",
       "7   ...  \"110\"                                                NaN   \n",
       "8   ...  \"120\"                                              HELIX   \n",
       "9   ...  \"120\"                                         HELICAL_CT   \n",
       "10  ...  \"120\"                                         HELICAL_CT   \n",
       "11  ...  \"120\"                                         HELICAL_CT   \n",
       "12  ...  \"120\"                                                NaN   \n",
       "13  ...  \"135\"                                         HELICAL_CT   \n",
       "14  ...  \"120\"                                              HELIX   \n",
       "15  ...  \"120\"                                              HELIX   \n",
       "16  ...   \"80\"  ['XOP', 'A4DS', '0001', 'CONT', 'RSER000001', ...   \n",
       "17  ...  \"120\"                                         HELICAL_CT   \n",
       "18  ...  \"120\"                                                NaN   \n",
       "19  ...  \"120\"                                                NaN   \n",
       "20  ...  \"120\"                                              HELIX   \n",
       "21  ...  \"120\"                                                NaN   \n",
       "22  ...  \"120\"                                              HELIX   \n",
       "23  ...  \"120\"                                                NaN   \n",
       "24  ...  \"100\"                                              HELIX   \n",
       "25  ...  \"120\"                                              HELIX   \n",
       "26  ...  \"100\"                                              HELIX   \n",
       "27  ...  \"120\"                                                NaN   \n",
       "28  ...  \"120\"                                                NaN   \n",
       "29  ...  \"120\"                                              HELIX   \n",
       "30  ...  \"110\"                                                NaN   \n",
       "31  ...  \"120\"                                         HELICAL_CT   \n",
       "32  ...  \"120\"                                                NaN   \n",
       "33  ...  \"120\"                                              HELIX   \n",
       "34  ...  \"120\"                                         HELICAL_CT   \n",
       "35  ...  \"120\"                                                NaN   \n",
       "36  ...  \"100\"                                              HELIX   \n",
       "37  ...  \"120\"                                                NaN   \n",
       "38  ...  \"100\"                                              HELIX   \n",
       "39  ...  \"120\"                                         HELICAL_CT   \n",
       "40  ...  \"100\"                                                NaN   \n",
       "41  ...  \"100\"                                              HELIX   \n",
       "42  ...  \"120\"                                                NaN   \n",
       "43  ...  \"120\"                                                NaN   \n",
       "44  ...  \"120\"                                                NaN   \n",
       "45  ...  \"120\"                                                NaN   \n",
       "46  ...  \"100\"                                              HELIX   \n",
       "47  ...  \"100\"                                                NaN   \n",
       "48  ...  \"120\"                                              HELIX   \n",
       "49  ...  \"120\"                                                NaN   \n",
       "\n",
       "   seriesdate_y gender   age                model_name  patient_position  \\\n",
       "0           NaN      M  079Y             Brilliance 64               FFS   \n",
       "1           NaN      M  066Y                   Asteion               HFS   \n",
       "2    20040419.0      M   NaN               Volume Zoom               HFS   \n",
       "3    20050506.0      M  057Y              Sensation 16               HFS   \n",
       "4           NaN      M  072Y             Mx8000 IDT 16               FFS   \n",
       "5    20140409.0      M  084Y              Sensation 40               HFS   \n",
       "6    20040604.0      M  067Y              Sensation 16               HFS   \n",
       "7    20111129.0      M  081Y               Emotion Duo               HFS   \n",
       "8           NaN      M  066Y             Brilliance 64               FFS   \n",
       "9    20100730.0      M  077Y                  Aquilion               FFS   \n",
       "10          NaN      M  074Y                  Aquilion               HFS   \n",
       "11   20150501.0      F  061Y              Aquilion ONE               FFS   \n",
       "12   20040108.0      M   NaN               Volume Zoom               HFS   \n",
       "13          NaN      F  079Y                   Asteion               HFS   \n",
       "14          NaN      M  052Y             Brilliance 64               FFS   \n",
       "15          NaN      M  065Y             Brilliance 64               FFS   \n",
       "16   20180215.0      M  068Y             SOMATOM Force               HFS   \n",
       "17   20141203.0      M  084Y              Aquilion ONE               FFS   \n",
       "18   20140610.0      M  069Y              Sensation 64               HFS   \n",
       "19   20070524.0      M  060Y              Sensation 16               HFS   \n",
       "20          NaN      M  057Y             Mx8000 IDT 16               FFS   \n",
       "21   20150202.0      M  060Y  SOMATOM Definition Flash               FFS   \n",
       "22          NaN      F  067Y             Brilliance 64               FFS   \n",
       "23   20151001.0      M  074Y              Sensation 64               HFS   \n",
       "24          NaN      M  054Y             Brilliance 64               FFS   \n",
       "25          NaN      M  054Y             Brilliance 40               HFS   \n",
       "26          NaN      M  067Y             Brilliance 64               FFS   \n",
       "27   20040129.0      F  067Y               Volume Zoom               HFS   \n",
       "28   20060426.0      F   NaN               Volume Zoom               HFS   \n",
       "29          NaN      M   NaN             Mx8000 IDT 10               FFS   \n",
       "30   20180123.0      M  064Y         SOMATOM Edge Plus               HFS   \n",
       "31          NaN      M  083Y                  Aquilion               HFS   \n",
       "32   20130301.0      M  073Y              Sensation 64               HFS   \n",
       "33          NaN      M  086Y                    Mx8000               HFS   \n",
       "34   20090106.0      M  054Y                  Aquilion               FFS   \n",
       "35   20100119.0      M   NaN               Volume Zoom               FFS   \n",
       "36          NaN      M  046Y             Brilliance 64               FFS   \n",
       "37   20121219.0      M  073Y              Sensation 64               HFS   \n",
       "38          NaN      M  073Y                   iCT 256               FFS   \n",
       "39   20120601.0      M  076Y                  Aquilion               FFS   \n",
       "40   20140214.0      M  070Y              Sensation 64               HFS   \n",
       "41          NaN      M  069Y             Brilliance 64               FFS   \n",
       "42   20040728.0      F  065Y              Sensation 16               HFS   \n",
       "43   20120416.0      F  054Y  SOMATOM Definition Flash               HFS   \n",
       "44   20130214.0      F  052Y              Sensation 64               HFS   \n",
       "45   20040929.0      M  057Y              Sensation 16               HFS   \n",
       "46          NaN      M  072Y             Brilliance 64               FFS   \n",
       "47   20160921.0      F  064Y   SOMATOM Definition Edge               HFS   \n",
       "48          NaN      F  058Y             Mx8000 IDT 10               FFS   \n",
       "49   20131004.0      F  049Y              Sensation 64               HFS   \n",
       "\n",
       "    manufacturer  slice_thickness  convolution_kernel  \n",
       "0        Philips           \"5.00\"                   B  \n",
       "1        TOSHIBA            \"3.0\"                FC10  \n",
       "2        SIEMENS              \"5\"                B30f  \n",
       "3        SIEMENS              \"5\"                B31f  \n",
       "4        Philips            \"2.0\"                   B  \n",
       "5        SIEMENS              \"5\"                B31s  \n",
       "6        SIEMENS              \"5\"                B31f  \n",
       "7        SIEMENS              \"6\"                B40s  \n",
       "8        Philips           \"5.00\"                   B  \n",
       "9        TOSHIBA            \"3.0\"                FC02  \n",
       "10       TOSHIBA            \"3.0\"                FC10  \n",
       "11       TOSHIBA            \"5.0\"                FC09  \n",
       "12       SIEMENS              \"5\"                B30f  \n",
       "13       TOSHIBA            \"5.0\"                FC10  \n",
       "14       Philips           \"5.00\"                   B  \n",
       "15       Philips           \"5.00\"                   B  \n",
       "16       SIEMENS            \"1.5\"               Br36f  \n",
       "17       TOSHIBA            \"5.0\"                FC09  \n",
       "18       SIEMENS              \"3\"                B31f  \n",
       "19       SIEMENS              \"5\"                B31f  \n",
       "20       Philips            \"2.0\"                   B  \n",
       "21       SIEMENS              \"2\"       ['I41f', '3']  \n",
       "22       Philips           \"5.00\"                   B  \n",
       "23       SIEMENS            \"1.5\"                B70f  \n",
       "24       Philips           \"5.00\"                   B  \n",
       "25       Philips           \"4.00\"                   B  \n",
       "26       Philips           \"5.00\"                   B  \n",
       "27       SIEMENS              \"5\"                B30f  \n",
       "28       SIEMENS              \"5\"                B30f  \n",
       "29       Philips           \"2.00\"                   C  \n",
       "30       SIEMENS              \"3\"      ['Br40f', '3']  \n",
       "31       TOSHIBA            \"3.0\"                FC10  \n",
       "32       SIEMENS              \"3\"                B31f  \n",
       "33       Philips            \"6.5\"                   B  \n",
       "34       TOSHIBA            \"3.0\"                FC13  \n",
       "35       SIEMENS              \"4\"                B40f  \n",
       "36       Philips           \"3.00\"                   B  \n",
       "37       SIEMENS            \"1.5\"                B70f  \n",
       "38       Philips           \"2.00\"                   B  \n",
       "39       TOSHIBA            \"3.0\"                FC02  \n",
       "40       SIEMENS              \"3\"                B31f  \n",
       "41       Philips           \"5.00\"                   B  \n",
       "42       SIEMENS              \"5\"                B20f  \n",
       "43       SIEMENS              \"3\"                B31f  \n",
       "44       SIEMENS            \"1.5\"                B70f  \n",
       "45       SIEMENS              \"2\"                B31f  \n",
       "46       Philips           \"5.00\"                   B  \n",
       "47       SIEMENS              \"3\"       ['I70f', '3']  \n",
       "48       Philips           \"2.00\"                   C  \n",
       "49       SIEMENS              \"3\"                B31f  \n",
       "\n",
       "[50 rows x 50 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move these files from the original folder to the new folder\n",
    "import shutil\n",
    "import os\n",
    "for i in test_name:\n",
    "    shutil.copy('../../Data/Mixed_HGP/Mixed_HGP_Only_Liver_07073_Windowed/' + i, '../../Data/Mixed_HGP/Mixed_HGP_Only_Liver_07073_Windowed_Test/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "stratify_kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "data_info = pd.read_csv('../../Data/Mixed_HGP/True_Label/scans_used_all_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data_info['HGP_Type']\n",
    "for i,(tr_idx,val_idx) in enumerate(stratify_kfold.split(data_info,label)):\n",
    "    train_data = data_info.loc[tr_idx]\n",
    "    val_data = data_info.loc[val_idx]\n",
    "    train_data.to_csv('../../Data/Mixed_HGP/True_Label/train_cv_'+str(i)+'.csv',index=False)\n",
    "    val_data.to_csv('../../Data/Mixed_HGP/True_Label/val_cv_'+str(i)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add data path in each cv in csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Scan</th>\n",
       "      <th>pHGP</th>\n",
       "      <th>dHGP</th>\n",
       "      <th>rHGP</th>\n",
       "      <th>HGP_Type</th>\n",
       "      <th>Series_description</th>\n",
       "      <th>acquisition_time</th>\n",
       "      <th>...</th>\n",
       "      <th>scan_options</th>\n",
       "      <th>seriesdate_y</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>model_name</th>\n",
       "      <th>patient_position</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>slice_thickness</th>\n",
       "      <th>convolution_kernel</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3932332</td>\n",
       "      <td>CRLM_137</td>\n",
       "      <td>CT_10033</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Lever meta's  2.0  B31f</td>\n",
       "      <td>84259.93629</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20060906.0</td>\n",
       "      <td>F</td>\n",
       "      <td>073Y</td>\n",
       "      <td>Sensation 16</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4327749</td>\n",
       "      <td>CRLM_147</td>\n",
       "      <td>CT_10043</td>\n",
       "      <td>2</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>ABDOMEN 2/2</td>\n",
       "      <td>141238.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mx8000 IDT 10</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"2.00\"</td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1030425</td>\n",
       "      <td>CRLM_042</td>\n",
       "      <td>CT_10104</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>A10 abdomen veneus 5.0 weke delen axial</td>\n",
       "      <td>104531.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>HELICAL_CT</td>\n",
       "      <td>20170614.0</td>\n",
       "      <td>M</td>\n",
       "      <td>061Y</td>\n",
       "      <td>Aquilion ONE</td>\n",
       "      <td>FFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>FC09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3985131</td>\n",
       "      <td>CRLM_139</td>\n",
       "      <td>CT_10203</td>\n",
       "      <td>7</td>\n",
       "      <td>27.555556</td>\n",
       "      <td>72.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Th-Abd. alg.  2.0  B20f</td>\n",
       "      <td>142730.55920</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20060131.0</td>\n",
       "      <td>M</td>\n",
       "      <td>061Y</td>\n",
       "      <td>Sensation 16</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>B20f</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8202397</td>\n",
       "      <td>CRLM_282</td>\n",
       "      <td>CT_10702</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>98.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>ONCO ThAbd  3.0  B31f</td>\n",
       "      <td>115626.45590</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170921.0</td>\n",
       "      <td>M</td>\n",
       "      <td>071Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>8488669</td>\n",
       "      <td>CRLM_292</td>\n",
       "      <td>CT_89092</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115132.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>HELIX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>064Y</td>\n",
       "      <td>Mx8000 IDT 16</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"2.0\"</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>9801055</td>\n",
       "      <td>CRLM_334</td>\n",
       "      <td>CT_89320</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Abd  ThorAbd  2.0  I41f  3</td>\n",
       "      <td>113700.46300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20150202.0</td>\n",
       "      <td>M</td>\n",
       "      <td>060Y</td>\n",
       "      <td>SOMATOM Definition Flash</td>\n",
       "      <td>FFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>['I41f', '3']</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>9247015</td>\n",
       "      <td>CRLM_317</td>\n",
       "      <td>CT_94131</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>ONCO Th/Abd.  3.0  B31f</td>\n",
       "      <td>120739.99420</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20140214.0</td>\n",
       "      <td>M</td>\n",
       "      <td>070Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>3835842</td>\n",
       "      <td>CRLM_129</td>\n",
       "      <td>CT_97575</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Thorax  5.0  B31f</td>\n",
       "      <td>91040.23781</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141016.0</td>\n",
       "      <td>F</td>\n",
       "      <td>071Y</td>\n",
       "      <td>Sensation 40</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>8408989</td>\n",
       "      <td>CRLM_290</td>\n",
       "      <td>CT_99400</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>th abd  3.0  B31f</td>\n",
       "      <td>155048.40080</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20130301.0</td>\n",
       "      <td>M</td>\n",
       "      <td>073Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID   Subject Experiment Scan       pHGP        dHGP        rHGP  \\\n",
       "0    3932332  CRLM_137   CT_10033    4   0.000000   30.000000   70.000000   \n",
       "1    4327749  CRLM_147   CT_10043    2  32.500000   22.500000   45.000000   \n",
       "2    1030425  CRLM_042   CT_10104    2   0.000000    0.000000  100.000000   \n",
       "3    3985131  CRLM_139   CT_10203    7  27.555556   72.444444    0.000000   \n",
       "4    8202397  CRLM_282   CT_10702    2   0.000000    1.111111   98.888889   \n",
       "..       ...       ...        ...  ...        ...         ...         ...   \n",
       "242  8488669  CRLM_292   CT_89092    5   0.000000  100.000000    0.000000   \n",
       "243  9801055  CRLM_334   CT_89320    3   0.000000   65.000000   35.000000   \n",
       "244  9247015  CRLM_317   CT_94131    3   0.000000  100.000000    0.000000   \n",
       "246  3835842  CRLM_129   CT_97575    2   0.000000  100.000000    0.000000   \n",
       "247  8408989  CRLM_290   CT_99400    9   0.000000  100.000000    0.000000   \n",
       "\n",
       "     HGP_Type                       Series_description  acquisition_time  ...  \\\n",
       "0           0                  Lever meta's  2.0  B31f       84259.93629  ...   \n",
       "1           0                              ABDOMEN 2/2      141238.00000  ...   \n",
       "2           0  A10 abdomen veneus 5.0 weke delen axial      104531.00000  ...   \n",
       "3           0                  Th-Abd. alg.  2.0  B20f      142730.55920  ...   \n",
       "4           0                    ONCO ThAbd  3.0  B31f      115626.45590  ...   \n",
       "..        ...                                      ...               ...  ...   \n",
       "242         1                                      NaN      115132.00000  ...   \n",
       "243         0               Abd  ThorAbd  2.0  I41f  3      113700.46300  ...   \n",
       "244         1                  ONCO Th/Abd.  3.0  B31f      120739.99420  ...   \n",
       "246         1                        Thorax  5.0  B31f       91040.23781  ...   \n",
       "247         1                        th abd  3.0  B31f      155048.40080  ...   \n",
       "\n",
       "     scan_options  seriesdate_y gender   age                model_name  \\\n",
       "0             NaN    20060906.0      F  073Y              Sensation 16   \n",
       "1           HELIX           NaN      M   NaN             Mx8000 IDT 10   \n",
       "2      HELICAL_CT    20170614.0      M  061Y              Aquilion ONE   \n",
       "3             NaN    20060131.0      M  061Y              Sensation 16   \n",
       "4             NaN    20170921.0      M  071Y              Sensation 64   \n",
       "..            ...           ...    ...   ...                       ...   \n",
       "242         HELIX           NaN      M  064Y             Mx8000 IDT 16   \n",
       "243           NaN    20150202.0      M  060Y  SOMATOM Definition Flash   \n",
       "244           NaN    20140214.0      M  070Y              Sensation 64   \n",
       "246           NaN    20141016.0      F  071Y              Sensation 40   \n",
       "247           NaN    20130301.0      M  073Y              Sensation 64   \n",
       "\n",
       "     patient_position  manufacturer  slice_thickness  convolution_kernel  \\\n",
       "0                 HFS       SIEMENS              \"2\"                B31f   \n",
       "1                 FFS       Philips           \"2.00\"                   C   \n",
       "2                 FFS       TOSHIBA              \"5\"                FC09   \n",
       "3                 HFS       SIEMENS              \"2\"                B20f   \n",
       "4                 HFS       SIEMENS              \"3\"                B31f   \n",
       "..                ...           ...              ...                 ...   \n",
       "242               FFS       Philips            \"2.0\"                   B   \n",
       "243               FFS       SIEMENS              \"2\"       ['I41f', '3']   \n",
       "244               HFS       SIEMENS              \"3\"                B31f   \n",
       "246               HFS       SIEMENS              \"5\"                B31f   \n",
       "247               HFS       SIEMENS              \"3\"                B31f   \n",
       "\n",
       "     kfold  \n",
       "0      3.0  \n",
       "1      2.0  \n",
       "2      0.0  \n",
       "3      1.0  \n",
       "4      3.0  \n",
       "..     ...  \n",
       "242    1.0  \n",
       "243    2.0  \n",
       "244    3.0  \n",
       "246    0.0  \n",
       "247    0.0  \n",
       "\n",
       "[199 rows x 51 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prefix = 'CILM_'\n",
    "Suffix = '0_0000.nii.gz'\n",
    "for i in range(5):\n",
    "    train_data = pd.read_csv('../../Data/Mixed_HGP/True_Label/train_cv_'+str(i)+'.csv')\n",
    "    val_data = pd.read_csv('../../Data/Mixed_HGP/True_Label/val_cv_'+str(i)+'.csv')\n",
    "    train_name = train_data.Experiment.tolist()\n",
    "    val_name = val_data.Experiment.tolist()\n",
    "    train_name = [Prefix  + str(i) + Suffix for i in train_name]\n",
    "    val_name = [Prefix + str(i) + Suffix for i in val_name]\n",
    "    train_data['data_path'] = train_name\n",
    "    val_data['data_path'] = val_name\n",
    "    train_data.to_csv('../../Data/Mixed_HGP/True_Label/train_cv_'+str(i)+'.csv',index=False)\n",
    "    val_data.to_csv('../../Data/Mixed_HGP/True_Label/val_cv_'+str(i)+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Scan</th>\n",
       "      <th>pHGP</th>\n",
       "      <th>dHGP</th>\n",
       "      <th>rHGP</th>\n",
       "      <th>HGP_Type</th>\n",
       "      <th>Series_description</th>\n",
       "      <th>acquisition_time</th>\n",
       "      <th>...</th>\n",
       "      <th>seriesdate_y</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>model_name</th>\n",
       "      <th>patient_position</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>slice_thickness</th>\n",
       "      <th>convolution_kernel</th>\n",
       "      <th>kfold</th>\n",
       "      <th>data_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3932332</td>\n",
       "      <td>CRLM_137</td>\n",
       "      <td>CT_10033</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Lever meta's  2.0  B31f</td>\n",
       "      <td>84259.93629</td>\n",
       "      <td>...</td>\n",
       "      <td>20060906.0</td>\n",
       "      <td>F</td>\n",
       "      <td>073Y</td>\n",
       "      <td>Sensation 16</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CILM_CT_100330_0000.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4327749</td>\n",
       "      <td>CRLM_147</td>\n",
       "      <td>CT_10043</td>\n",
       "      <td>2</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>ABDOMEN 2/2</td>\n",
       "      <td>141238.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mx8000 IDT 10</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"2.00\"</td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CILM_CT_100430_0000.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1030425</td>\n",
       "      <td>CRLM_042</td>\n",
       "      <td>CT_10104</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>A10 abdomen veneus 5.0 weke delen axial</td>\n",
       "      <td>104531.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>20170614.0</td>\n",
       "      <td>M</td>\n",
       "      <td>061Y</td>\n",
       "      <td>Aquilion ONE</td>\n",
       "      <td>FFS</td>\n",
       "      <td>TOSHIBA</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>FC09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CILM_CT_101040_0000.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3985131</td>\n",
       "      <td>CRLM_139</td>\n",
       "      <td>CT_10203</td>\n",
       "      <td>7</td>\n",
       "      <td>27.555556</td>\n",
       "      <td>72.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Th-Abd. alg.  2.0  B20f</td>\n",
       "      <td>142730.55920</td>\n",
       "      <td>...</td>\n",
       "      <td>20060131.0</td>\n",
       "      <td>M</td>\n",
       "      <td>061Y</td>\n",
       "      <td>Sensation 16</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>B20f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CILM_CT_102030_0000.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8202397</td>\n",
       "      <td>CRLM_282</td>\n",
       "      <td>CT_10702</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>98.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>ONCO ThAbd  3.0  B31f</td>\n",
       "      <td>115626.45590</td>\n",
       "      <td>...</td>\n",
       "      <td>20170921.0</td>\n",
       "      <td>M</td>\n",
       "      <td>071Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CILM_CT_107020_0000.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>8488669</td>\n",
       "      <td>CRLM_292</td>\n",
       "      <td>CT_89092</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115132.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>064Y</td>\n",
       "      <td>Mx8000 IDT 16</td>\n",
       "      <td>FFS</td>\n",
       "      <td>Philips</td>\n",
       "      <td>\"2.0\"</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CILM_CT_890920_0000.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>9801055</td>\n",
       "      <td>CRLM_334</td>\n",
       "      <td>CT_89320</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Abd  ThorAbd  2.0  I41f  3</td>\n",
       "      <td>113700.46300</td>\n",
       "      <td>...</td>\n",
       "      <td>20150202.0</td>\n",
       "      <td>M</td>\n",
       "      <td>060Y</td>\n",
       "      <td>SOMATOM Definition Flash</td>\n",
       "      <td>FFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"2\"</td>\n",
       "      <td>['I41f', '3']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CILM_CT_893200_0000.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9247015</td>\n",
       "      <td>CRLM_317</td>\n",
       "      <td>CT_94131</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>ONCO Th/Abd.  3.0  B31f</td>\n",
       "      <td>120739.99420</td>\n",
       "      <td>...</td>\n",
       "      <td>20140214.0</td>\n",
       "      <td>M</td>\n",
       "      <td>070Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CILM_CT_941310_0000.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3835842</td>\n",
       "      <td>CRLM_129</td>\n",
       "      <td>CT_97575</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Thorax  5.0  B31f</td>\n",
       "      <td>91040.23781</td>\n",
       "      <td>...</td>\n",
       "      <td>20141016.0</td>\n",
       "      <td>F</td>\n",
       "      <td>071Y</td>\n",
       "      <td>Sensation 40</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CILM_CT_975750_0000.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>8408989</td>\n",
       "      <td>CRLM_290</td>\n",
       "      <td>CT_99400</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>th abd  3.0  B31f</td>\n",
       "      <td>155048.40080</td>\n",
       "      <td>...</td>\n",
       "      <td>20130301.0</td>\n",
       "      <td>M</td>\n",
       "      <td>073Y</td>\n",
       "      <td>Sensation 64</td>\n",
       "      <td>HFS</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>B31f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CILM_CT_994000_0000.nii.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID   Subject Experiment Scan       pHGP        dHGP        rHGP  \\\n",
       "0    3932332  CRLM_137   CT_10033    4   0.000000   30.000000   70.000000   \n",
       "1    4327749  CRLM_147   CT_10043    2  32.500000   22.500000   45.000000   \n",
       "2    1030425  CRLM_042   CT_10104    2   0.000000    0.000000  100.000000   \n",
       "3    3985131  CRLM_139   CT_10203    7  27.555556   72.444444    0.000000   \n",
       "4    8202397  CRLM_282   CT_10702    2   0.000000    1.111111   98.888889   \n",
       "..       ...       ...        ...  ...        ...         ...         ...   \n",
       "194  8488669  CRLM_292   CT_89092    5   0.000000  100.000000    0.000000   \n",
       "195  9801055  CRLM_334   CT_89320    3   0.000000   65.000000   35.000000   \n",
       "196  9247015  CRLM_317   CT_94131    3   0.000000  100.000000    0.000000   \n",
       "197  3835842  CRLM_129   CT_97575    2   0.000000  100.000000    0.000000   \n",
       "198  8408989  CRLM_290   CT_99400    9   0.000000  100.000000    0.000000   \n",
       "\n",
       "     HGP_Type                       Series_description  acquisition_time  ...  \\\n",
       "0           0                  Lever meta's  2.0  B31f       84259.93629  ...   \n",
       "1           0                              ABDOMEN 2/2      141238.00000  ...   \n",
       "2           0  A10 abdomen veneus 5.0 weke delen axial      104531.00000  ...   \n",
       "3           0                  Th-Abd. alg.  2.0  B20f      142730.55920  ...   \n",
       "4           0                    ONCO ThAbd  3.0  B31f      115626.45590  ...   \n",
       "..        ...                                      ...               ...  ...   \n",
       "194         1                                      NaN      115132.00000  ...   \n",
       "195         0               Abd  ThorAbd  2.0  I41f  3      113700.46300  ...   \n",
       "196         1                  ONCO Th/Abd.  3.0  B31f      120739.99420  ...   \n",
       "197         1                        Thorax  5.0  B31f       91040.23781  ...   \n",
       "198         1                        th abd  3.0  B31f      155048.40080  ...   \n",
       "\n",
       "     seriesdate_y  gender   age                model_name  patient_position  \\\n",
       "0      20060906.0       F  073Y              Sensation 16               HFS   \n",
       "1             NaN       M   NaN             Mx8000 IDT 10               FFS   \n",
       "2      20170614.0       M  061Y              Aquilion ONE               FFS   \n",
       "3      20060131.0       M  061Y              Sensation 16               HFS   \n",
       "4      20170921.0       M  071Y              Sensation 64               HFS   \n",
       "..            ...     ...   ...                       ...               ...   \n",
       "194           NaN       M  064Y             Mx8000 IDT 16               FFS   \n",
       "195    20150202.0       M  060Y  SOMATOM Definition Flash               FFS   \n",
       "196    20140214.0       M  070Y              Sensation 64               HFS   \n",
       "197    20141016.0       F  071Y              Sensation 40               HFS   \n",
       "198    20130301.0       M  073Y              Sensation 64               HFS   \n",
       "\n",
       "     manufacturer  slice_thickness  convolution_kernel  kfold  \\\n",
       "0         SIEMENS              \"2\"                B31f    3.0   \n",
       "1         Philips           \"2.00\"                   C    2.0   \n",
       "2         TOSHIBA              \"5\"                FC09    0.0   \n",
       "3         SIEMENS              \"2\"                B20f    1.0   \n",
       "4         SIEMENS              \"3\"                B31f    3.0   \n",
       "..            ...              ...                 ...    ...   \n",
       "194       Philips            \"2.0\"                   B    1.0   \n",
       "195       SIEMENS              \"2\"       ['I41f', '3']    2.0   \n",
       "196       SIEMENS              \"3\"                B31f    3.0   \n",
       "197       SIEMENS              \"5\"                B31f    0.0   \n",
       "198       SIEMENS              \"3\"                B31f    0.0   \n",
       "\n",
       "                      data_path  \n",
       "0    CILM_CT_100330_0000.nii.gz  \n",
       "1    CILM_CT_100430_0000.nii.gz  \n",
       "2    CILM_CT_101040_0000.nii.gz  \n",
       "3    CILM_CT_102030_0000.nii.gz  \n",
       "4    CILM_CT_107020_0000.nii.gz  \n",
       "..                          ...  \n",
       "194  CILM_CT_890920_0000.nii.gz  \n",
       "195  CILM_CT_893200_0000.nii.gz  \n",
       "196  CILM_CT_941310_0000.nii.gz  \n",
       "197  CILM_CT_975750_0000.nii.gz  \n",
       "198  CILM_CT_994000_0000.nii.gz  \n",
       "\n",
       "[199 rows x 52 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#allow duplicates\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../')\n",
    "from Core.Utils import Swin_Transformer_Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fucking dhw 35 133 133\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 849425780 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m test_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#model.eval()\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\098986\\Intership_CILM\\CRLM_Internship_Project\\Jupyter_Test\\..\\Core\\Utils\\Swin_Transformer_Classification.py:334\u001b[0m, in \u001b[0;36mSwinUNETR.forward\u001b[1;34m(self, x_in)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_size(x_in\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m--> 334\u001b[0m hidden_states_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswinViT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m#print('hidden states out',hidden_states_out.shape)\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03menc0 = self.encoder1(x_in)\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03menc1 = self.encoder2(hidden_states_out[0])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03mreturn logits\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\098986\\Intership_CILM\\CRLM_Internship_Project\\Jupyter_Test\\..\\Core\\Utils\\Swin_Transformer_Classification.py:1091\u001b[0m, in \u001b[0;36mSwinTransformer.forward\u001b[1;34m(self, x, normalize)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_v2:\n\u001b[0;32m   1090\u001b[0m     x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers1c[\u001b[38;5;241m0\u001b[39m](x0\u001b[38;5;241m.\u001b[39mcontiguous())\n\u001b[1;32m-> 1091\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28mprint\u001b[39m(x1\u001b[38;5;241m.\u001b[39mshape,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis is x1 shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1093\u001b[0m x1_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_out(x1, normalize)\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\098986\\Intership_CILM\\CRLM_Internship_Project\\Jupyter_Test\\..\\Core\\Utils\\Swin_Transformer_Classification.py:921\u001b[0m, in \u001b[0;36mBasicLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    919\u001b[0m hp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(h \u001b[38;5;241m/\u001b[39m window_size[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m*\u001b[39m window_size[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    920\u001b[0m wp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(w \u001b[38;5;241m/\u001b[39m window_size[\u001b[38;5;241m2\u001b[39m])) \u001b[38;5;241m*\u001b[39m window_size[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m--> 921\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m    923\u001b[0m     x \u001b[38;5;241m=\u001b[39m blk(x, attn_mask)\n",
      "File \u001b[1;32mc:\\Users\\098986\\Intership_CILM\\CRLM_Internship_Project\\Jupyter_Test\\..\\Core\\Utils\\Swin_Transformer_Classification.py:837\u001b[0m, in \u001b[0;36mcompute_mask\u001b[1;34m(dims, window_size, shift_size, device)\u001b[0m\n\u001b[0;32m    835\u001b[0m mask_windows \u001b[38;5;241m=\u001b[39m window_partition(img_mask, window_size)\n\u001b[0;32m    836\u001b[0m mask_windows \u001b[38;5;241m=\u001b[39m mask_windows\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 837\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmask_windows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask_windows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m attn_mask\u001b[38;5;241m.\u001b[39mmasked_fill(attn_mask \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100.0\u001b[39m))\u001b[38;5;241m.\u001b[39mmasked_fill(attn_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m0.0\u001b[39m))\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_mask\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 849425780 bytes."
     ]
    }
   ],
   "source": [
    "model = Swin_Transformer_Classification.SwinUNETR(img_size=256,in_channels=1, num_classes=2, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],out_channels=1)\n",
    "model_dicts = torch.load('../../Output/Resnet10/Test_local/SwingTransformer/0/best_metric_1.pth')['model']\n",
    "model.load_state_dict(model_dicts)\n",
    "model.train()\n",
    "test_data = torch.randn(1,1,64,256,256)\n",
    "#model.eval()\n",
    "model(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_para(para_name,model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if para_name in name:\n",
    "            print(name,param.shape)\n",
    "    return param "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = [0]\n",
    "torch.save(a,'./new.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.load('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import itertools\n",
    "from collections.abc import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from torch.nn import LayerNorm\n",
    "from typing_extensions import Final\n",
    "\n",
    "from monai.networks.blocks import MLPBlock as Mlp\n",
    "from monai.networks.blocks import PatchEmbed, UnetOutBlock, UnetrBasicBlock, UnetrUpBlock\n",
    "from monai.networks.layers import DropPath, trunc_normal_\n",
    "from monai.utils import ensure_tuple_rep, look_up_option, optional_import\n",
    "from monai.utils.deprecate_utils import deprecated_arg\n",
    "\n",
    "\n",
    "rearrange, _ = optional_import(\"einops\", name=\"rearrange\")\n",
    "\n",
    "__all__ = [\n",
    "    \"SwinUNETR\",\n",
    "    \"window_partition\",\n",
    "    \"window_reverse\",\n",
    "    \"WindowAttention\",\n",
    "    \"SwinTransformerBlock\",\n",
    "    \"PatchMerging\",\n",
    "    \"PatchMergingV2\",\n",
    "    \"MERGING_MODE\",\n",
    "    \"BasicLayer\",\n",
    "    \"SwinTransformer\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "class SwinUNETR(nn.Module):\n",
    "    \"\"\"\n",
    "    Swin UNETR based on: \"Hatamizadeh et al.,\n",
    "    Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images\n",
    "    <https://arxiv.org/abs/2201.01266>\"\n",
    "    \"\"\"\n",
    "\n",
    "    patch_size: Final[int] = 2\n",
    "\n",
    "    @deprecated_arg(\n",
    "        name=\"img_size\",\n",
    "        since=\"1.3\",\n",
    "        removed=\"1.5\",\n",
    "        msg_suffix=\"The img_size argument is not required anymore and \"\n",
    "        \"checks on the input size are run during forward().\",\n",
    "    )\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size: Sequence[int] | int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        depths: Sequence[int] = (2, 2, 2, 2),\n",
    "        num_heads: Sequence[int] = (3, 6, 12, 24),\n",
    "        feature_size: int = 24,\n",
    "        norm_name: tuple | str = \"instance\",\n",
    "        drop_rate: float = 0.0,\n",
    "        attn_drop_rate: float = 0.0,\n",
    "        dropout_path_rate: float = 0.0,\n",
    "        normalize: bool = True,\n",
    "        use_checkpoint: bool = False,\n",
    "        spatial_dims: int = 3,\n",
    "        downsample=\"merging\",\n",
    "        use_v2=False,\n",
    "        num_classes = 2\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_size: spatial dimension of input image.\n",
    "                This argument is only used for checking that the input image size is divisible by the patch size.\n",
    "                The tensor passed to forward() can have a dynamic shape as long as its spatial dimensions are divisible by 2**5.\n",
    "                It will be removed in an upcoming version.\n",
    "            in_channels: dimension of input channels.\n",
    "            out_channels: dimension of output channels.\n",
    "            feature_size: dimension of network feature size.\n",
    "            depths: number of layers in each stage.\n",
    "            num_heads: number of attention heads.\n",
    "            norm_name: feature normalization type and arguments.\n",
    "            drop_rate: dropout rate.\n",
    "            attn_drop_rate: attention dropout rate.\n",
    "            dropout_path_rate: drop path rate.\n",
    "            normalize: normalize output intermediate features in each stage.\n",
    "            use_checkpoint: use gradient checkpointing for reduced memory usage.\n",
    "            spatial_dims: number of spatial dims.\n",
    "            downsample: module used for downsampling, available options are `\"mergingv2\"`, `\"merging\"` and a\n",
    "                user-specified `nn.Module` following the API defined in :py:class:`monai.networks.nets.PatchMerging`.\n",
    "                The default is currently `\"merging\"` (the original version defined in v0.9.0).\n",
    "            use_v2: using swinunetr_v2, which adds a residual convolution block at the beggining of each swin stage.\n",
    "            num_class: number of classes for classification.\n",
    "        Examples::\n",
    "\n",
    "            # for 3D single channel input with size (96,96,96), 4-channel output and feature size of 48.\n",
    "            >>> net = SwinUNETR(img_size=(96,96,96), in_channels=1, out_channels=4, feature_size=48)\n",
    "\n",
    "            # for 3D 4-channel input with size (128,128,128), 3-channel output and (2,4,2,2) layers in each stage.\n",
    "            >>> net = SwinUNETR(img_size=(128,128,128), in_channels=4, out_channels=3, depths=(2,4,2,2))\n",
    "\n",
    "            # for 2D single channel input with size (96,96), 2-channel output and gradient checkpointing.\n",
    "            >>> net = SwinUNETR(img_size=(96,96), in_channels=3, out_channels=2, use_checkpoint=True, spatial_dims=2)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        img_size = ensure_tuple_rep(img_size, spatial_dims)\n",
    "        patch_sizes = ensure_tuple_rep(self.patch_size, spatial_dims)\n",
    "        window_size = ensure_tuple_rep(7, spatial_dims)\n",
    "        #print(patch_sizes,'666')\n",
    "\n",
    "\n",
    "        if spatial_dims not in (2, 3):\n",
    "            raise ValueError(\"spatial dimension should be 2 or 3.\")\n",
    "\n",
    "        self._check_input_size(img_size)\n",
    "\n",
    "        if not (0 <= drop_rate <= 1):\n",
    "            raise ValueError(\"dropout rate should be between 0 and 1.\")\n",
    "\n",
    "        if not (0 <= attn_drop_rate <= 1):\n",
    "            raise ValueError(\"attention dropout rate should be between 0 and 1.\")\n",
    "\n",
    "        if not (0 <= dropout_path_rate <= 1):\n",
    "            raise ValueError(\"drop path rate should be between 0 and 1.\")\n",
    "\n",
    "        if feature_size % 12 != 0:\n",
    "            raise ValueError(\"feature_size should be divisible by 12.\")\n",
    "\n",
    "        self.normalize = normalize\n",
    "        self.num_class = num_classes\n",
    "        self.final_feature_size = feature_size * 2 * 2 ** (len(depths) - 1)\n",
    "\n",
    "        self.swinViT = SwinTransformer(\n",
    "            in_chans=in_channels,\n",
    "            embed_dim=feature_size,\n",
    "            window_size=window_size,\n",
    "            patch_size=patch_sizes,\n",
    "            depths=depths,\n",
    "            num_heads=num_heads,\n",
    "            mlp_ratio=4.0,\n",
    "            qkv_bias=True,\n",
    "            drop_rate=drop_rate,\n",
    "            attn_drop_rate=attn_drop_rate,\n",
    "            drop_path_rate=dropout_path_rate,\n",
    "            norm_layer=nn.LayerNorm,\n",
    "            use_checkpoint=use_checkpoint,\n",
    "            spatial_dims=spatial_dims,\n",
    "            downsample=look_up_option(downsample, MERGING_MODE) if isinstance(downsample, str) else downsample,\n",
    "            use_v2=use_v2,\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.head = nn.Linear(self.final_feature_size, self.num_class)\n",
    "        \"\"\"\n",
    "        self.encoder1 = UnetrBasicBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=feature_size,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "\n",
    "        self.encoder2 = UnetrBasicBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=feature_size,\n",
    "            out_channels=feature_size,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "\n",
    "        self.encoder3 = UnetrBasicBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=2 * feature_size,\n",
    "            out_channels=2 * feature_size,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "\n",
    "        self.encoder4 = UnetrBasicBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=4 * feature_size,\n",
    "            out_channels=4 * feature_size,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "\n",
    "        self.encoder10 = UnetrBasicBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=16 * feature_size,\n",
    "            out_channels=16 * feature_size,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "\n",
    "        self.decoder5 = UnetrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=16 * feature_size,\n",
    "            out_channels=8 * feature_size,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "\n",
    "        self.decoder4 = UnetrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=feature_size * 8,\n",
    "            out_channels=feature_size * 4,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "\n",
    "        self.decoder3 = UnetrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=feature_size * 4,\n",
    "            out_channels=feature_size * 2,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "        self.decoder2 = UnetrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=feature_size * 2,\n",
    "            out_channels=feature_size,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "\n",
    "        self.decoder1 = UnetrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=feature_size,\n",
    "            out_channels=feature_size,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=True,\n",
    "        )\n",
    "\n",
    "        self.out = UnetOutBlock(spatial_dims=spatial_dims, in_channels=feature_size, out_channels=out_channels)\n",
    "        \"\"\"\n",
    "    def load_from(self, weights):\n",
    "        with torch.no_grad():\n",
    "            self.swinViT.patch_embed.proj.weight.copy_(weights[\"state_dict\"][\"module.patch_embed.proj.weight\"])\n",
    "            self.swinViT.patch_embed.proj.bias.copy_(weights[\"state_dict\"][\"module.patch_embed.proj.bias\"])\n",
    "            for bname, block in self.swinViT.layers1[0].blocks.named_children():\n",
    "                block.load_from(weights, n_block=bname, layer=\"layers1\")\n",
    "            self.swinViT.layers1[0].downsample.reduction.weight.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers1.0.downsample.reduction.weight\"]\n",
    "            )\n",
    "            self.swinViT.layers1[0].downsample.norm.weight.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers1.0.downsample.norm.weight\"]\n",
    "            )\n",
    "            self.swinViT.layers1[0].downsample.norm.bias.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers1.0.downsample.norm.bias\"]\n",
    "            )\n",
    "            for bname, block in self.swinViT.layers2[0].blocks.named_children():\n",
    "                block.load_from(weights, n_block=bname, layer=\"layers2\")\n",
    "            self.swinViT.layers2[0].downsample.reduction.weight.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers2.0.downsample.reduction.weight\"]\n",
    "            )\n",
    "            self.swinViT.layers2[0].downsample.norm.weight.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers2.0.downsample.norm.weight\"]\n",
    "            )\n",
    "            self.swinViT.layers2[0].downsample.norm.bias.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers2.0.downsample.norm.bias\"]\n",
    "            )\n",
    "            for bname, block in self.swinViT.layers3[0].blocks.named_children():\n",
    "                block.load_from(weights, n_block=bname, layer=\"layers3\")\n",
    "            self.swinViT.layers3[0].downsample.reduction.weight.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers3.0.downsample.reduction.weight\"]\n",
    "            )\n",
    "            self.swinViT.layers3[0].downsample.norm.weight.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers3.0.downsample.norm.weight\"]\n",
    "            )\n",
    "            self.swinViT.layers3[0].downsample.norm.bias.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers3.0.downsample.norm.bias\"]\n",
    "            )\n",
    "            for bname, block in self.swinViT.layers4[0].blocks.named_children():\n",
    "                block.load_from(weights, n_block=bname, layer=\"layers4\")\n",
    "            self.swinViT.layers4[0].downsample.reduction.weight.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers4.0.downsample.reduction.weight\"]\n",
    "            )\n",
    "            self.swinViT.layers4[0].downsample.norm.weight.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers4.0.downsample.norm.weight\"]\n",
    "            )\n",
    "            self.swinViT.layers4[0].downsample.norm.bias.copy_(\n",
    "                weights[\"state_dict\"][\"module.layers4.0.downsample.norm.bias\"]\n",
    "            )\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def _check_input_size(self, spatial_shape):\n",
    "        img_size = np.array(spatial_shape)\n",
    "        remainder = (img_size % np.power(self.patch_size, 5)) > 0\n",
    "        if remainder.any():\n",
    "            wrong_dims = (np.where(remainder)[0] + 2).tolist()\n",
    "            raise ValueError(\n",
    "                f\"spatial dimensions {wrong_dims} of input image (spatial shape: {spatial_shape})\"\n",
    "                f\" must be divisible by {self.patch_size}**5.\"\n",
    "            )\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        if not torch.jit.is_scripting():\n",
    "            self._check_input_size(x_in.shape[2:])\n",
    "        hidden_states_out = self.swinViT(x_in, self.normalize)\n",
    "        #print('hidden states out',hidden_states_out.shape)\n",
    "        \n",
    "        \"\"\"\n",
    "        enc0 = self.encoder1(x_in)\n",
    "        enc1 = self.encoder2(hidden_states_out[0])\n",
    "        enc2 = self.encoder3(hidden_states_out[1])\n",
    "        enc3 = self.encoder4(hidden_states_out[2])\n",
    "        dec4 = self.encoder10(hidden_states_out[4])\n",
    "        dec3 = self.decoder5(dec4, hidden_states_out[3])\n",
    "        dec2 = self.decoder4(dec3, enc3)\n",
    "        dec1 = self.decoder3(dec2, enc2)\n",
    "        dec0 = self.decoder2(dec1, enc1)\n",
    "        out = self.decoder1(dec0, enc0)\n",
    "        logits = self.out(out)\n",
    "        return logits\n",
    "        \"\"\"\n",
    "        x = self.avgpool(hidden_states_out)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    \"\"\"window partition operation based on: \"Liu et al.,\n",
    "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
    "    <https://arxiv.org/abs/2103.14030>\"\n",
    "    https://github.com/microsoft/Swin-Transformer\n",
    "\n",
    "     Args:\n",
    "        x: input tensor.\n",
    "        window_size: local window size.\n",
    "    \"\"\"\n",
    "    x_shape = x.size()\n",
    "    if len(x_shape) == 5:\n",
    "        b, d, h, w, c = x_shape\n",
    "        x = x.view(\n",
    "            b,\n",
    "            d // window_size[0],\n",
    "            window_size[0],\n",
    "            h // window_size[1],\n",
    "            window_size[1],\n",
    "            w // window_size[2],\n",
    "            window_size[2],\n",
    "            c,\n",
    "        )\n",
    "        windows = (\n",
    "            x.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous().view(-1, window_size[0] * window_size[1] * window_size[2], c)\n",
    "        )\n",
    "    elif len(x_shape) == 4:\n",
    "        b, h, w, c = x.shape\n",
    "        x = x.view(b, h // window_size[0], window_size[0], w // window_size[1], window_size[1], c)\n",
    "        windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size[0] * window_size[1], c)\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, dims):\n",
    "    \"\"\"window reverse operation based on: \"Liu et al.,\n",
    "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
    "    <https://arxiv.org/abs/2103.14030>\"\n",
    "    https://github.com/microsoft/Swin-Transformer\n",
    "\n",
    "     Args:\n",
    "        windows: windows tensor.\n",
    "        window_size: local window size.\n",
    "        dims: dimension values.\n",
    "    \"\"\"\n",
    "    if len(dims) == 4:\n",
    "        b, d, h, w = dims\n",
    "        x = windows.view(\n",
    "            b,\n",
    "            d // window_size[0],\n",
    "            h // window_size[1],\n",
    "            w // window_size[2],\n",
    "            window_size[0],\n",
    "            window_size[1],\n",
    "            window_size[2],\n",
    "            -1,\n",
    "        )\n",
    "        x = x.permute(0, 1, 4, 2, 5, 3, 6, 7).contiguous().view(b, d, h, w, -1)\n",
    "\n",
    "    elif len(dims) == 3:\n",
    "        b, h, w = dims\n",
    "        x = windows.view(b, h // window_size[0], w // window_size[1], window_size[0], window_size[1], -1)\n",
    "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(b, h, w, -1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_window_size(x_size, window_size, shift_size=None):\n",
    "    \"\"\"Computing window size based on: \"Liu et al.,\n",
    "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
    "    <https://arxiv.org/abs/2103.14030>\"\n",
    "    https://github.com/microsoft/Swin-Transformer\n",
    "\n",
    "     Args:\n",
    "        x_size: input size.\n",
    "        window_size: local window size.\n",
    "        shift_size: window shifting size.\n",
    "    \"\"\"\n",
    "\n",
    "    use_window_size = list(window_size)\n",
    "    if shift_size is not None:\n",
    "        use_shift_size = list(shift_size)\n",
    "    for i in range(len(x_size)):\n",
    "        if x_size[i] <= window_size[i]:\n",
    "            use_window_size[i] = x_size[i]\n",
    "            if shift_size is not None:\n",
    "                use_shift_size[i] = 0\n",
    "\n",
    "    if shift_size is None:\n",
    "        return tuple(use_window_size)\n",
    "    else:\n",
    "        return tuple(use_window_size), tuple(use_shift_size)\n",
    "\n",
    "\n",
    "class WindowAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Window based multi-head self attention module with relative position bias based on: \"Liu et al.,\n",
    "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
    "    <https://arxiv.org/abs/2103.14030>\"\n",
    "    https://github.com/microsoft/Swin-Transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_heads: int,\n",
    "        window_size: Sequence[int],\n",
    "        qkv_bias: bool = False,\n",
    "        attn_drop: float = 0.0,\n",
    "        proj_drop: float = 0.0,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: number of feature channels.\n",
    "            num_heads: number of attention heads.\n",
    "            window_size: local window size.\n",
    "            qkv_bias: add a learnable bias to query, key, value.\n",
    "            attn_drop: attention dropout rate.\n",
    "            proj_drop: dropout rate of output.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim**-0.5\n",
    "        mesh_args = torch.meshgrid.__kwdefaults__\n",
    "\n",
    "        if len(self.window_size) == 3:\n",
    "            self.relative_position_bias_table = nn.Parameter(\n",
    "                torch.zeros(\n",
    "                    (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1) * (2 * self.window_size[2] - 1),\n",
    "                    num_heads,\n",
    "                )\n",
    "            )\n",
    "            coords_d = torch.arange(self.window_size[0])\n",
    "            coords_h = torch.arange(self.window_size[1])\n",
    "            coords_w = torch.arange(self.window_size[2])\n",
    "            if mesh_args is not None:\n",
    "                coords = torch.stack(torch.meshgrid(coords_d, coords_h, coords_w, indexing=\"ij\"))\n",
    "            else:\n",
    "                coords = torch.stack(torch.meshgrid(coords_d, coords_h, coords_w))\n",
    "            coords_flatten = torch.flatten(coords, 1)\n",
    "            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "            relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "            relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "            relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "            relative_coords[:, :, 2] += self.window_size[2] - 1\n",
    "            relative_coords[:, :, 0] *= (2 * self.window_size[1] - 1) * (2 * self.window_size[2] - 1)\n",
    "            relative_coords[:, :, 1] *= 2 * self.window_size[2] - 1\n",
    "        elif len(self.window_size) == 2:\n",
    "            self.relative_position_bias_table = nn.Parameter(\n",
    "                torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads)\n",
    "            )\n",
    "            coords_h = torch.arange(self.window_size[0])\n",
    "            coords_w = torch.arange(self.window_size[1])\n",
    "            if mesh_args is not None:\n",
    "                coords = torch.stack(torch.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
    "            else:\n",
    "                coords = torch.stack(torch.meshgrid(coords_h, coords_w))\n",
    "            coords_flatten = torch.flatten(coords, 1)\n",
    "            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "            relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "            relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "            relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "            relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        trunc_normal_(self.relative_position_bias_table, std=0.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        b, n, c = x.shape\n",
    "        qkv = self.qkv(x).reshape(b, n, 3, self.num_heads, c // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        q = q * self.scale\n",
    "        attn = q @ k.transpose(-2, -1)\n",
    "        relative_position_bias = self.relative_position_bias_table[\n",
    "            self.relative_position_index.clone()[:n, :n].reshape(-1)\n",
    "        ].reshape(n, n, -1)\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "        if mask is not None:\n",
    "            nw = mask.shape[0]\n",
    "            attn = attn.view(b // nw, nw, self.num_heads, n, n) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, n, n)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn).to(v.dtype)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(b, n, c)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SwinTransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Swin Transformer block based on: \"Liu et al.,\n",
    "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
    "    <https://arxiv.org/abs/2103.14030>\"\n",
    "    https://github.com/microsoft/Swin-Transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_heads: int,\n",
    "        window_size: Sequence[int],\n",
    "        shift_size: Sequence[int],\n",
    "        mlp_ratio: float = 4.0,\n",
    "        qkv_bias: bool = True,\n",
    "        drop: float = 0.0,\n",
    "        attn_drop: float = 0.0,\n",
    "        drop_path: float = 0.0,\n",
    "        act_layer: str = \"GELU\",\n",
    "        norm_layer: type[LayerNorm] = nn.LayerNorm,\n",
    "        use_checkpoint: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: number of feature channels.\n",
    "            num_heads: number of attention heads.\n",
    "            window_size: local window size.\n",
    "            shift_size: window shift size.\n",
    "            mlp_ratio: ratio of mlp hidden dim to embedding dim.\n",
    "            qkv_bias: add a learnable bias to query, key, value.\n",
    "            drop: dropout rate.\n",
    "            attn_drop: attention dropout rate.\n",
    "            drop_path: stochastic depth rate.\n",
    "            act_layer: activation layer.\n",
    "            norm_layer: normalization layer.\n",
    "            use_checkpoint: use gradient checkpointing for reduced memory usage.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim,\n",
    "            window_size=self.window_size,\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            attn_drop=attn_drop,\n",
    "            proj_drop=drop,\n",
    "        )\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(hidden_size=dim, mlp_dim=mlp_hidden_dim, act=act_layer, dropout_rate=drop, dropout_mode=\"swin\")\n",
    "\n",
    "    def forward_part1(self, x, mask_matrix):\n",
    "        x_shape = x.size()\n",
    "        x = self.norm1(x)\n",
    "        if len(x_shape) == 5:\n",
    "            b, d, h, w, c = x.shape\n",
    "            window_size, shift_size = get_window_size((d, h, w), self.window_size, self.shift_size)\n",
    "            pad_l = pad_t = pad_d0 = 0\n",
    "            pad_d1 = (window_size[0] - d % window_size[0]) % window_size[0]\n",
    "            pad_b = (window_size[1] - h % window_size[1]) % window_size[1]\n",
    "            pad_r = (window_size[2] - w % window_size[2]) % window_size[2]\n",
    "            x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b, pad_d0, pad_d1))\n",
    "            _, dp, hp, wp, _ = x.shape\n",
    "            dims = [b, dp, hp, wp]\n",
    "\n",
    "        elif len(x_shape) == 4:\n",
    "            b, h, w, c = x.shape\n",
    "            window_size, shift_size = get_window_size((h, w), self.window_size, self.shift_size)\n",
    "            pad_l = pad_t = 0\n",
    "            pad_b = (window_size[0] - h % window_size[0]) % window_size[0]\n",
    "            pad_r = (window_size[1] - w % window_size[1]) % window_size[1]\n",
    "            x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b))\n",
    "            _, hp, wp, _ = x.shape\n",
    "            dims = [b, hp, wp]\n",
    "\n",
    "        if any(i > 0 for i in shift_size):\n",
    "            if len(x_shape) == 5:\n",
    "                shifted_x = torch.roll(x, shifts=(-shift_size[0], -shift_size[1], -shift_size[2]), dims=(1, 2, 3))\n",
    "            elif len(x_shape) == 4:\n",
    "                shifted_x = torch.roll(x, shifts=(-shift_size[0], -shift_size[1]), dims=(1, 2))\n",
    "            attn_mask = mask_matrix\n",
    "        else:\n",
    "            shifted_x = x\n",
    "            attn_mask = None\n",
    "        x_windows = window_partition(shifted_x, window_size)\n",
    "        attn_windows = self.attn(x_windows, mask=attn_mask)\n",
    "        attn_windows = attn_windows.view(-1, *(window_size + (c,)))\n",
    "        shifted_x = window_reverse(attn_windows, window_size, dims)\n",
    "        if any(i > 0 for i in shift_size):\n",
    "            if len(x_shape) == 5:\n",
    "                x = torch.roll(shifted_x, shifts=(shift_size[0], shift_size[1], shift_size[2]), dims=(1, 2, 3))\n",
    "            elif len(x_shape) == 4:\n",
    "                x = torch.roll(shifted_x, shifts=(shift_size[0], shift_size[1]), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        if len(x_shape) == 5:\n",
    "            if pad_d1 > 0 or pad_r > 0 or pad_b > 0:\n",
    "                x = x[:, :d, :h, :w, :].contiguous()\n",
    "        elif len(x_shape) == 4:\n",
    "            if pad_r > 0 or pad_b > 0:\n",
    "                x = x[:, :h, :w, :].contiguous()\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_part2(self, x):\n",
    "        print(\"all < 0\",torch.all(self.norm2(x)<0))\n",
    "        return self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "    def load_from(self, weights, n_block, layer):\n",
    "        root = f\"module.{layer}.0.blocks.{n_block}.\"\n",
    "        block_names = [\n",
    "            \"norm1.weight\",\n",
    "            \"norm1.bias\",\n",
    "            \"attn.relative_position_bias_table\",\n",
    "            \"attn.relative_position_index\",\n",
    "            \"attn.qkv.weight\",\n",
    "            \"attn.qkv.bias\",\n",
    "            \"attn.proj.weight\",\n",
    "            \"attn.proj.bias\",\n",
    "            \"norm2.weight\",\n",
    "            \"norm2.bias\",\n",
    "            \"mlp.fc1.weight\",\n",
    "            \"mlp.fc1.bias\",\n",
    "            \"mlp.fc2.weight\",\n",
    "            \"mlp.fc2.bias\",\n",
    "        ]\n",
    "        with torch.no_grad():\n",
    "            self.norm1.weight.copy_(weights[\"state_dict\"][root + block_names[0]])\n",
    "            self.norm1.bias.copy_(weights[\"state_dict\"][root + block_names[1]])\n",
    "            self.attn.relative_position_bias_table.copy_(weights[\"state_dict\"][root + block_names[2]])\n",
    "            self.attn.relative_position_index.copy_(weights[\"state_dict\"][root + block_names[3]])\n",
    "            self.attn.qkv.weight.copy_(weights[\"state_dict\"][root + block_names[4]])\n",
    "            self.attn.qkv.bias.copy_(weights[\"state_dict\"][root + block_names[5]])\n",
    "            self.attn.proj.weight.copy_(weights[\"state_dict\"][root + block_names[6]])\n",
    "            self.attn.proj.bias.copy_(weights[\"state_dict\"][root + block_names[7]])\n",
    "            self.norm2.weight.copy_(weights[\"state_dict\"][root + block_names[8]])\n",
    "            self.norm2.bias.copy_(weights[\"state_dict\"][root + block_names[9]])\n",
    "            self.mlp.linear1.weight.copy_(weights[\"state_dict\"][root + block_names[10]])\n",
    "            self.mlp.linear1.bias.copy_(weights[\"state_dict\"][root + block_names[11]])\n",
    "            self.mlp.linear2.weight.copy_(weights[\"state_dict\"][root + block_names[12]])\n",
    "            self.mlp.linear2.bias.copy_(weights[\"state_dict\"][root + block_names[13]])\n",
    "\n",
    "    def forward(self, x, mask_matrix):\n",
    "        shortcut = x\n",
    "        if self.use_checkpoint:\n",
    "            x = checkpoint.checkpoint(self.forward_part1, x, mask_matrix, use_reentrant=False)\n",
    "        else:\n",
    "            x = self.forward_part1(x, mask_matrix)\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        if self.use_checkpoint:\n",
    "            x = x + checkpoint.checkpoint(self.forward_part2, x, use_reentrant=False)\n",
    "        else:\n",
    "            x = x + self.forward_part2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchMergingV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Patch merging layer based on: \"Liu et al.,\n",
    "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
    "    <https://arxiv.org/abs/2103.14030>\"\n",
    "    https://github.com/microsoft/Swin-Transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int, norm_layer: type[LayerNorm] = nn.LayerNorm, spatial_dims: int = 3) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: number of feature channels.\n",
    "            norm_layer: normalization layer.\n",
    "            spatial_dims: number of spatial dims.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        if spatial_dims == 3:\n",
    "            self.reduction = nn.Linear(8 * dim, 2 * dim, bias=False)\n",
    "            self.norm = norm_layer(8 * dim)\n",
    "        elif spatial_dims == 2:\n",
    "            self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
    "            self.norm = norm_layer(4 * dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_shape = x.size()\n",
    "        if len(x_shape) == 5:\n",
    "            b, d, h, w, c = x_shape\n",
    "            pad_input = (h % 2 == 1) or (w % 2 == 1) or (d % 2 == 1)\n",
    "            if pad_input:\n",
    "                x = F.pad(x, (0, 0, 0, w % 2, 0, h % 2, 0, d % 2))\n",
    "            x = torch.cat(\n",
    "                [x[:, i::2, j::2, k::2, :] for i, j, k in itertools.product(range(2), range(2), range(2))], -1\n",
    "            )\n",
    "\n",
    "        elif len(x_shape) == 4:\n",
    "            b, h, w, c = x_shape\n",
    "            pad_input = (h % 2 == 1) or (w % 2 == 1)\n",
    "            if pad_input:\n",
    "                x = F.pad(x, (0, 0, 0, w % 2, 0, h % 2))\n",
    "            x = torch.cat([x[:, j::2, i::2, :] for i, j in itertools.product(range(2), range(2))], -1)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchMerging(PatchMergingV2):\n",
    "    \"\"\"The `PatchMerging` module previously defined in v0.9.0.\"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_shape = x.size()\n",
    "        if len(x_shape) == 4:\n",
    "            return super().forward(x)\n",
    "        if len(x_shape) != 5:\n",
    "            raise ValueError(f\"expecting 5D x, got {x.shape}.\")\n",
    "        b, d, h, w, c = x_shape\n",
    "        pad_input = (h % 2 == 1) or (w % 2 == 1) or (d % 2 == 1)\n",
    "        if pad_input:\n",
    "            x = F.pad(x, (0, 0, 0, w % 2, 0, h % 2, 0, d % 2))\n",
    "        x0 = x[:, 0::2, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, 0::2, :]\n",
    "        x3 = x[:, 0::2, 0::2, 1::2, :]\n",
    "        x4 = x[:, 1::2, 0::2, 1::2, :]\n",
    "        x5 = x[:, 0::2, 1::2, 0::2, :]\n",
    "        x6 = x[:, 0::2, 0::2, 1::2, :]\n",
    "        x7 = x[:, 1::2, 1::2, 1::2, :]\n",
    "        x = torch.cat([x0, x1, x2, x3, x4, x5, x6, x7], -1)\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "MERGING_MODE = {\"merging\": PatchMerging, \"mergingv2\": PatchMergingV2}\n",
    "\n",
    "\n",
    "def compute_mask(dims, window_size, shift_size, device):\n",
    "    \"\"\"Computing region masks based on: \"Liu et al.,\n",
    "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
    "    <https://arxiv.org/abs/2103.14030>\"\n",
    "    https://github.com/microsoft/Swin-Transformer\n",
    "\n",
    "     Args:\n",
    "        dims: dimension values.\n",
    "        window_size: local window size.\n",
    "        shift_size: shift size.\n",
    "        device: device.\n",
    "    \"\"\"\n",
    "\n",
    "    cnt = 0\n",
    "\n",
    "    if len(dims) == 3:\n",
    "        d, h, w = dims\n",
    "        #print('fucking dhw',d,h,w)\n",
    "        img_mask = torch.zeros((1, d, h, w, 1), device=device)\n",
    "        for d in slice(-window_size[0]), slice(-window_size[0], -shift_size[0]), slice(-shift_size[0], None):\n",
    "            for h in slice(-window_size[1]), slice(-window_size[1], -shift_size[1]), slice(-shift_size[1], None):\n",
    "                for w in slice(-window_size[2]), slice(-window_size[2], -shift_size[2]), slice(-shift_size[2], None):\n",
    "                    img_mask[:, d, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "\n",
    "    elif len(dims) == 2:\n",
    "        h, w = dims\n",
    "        img_mask = torch.zeros((1, h, w, 1), device=device)\n",
    "        for h in slice(-window_size[0]), slice(-window_size[0], -shift_size[0]), slice(-shift_size[0], None):\n",
    "            for w in slice(-window_size[1]), slice(-window_size[1], -shift_size[1]), slice(-shift_size[1], None):\n",
    "                img_mask[:, h, w, :] = cnt\n",
    "                cnt += 1\n",
    "\n",
    "    mask_windows = window_partition(img_mask, window_size)\n",
    "    mask_windows = mask_windows.squeeze(-1)\n",
    "    attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "    attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "    return attn_mask\n",
    "\n",
    "\n",
    "class BasicLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic Swin Transformer layer in one stage based on: \"Liu et al.,\n",
    "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
    "    <https://arxiv.org/abs/2103.14030>\"\n",
    "    https://github.com/microsoft/Swin-Transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        depth: int,\n",
    "        num_heads: int,\n",
    "        window_size: Sequence[int],\n",
    "        drop_path: list,\n",
    "        mlp_ratio: float = 4.0,\n",
    "        qkv_bias: bool = False,\n",
    "        drop: float = 0.0,\n",
    "        attn_drop: float = 0.0,\n",
    "        norm_layer: type[LayerNorm] = nn.LayerNorm,\n",
    "        downsample: nn.Module | None = None,\n",
    "        use_checkpoint: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: number of feature channels.\n",
    "            depth: number of layers in each stage.\n",
    "            num_heads: number of attention heads.\n",
    "            window_size: local window size.\n",
    "            drop_path: stochastic depth rate.\n",
    "            mlp_ratio: ratio of mlp hidden dim to embedding dim.\n",
    "            qkv_bias: add a learnable bias to query, key, value.\n",
    "            drop: dropout rate.\n",
    "            attn_drop: attention dropout rate.\n",
    "            norm_layer: normalization layer.\n",
    "            downsample: an optional downsampling layer at the end of the layer.\n",
    "            use_checkpoint: use gradient checkpointing for reduced memory usage.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        #就是除以windowsize,比如56X56 shiftsize就是3X3,因为windowssize 是7X7\n",
    "        self.shift_size = tuple(i // 2 for i in window_size)\n",
    "        self.no_shift = tuple(0 for i in window_size)\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                SwinTransformerBlock(\n",
    "                    dim=dim,\n",
    "                    num_heads=num_heads,\n",
    "                    window_size=self.window_size,\n",
    "                    shift_size=self.no_shift if (i % 2 == 0) else self.shift_size,\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    drop=drop,\n",
    "                    attn_drop=attn_drop,\n",
    "                    drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                    norm_layer=norm_layer,\n",
    "                    use_checkpoint=use_checkpoint,\n",
    "                )\n",
    "                for i in range(depth)\n",
    "            ]\n",
    "        )\n",
    "        #就是patch merging\n",
    "        self.downsample = downsample\n",
    "        if callable(self.downsample):\n",
    "            self.downsample = downsample(dim=dim, norm_layer=norm_layer, spatial_dims=len(self.window_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_shape = x.size()\n",
    "        if len(x_shape) == 5:\n",
    "            b, c, d, h, w = x_shape\n",
    "            window_size, shift_size = get_window_size((d, h, w), self.window_size, self.shift_size)\n",
    "            x = rearrange(x, \"b c d h w -> b d h w c\")\n",
    "            dp = int(np.ceil(d / window_size[0])) * window_size[0]\n",
    "            hp = int(np.ceil(h / window_size[1])) * window_size[1]\n",
    "            wp = int(np.ceil(w / window_size[2])) * window_size[2]\n",
    "            attn_mask = compute_mask([dp, hp, wp], window_size, shift_size, x.device)\n",
    "            for blk in self.blocks:\n",
    "                x = blk(x, attn_mask)\n",
    "            x = x.view(b, d, h, w, -1)\n",
    "            if self.downsample is not None:\n",
    "                x = self.downsample(x)\n",
    "            x = rearrange(x, \"b d h w c -> b c d h w\")\n",
    "\n",
    "        elif len(x_shape) == 4:\n",
    "            b, c, h, w = x_shape\n",
    "            window_size, shift_size = get_window_size((h, w), self.window_size, self.shift_size)\n",
    "            x = rearrange(x, \"b c h w -> b h w c\")\n",
    "            hp = int(np.ceil(h / window_size[0])) * window_size[0]\n",
    "            wp = int(np.ceil(w / window_size[1])) * window_size[1]\n",
    "            attn_mask = compute_mask([hp, wp], window_size, shift_size, x.device)\n",
    "            for blk in self.blocks:\n",
    "                x = blk(x, attn_mask)\n",
    "            x = x.view(b, h, w, -1)\n",
    "            if self.downsample is not None:\n",
    "                x = self.downsample(x)\n",
    "            x = rearrange(x, \"b h w c -> b c h w\")\n",
    "        return x\n",
    "\n",
    "\n",
    "class SwinTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Swin Transformer based on: \"Liu et al.,\n",
    "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
    "    <https://arxiv.org/abs/2103.14030>\"\n",
    "    https://github.com/microsoft/Swin-Transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chans: int,\n",
    "        embed_dim: int,\n",
    "        window_size: Sequence[int],\n",
    "        patch_size: Sequence[int],\n",
    "        depths: Sequence[int],\n",
    "        num_heads: Sequence[int],\n",
    "        mlp_ratio: float = 4.0,\n",
    "        qkv_bias: bool = True,\n",
    "        drop_rate: float = 0.0,\n",
    "        attn_drop_rate: float = 0.0,\n",
    "        drop_path_rate: float = 0.0,\n",
    "        norm_layer: type[LayerNorm] = nn.LayerNorm,\n",
    "        patch_norm: bool = False,\n",
    "        use_checkpoint: bool = False,\n",
    "        spatial_dims: int = 3,\n",
    "        downsample=\"merging\",\n",
    "        use_v2=False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans: dimension of input channels.\n",
    "            embed_dim: number of linear projection output channels.\n",
    "            window_size: local window size.\n",
    "            patch_size: patch size.\n",
    "            depths: number of layers in each stage.\n",
    "            num_heads: number of attention heads.\n",
    "            mlp_ratio: ratio of mlp hidden dim to embedding dim.\n",
    "            qkv_bias: add a learnable bias to query, key, value.\n",
    "            drop_rate: dropout rate.\n",
    "            attn_drop_rate: attention dropout rate.\n",
    "            drop_path_rate: stochastic depth rate.\n",
    "            norm_layer: normalization layer.\n",
    "            patch_norm: add normalization after patch embedding.\n",
    "            use_checkpoint: use gradient checkpointing for reduced memory usage.\n",
    "            spatial_dims: spatial dimension.\n",
    "            downsample: module used for downsampling, available options are `\"mergingv2\"`, `\"merging\"` and a\n",
    "                user-specified `nn.Module` following the API defined in :py:class:`monai.networks.nets.PatchMerging`.\n",
    "                The default is currently `\"merging\"` (the original version defined in v0.9.0).\n",
    "            use_v2: using swinunetr_v2, which adds a residual convolution block at the beginning of each swin stage.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_norm = patch_norm\n",
    "        self.window_size = window_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            patch_size=self.patch_size,\n",
    "            in_chans=in_chans,\n",
    "            embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer if self.patch_norm else None,  # type: ignore\n",
    "            spatial_dims=spatial_dims,\n",
    "        )\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        self.use_v2 = use_v2\n",
    "        self.layers1 = nn.ModuleList()\n",
    "        self.layers2 = nn.ModuleList()\n",
    "        self.layers3 = nn.ModuleList()\n",
    "        self.layers4 = nn.ModuleList()\n",
    "        if self.use_v2:\n",
    "            self.layers1c = nn.ModuleList()\n",
    "            self.layers2c = nn.ModuleList()\n",
    "            self.layers3c = nn.ModuleList()\n",
    "            self.layers4c = nn.ModuleList()\n",
    "        down_sample_mod = look_up_option(downsample, MERGING_MODE) if isinstance(downsample, str) else downsample\n",
    "        for i_layer in range(self.num_layers):\n",
    "            layer = BasicLayer(\n",
    "                dim=int(embed_dim * 2**i_layer),\n",
    "                depth=depths[i_layer],\n",
    "                num_heads=num_heads[i_layer],\n",
    "                window_size=self.window_size,\n",
    "                drop_path=dpr[sum(depths[:i_layer]) : sum(depths[: i_layer + 1])],\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                norm_layer=norm_layer,\n",
    "                downsample=down_sample_mod,\n",
    "                use_checkpoint=use_checkpoint,\n",
    "            )\n",
    "            if i_layer == 0:\n",
    "                self.layers1.append(layer)\n",
    "            elif i_layer == 1:\n",
    "                self.layers2.append(layer)\n",
    "            elif i_layer == 2:\n",
    "                self.layers3.append(layer)\n",
    "            elif i_layer == 3:\n",
    "                self.layers4.append(layer)\n",
    "            if self.use_v2:\n",
    "                layerc = UnetrBasicBlock(\n",
    "                    spatial_dims=3,\n",
    "                    in_channels=embed_dim * 2**i_layer,\n",
    "                    out_channels=embed_dim * 2**i_layer,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    norm_name=\"instance\",\n",
    "                    res_block=True,\n",
    "                )\n",
    "                if i_layer == 0:\n",
    "                    self.layers1c.append(layerc)\n",
    "                elif i_layer == 1:\n",
    "                    self.layers2c.append(layerc)\n",
    "                elif i_layer == 2:\n",
    "                    self.layers3c.append(layerc)\n",
    "                elif i_layer == 3:\n",
    "                    self.layers4c.append(layerc)\n",
    "        #这里的number features跟层数有关系！比如说4层的话，最后的number features就是embed_dim * 2 ** 3\n",
    "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
    "\n",
    "    def proj_out(self, x, normalize=False):\n",
    "        if normalize:\n",
    "            x_shape = x.size()\n",
    "            if len(x_shape) == 5:\n",
    "\n",
    "                n, ch, d, h, w = x_shape\n",
    "                x = rearrange(x, \"n c d h w -> n d h w c\")\n",
    "                x = F.layer_norm(x, [ch])\n",
    "                x = rearrange(x, \"n d h w c -> n c d h w\")\n",
    "            elif len(x_shape) == 4:\n",
    "                n, ch, h, w = x_shape\n",
    "                x = rearrange(x, \"n c h w -> n h w c\")\n",
    "                x = F.layer_norm(x, [ch])\n",
    "                x = rearrange(x, \"n h w c -> n c h w\")\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, normalize=True):\n",
    "        #print(x.shape,'this is x shape')\n",
    "        x0 = self.patch_embed(x)\n",
    "        #print(x0.shape,'after embed')\n",
    "        x0 = self.pos_drop(x0)\n",
    "        #print(x0.shape,'this is x0 shape')\n",
    "        x0_out = self.proj_out(x0, normalize)\n",
    "        if self.use_v2:\n",
    "            x0 = self.layers1c[0](x0.contiguous())\n",
    "        x1 = self.layers1[0](x0.contiguous())\n",
    "        print(x1.shape,'this is x1 shape')\n",
    "        x1_out = self.proj_out(x1, normalize)\n",
    "        if self.use_v2:\n",
    "            x1 = self.layers2c[0](x1.contiguous())\n",
    "        x2 = self.layers2[0](x1.contiguous())\n",
    "        x2_out = self.proj_out(x2, normalize)\n",
    "        #print(x2.shape,'this is x2 shape')\n",
    "        if self.use_v2:\n",
    "            x2 = self.layers3c[0](x2.contiguous())\n",
    "        x3 = self.layers3[0](x2.contiguous())\n",
    "        x3_out = self.proj_out(x3, normalize)\n",
    "        if self.use_v2:\n",
    "            x3 = self.layers4c[0](x3.contiguous())\n",
    "        x4 = self.layers4[0](x3.contiguous())\n",
    "        x4_out = self.proj_out(x4, normalize)\n",
    "        #return [x0_out, x1_out, x2_out, x3_out, x4_out]\n",
    "        return x4_out\n",
    "\n",
    "\n",
    "def filter_swinunetr(key, value):\n",
    "    \"\"\"\n",
    "    A filter function used to filter the pretrained weights from [1], then the weights can be loaded into MONAI SwinUNETR Model.\n",
    "    This function is typically used with `monai.networks.copy_model_state`\n",
    "    [1] \"Valanarasu JM et al., Disruptive Autoencoders: Leveraging Low-level features for 3D Medical Image Pre-training\n",
    "    <https://arxiv.org/abs/2307.16896>\"\n",
    "\n",
    "    Args:\n",
    "        key: the key in the source state dict used for the update.\n",
    "        value: the value in the source state dict used for the update.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        import torch\n",
    "        from monai.apps import download_url\n",
    "        from monai.networks.utils import copy_model_state\n",
    "        from monai.networks.nets.swin_unetr import SwinUNETR, filter_swinunetr\n",
    "\n",
    "        model = SwinUNETR(img_size=(96, 96, 96), in_channels=1, out_channels=3, feature_size=48)\n",
    "        resource = (\n",
    "            \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/ssl_pretrained_weights.pth\"\n",
    "        )\n",
    "        ssl_weights_path = \"./ssl_pretrained_weights.pth\"\n",
    "        download_url(resource, ssl_weights_path)\n",
    "        ssl_weights = torch.load(ssl_weights_path)[\"model\"]\n",
    "\n",
    "        dst_dict, loaded, not_loaded = copy_model_state(model, ssl_weights, filter_func=filter_swinunetr)\n",
    "\n",
    "    \"\"\"\n",
    "    if key in [\n",
    "        \"encoder.mask_token\",\n",
    "        \"encoder.norm.weight\",\n",
    "        \"encoder.norm.bias\",\n",
    "        \"out.conv.conv.weight\",\n",
    "        \"out.conv.conv.bias\",\n",
    "    ]:\n",
    "        return None\n",
    "\n",
    "    if key[:8] == \"encoder.\":\n",
    "        if key[8:19] == \"patch_embed\":\n",
    "            new_key = \"swinViT.\" + key[8:]\n",
    "        else:\n",
    "            new_key = \"swinViT.\" + key[8:18] + key[20:]\n",
    "\n",
    "        return new_key, value\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CILM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
