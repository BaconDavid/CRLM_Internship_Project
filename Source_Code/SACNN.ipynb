{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 32, 64, 128] shit\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 3, 7, 7, 7], expected input[1, 1, 64, 64, 64] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m rand_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m      2\u001b[0m SACNN_model \u001b[38;5;241m=\u001b[39m ResNet(ResNetBlock, [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m], get_inplanes(),spatial_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mSACNN_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrand_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[5], line 428\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 428\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    430\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\nn\\modules\\conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\nn\\modules\\conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[0;32m    598\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    599\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    607\u001b[0m     )\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 3, 7, 7, 7], expected input[1, 1, 64, 64, 64] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "rand_data = torch.rand(1,1,10,64,64)\n",
    "SACNN_model = ResNet(ResNetBlock, [2, 2, 2, 2], get_inplanes(),spatial_dims=3)\n",
    "SACNN_model(rand_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Self-Attention Block\n",
    "##***********************************************************************************************************\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "class SA(nn.Module):\n",
    "    \"\"\"\n",
    "    input:N*C*H*W*D\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, N):\n",
    "        super().__init__()\n",
    "        self.N = N \n",
    "        self.C = in_ch\n",
    "        self.D = 8\n",
    "        self.H = 64\n",
    "        self.W = 64\n",
    "        self.gama = nn.Parameter(torch.tensor([0.0]))\n",
    "\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        \n",
    "        self.conv3d_3 = nn.Sequential(\n",
    "            # Conv3d input:N*C*D*H*W\n",
    "            # Conv3d output:N*C*D*H*W\n",
    "            nn.Conv3d(in_channels=self.in_ch, out_channels=self.out_ch, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.BatchNorm3d(self.out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv3d_1 = nn.Sequential(\n",
    "            # Conv3d input:N*C*D*H*W\n",
    "            # Conv3d output:N*C*D*H*W\n",
    "            nn.Conv3d(in_channels=self.in_ch, out_channels=self.out_ch, kernel_size=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(self.out_ch),\n",
    "            nn.ReLU(inplace=True), \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def Cal_Patt(self,k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input:N*C*H*W*D\n",
    "        origin_input : N*C*D*H*W\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "       # k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "       # q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "       # v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        # k_x_flatten = k_x.view((N, C, D, 1, H * W))\n",
    "        # q_x_flatten = q_x.view((N, C, D, 1, H * W))\n",
    "        # v_x_flatten = v_x.view((N, C, D, 1, H * W))\n",
    "        with torch.no_grad():\n",
    "            k_x = k_x.view((N, C, D, 1, H * W))\n",
    "            q_x = q_x.view((N, C, D, 1, H * W))\n",
    "            v_x = v_x.view((N, C, D, 1, H * W))\n",
    "            sigma_x = torch.mul(q_x.permute(0, 1, 2, 4, 3), k_x)\n",
    "            r_x = F.softmax(sigma_x, dim=4)\n",
    "            # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "            Patt = torch.matmul(v_x, r_x).reshape(N, C, D, H, W)\n",
    "        return Patt\n",
    "\n",
    "    \n",
    "\n",
    "    def Cal_Datt(self,k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input:N*C*H*W*D\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "        #k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "        #q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "        #v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        # k_x_flatten = k_x.permute(0, 1, 3, 4, 2).view((N, C, H, W, 1, D))\n",
    "        # q_x_flatten = q_x.permute(0, 1, 3, 4, 2).view((N, C, H, W, 1, D))\n",
    "        # v_x_flatten = v_x.permute(0, 1, 3, 4, 2).view((N, C, H, W, 1, D))\n",
    "        with torch.no_grad():\n",
    "            k_x = k_x.permute(0, 1, 3, 4, 2).view((N, C, H, W, 1, D))\n",
    "            q_x = q_x.permute(0, 1, 3, 4, 2).view((N, C, H, W, 1, D))\n",
    "            v_x = v_x.permute(0, 1, 3, 4, 2).view((N, C, H, W, 1, D))\n",
    "            #print(k_x_flatten.shape,'this is k_x_flatten shape')\n",
    "            #print(q_x_flatten.permute(0, 1, 2, 3, 5, 4).shape,'this is q_x_flatten shape')\n",
    "            sigma_x = torch.mul(q_x.permute(0, 1, 2, 3, 5, 4), k_x)\n",
    "            print(sigma_x.shape,'this is sigma_x shape')\n",
    "            r_x = F.softmax(sigma_x, dim=5)\n",
    "            # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "            Datt = torch.matmul(v_x, r_x).reshape(N, C, H, W, D)\n",
    "        return Datt.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        v_x = self.conv3d_3(x)\n",
    "        k_x = self.conv3d_1(x)\n",
    "        q_x = self.conv3d_1(x)\n",
    "        \n",
    "        Patt = self.Cal_Patt(k_x, q_x, v_x, self.N, self.C, self.D, self.H, self.W)\n",
    "        #Datt = self.Cal_Datt(k_x, q_x, v_x, self.N, self.C, self.D, self.H, self.W)\n",
    "        \n",
    "        #Y = self.gama*(Patt + Datt) + x\n",
    "        return v_x,k_x,q_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cal_Datt(k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input:N*C*H*W*D\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "        #k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "        #q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "        #v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        k_x_flatten = k_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        q_x_flatten = q_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        v_x_flatten = v_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        print(k_x_flatten.shape,'this is k_x_flatten shape')\n",
    "        print(q_x_flatten.permute(0, 1, 2, 3, 5, 4).shape,'this is q_x_flatten shape')\n",
    "        sigma_x = torch.mul(q_x_flatten.permute(0, 1, 2, 3, 5, 4), k_x_flatten)\n",
    "        print(sigma_x.shape,'this is sigma_x shape')\n",
    "        r_x = F.softmax(sigma_x, dim=5)\n",
    "        # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "        Datt = torch.matmul(v_x_flatten, r_x).reshape(N, C, H, W, D)\n",
    "        return Datt.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "def Cal_Patt(k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input:N*C*H*W*D\n",
    "        origin_input : N*C*D*H*W\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "       # k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "       # q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "       # v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        k_x_flatten = k_x.reshape((N, C, D, 1, H * W))\n",
    "        q_x_flatten = q_x.reshape((N, C, D, 1, H * W))\n",
    "        v_x_flatten = v_x.reshape((N, C, D, 1, H * W))\n",
    "        print(q_x_flatten.shape,'this is q_x_flatten shape')\n",
    "        sigma_x = torch.mul(q_x_flatten.permute(0, 1, 2, 4, 3), k_x_flatten)\n",
    "        r_x = F.softmax(sigma_x, dim=4)\n",
    "        # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "        Patt = torch.matmul(v_x_flatten, r_x).reshape(N, C, D, H, W)\n",
    "        return Patt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 34359738368 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SA(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[20], line 98\u001b[0m, in \u001b[0;36mSA.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     95\u001b[0m k_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3d_1(x)\n\u001b[0;32m     96\u001b[0m q_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3d_1(x)\n\u001b[1;32m---> 98\u001b[0m Patt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCal_Patt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m#Datt = self.Cal_Datt(k_x, q_x, v_x, self.N, self.C, self.D, self.H, self.W)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m#Y = self.gama*(Patt + Datt) + x\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v_x,k_x,q_x\n",
      "Cell \u001b[1;32mIn[20], line 58\u001b[0m, in \u001b[0;36mSA.Cal_Patt\u001b[1;34m(self, k_x, q_x, v_x, N, C, D, H, W)\u001b[0m\n\u001b[0;32m     56\u001b[0m q_x \u001b[38;5;241m=\u001b[39m q_x\u001b[38;5;241m.\u001b[39mview((N, C, D, \u001b[38;5;241m1\u001b[39m, H \u001b[38;5;241m*\u001b[39m W))\n\u001b[0;32m     57\u001b[0m v_x \u001b[38;5;241m=\u001b[39m v_x\u001b[38;5;241m.\u001b[39mview((N, C, D, \u001b[38;5;241m1\u001b[39m, H \u001b[38;5;241m*\u001b[39m W))\n\u001b[1;32m---> 58\u001b[0m sigma_x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m r_x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(sigma_x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# r_x = F.softmax(sigma_x.float(), dim=4)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 34359738368 bytes."
     ]
    }
   ],
   "source": [
    "test_data = torch.rand((1,64,64,64,8))\n",
    "model = SA(64,64,1)\n",
    "model(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 16, 1, 64]) this is q_x_flatten shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.1840,  0.1840,  0.1840,  0.4857],\n",
       "           [ 0.1840,  0.1840,  0.1916,  0.2848],\n",
       "           [ 0.1840,  0.2147,  0.2085,  0.1994],\n",
       "           ...,\n",
       "           [ 0.1840,  0.1840,  0.1840,  0.8523],\n",
       "           [ 0.1840,  0.4757,  0.1840,  0.7862],\n",
       "           [ 0.1840,  0.2523,  0.1840,  0.4542]],\n",
       "\n",
       "          [[ 0.1794,  0.1794,  0.1794,  0.1794],\n",
       "           [ 0.1794,  0.1794,  0.1794,  0.4105],\n",
       "           [ 0.1794,  0.1794,  0.5565,  0.3375],\n",
       "           ...,\n",
       "           [ 0.1794,  0.2145,  1.5284,  0.2050],\n",
       "           [ 0.1794,  0.1794,  0.1794,  2.9662],\n",
       "           [ 0.1794,  0.2337,  1.4631,  1.4761]],\n",
       "\n",
       "          [[ 0.1881,  0.2232,  0.1881,  0.1881],\n",
       "           [ 0.1881,  0.2146,  0.1881,  0.8074],\n",
       "           [ 0.1881,  1.5529,  0.2120,  0.1881],\n",
       "           ...,\n",
       "           [ 0.1881,  0.1881,  0.1881,  0.3370],\n",
       "           [ 0.1881,  0.2497,  0.1881,  0.3790],\n",
       "           [ 0.1881,  0.2476,  0.5768,  0.4506]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 0.1676,  0.2629,  0.1676,  0.1676],\n",
       "           [ 0.1676,  0.1676,  0.4219,  0.4619],\n",
       "           [ 0.1676,  0.1730,  0.1676,  0.6221],\n",
       "           ...,\n",
       "           [ 0.1676,  0.1676,  0.2205,  0.1676],\n",
       "           [ 0.1676,  0.2255,  0.5350,  1.1874],\n",
       "           [ 0.1917,  0.6851,  0.2778,  0.3191]],\n",
       "\n",
       "          [[ 0.2251,  0.3056,  0.2251,  0.2251],\n",
       "           [ 0.2251,  0.2251,  0.2251,  0.6514],\n",
       "           [ 0.2251,  0.2251,  0.2251,  0.5160],\n",
       "           ...,\n",
       "           [ 0.2251,  0.3106,  0.2488,  0.6024],\n",
       "           [ 0.2251,  0.2251,  0.2466,  0.2251],\n",
       "           [ 0.2251,  0.8822,  0.2251,  0.4046]],\n",
       "\n",
       "          [[ 0.2636,  0.2636,  0.2636,  0.3761],\n",
       "           [ 0.2636,  0.2636,  0.3820,  0.2636],\n",
       "           [ 0.2636,  0.3781,  0.2636,  0.2636],\n",
       "           ...,\n",
       "           [ 0.2636,  0.2636,  1.1646,  1.2970],\n",
       "           [ 0.2636,  0.7880,  0.3355,  1.7900],\n",
       "           [ 0.2764,  0.7235,  1.0063,  0.7186]]],\n",
       "\n",
       "\n",
       "         [[[ 0.8899,  0.2522,  0.1615,  0.3078],\n",
       "           [ 0.7925,  0.1615,  0.1615,  0.3507],\n",
       "           [ 2.2956,  0.3990,  0.5569,  0.2213],\n",
       "           ...,\n",
       "           [ 0.7527,  0.1615,  0.1615,  0.2477],\n",
       "           [ 0.7125,  0.3307,  0.1795,  0.4424],\n",
       "           [ 1.1290,  0.2998,  0.1615,  0.5911]],\n",
       "\n",
       "          [[ 0.1633,  0.1633,  0.3825,  0.1633],\n",
       "           [ 1.1402,  0.1633,  0.1633,  0.1633],\n",
       "           [ 0.9876,  0.1633,  0.1633,  0.5741],\n",
       "           ...,\n",
       "           [ 0.7323,  0.1633,  0.1633,  0.2972],\n",
       "           [ 6.0206,  0.1633,  0.1633,  0.1662],\n",
       "           [ 1.1164,  0.3589,  0.2255,  0.2944]],\n",
       "\n",
       "          [[ 0.2457,  0.4943,  0.4578,  0.3202],\n",
       "           [ 1.3661,  0.2457,  0.2457,  1.1524],\n",
       "           [ 0.6856,  0.2457,  0.2457,  0.2457],\n",
       "           ...,\n",
       "           [ 2.4564,  0.2457,  0.2457,  0.2457],\n",
       "           [ 1.9876,  0.2457,  0.2457,  0.2457],\n",
       "           [ 0.4041,  0.2457,  0.3756,  0.3659]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 0.2439,  0.2222,  0.1641,  0.2656],\n",
       "           [ 0.4072,  0.1641,  0.1641,  0.1653],\n",
       "           [ 0.3102,  0.1641,  0.1818,  0.5332],\n",
       "           ...,\n",
       "           [ 4.2622,  0.1641,  0.1641,  0.2279],\n",
       "           [ 0.6131,  0.1641,  0.3931,  0.1867],\n",
       "           [ 0.4028,  0.1641,  0.1641,  0.4211]],\n",
       "\n",
       "          [[ 0.1773,  0.3754,  0.1773,  0.1773],\n",
       "           [ 0.4888,  0.2845,  0.3440,  0.1773],\n",
       "           [ 0.5100,  0.2574,  0.1773,  0.1773],\n",
       "           ...,\n",
       "           [ 0.3524,  0.1773,  0.1773,  0.1773],\n",
       "           [ 2.0314,  0.2471,  0.1773,  0.1889],\n",
       "           [ 0.4802,  0.1773,  0.1773,  0.2037]],\n",
       "\n",
       "          [[ 0.2138,  0.5344,  0.4744,  0.2319],\n",
       "           [ 0.9194,  0.2195,  0.2863,  0.1546],\n",
       "           [ 2.4002,  0.2038,  0.2376,  0.1914],\n",
       "           ...,\n",
       "           [ 0.1949,  0.3814,  0.3249,  0.2953],\n",
       "           [ 0.9243,  0.2338,  0.1509,  0.4405],\n",
       "           [ 0.4603,  0.2993,  0.3385,  0.1815]]],\n",
       "\n",
       "\n",
       "         [[[ 0.5433,  0.5433,  0.5433,  0.5433],\n",
       "           [ 0.5433,  0.5433,  0.5433,  0.5433],\n",
       "           [ 0.5433,  0.5433,  0.5433,  0.5433],\n",
       "           ...,\n",
       "           [ 0.5433,  0.5433,  0.5433,  0.5433],\n",
       "           [ 0.5433,  0.5433,  0.5433,  0.5433],\n",
       "           [ 0.5433,  0.5433,  0.5433,  0.5433]],\n",
       "\n",
       "          [[ 0.2062,  0.2062,  0.2062,  0.2062],\n",
       "           [ 0.5355,  0.8852,  0.2062,  0.3328],\n",
       "           [ 0.2062,  0.2939,  0.5141,  0.2468],\n",
       "           ...,\n",
       "           [ 0.2062,  0.2062,  0.2062,  0.2253],\n",
       "           [ 0.4060,  0.5783,  0.9166,  0.4068],\n",
       "           [ 0.2062,  0.2062,  0.2062,  0.2062]],\n",
       "\n",
       "          [[ 0.1825,  0.1825,  0.1825,  0.1825],\n",
       "           [ 0.1825,  0.1825,  0.1825,  0.2590],\n",
       "           [ 0.1825,  0.4809,  0.4604,  0.2394],\n",
       "           ...,\n",
       "           [ 1.4793,  1.2266,  0.3744,  0.2578],\n",
       "           [ 0.1825,  0.2107,  1.6392,  0.2491],\n",
       "           [ 0.1825,  0.1825,  0.1825,  0.1825]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 0.1306,  0.1306,  0.1306,  0.1306],\n",
       "           [ 0.1546,  0.5209,  0.5092,  0.4697],\n",
       "           [ 0.1605,  0.1306,  0.2027,  0.2235],\n",
       "           ...,\n",
       "           [ 0.1427,  2.2422,  0.2058,  0.6698],\n",
       "           [ 0.1306,  0.3568,  0.1606,  0.1797],\n",
       "           [ 0.1306,  0.1306,  0.1306,  0.1564]],\n",
       "\n",
       "          [[ 0.1698,  0.1698,  0.1698,  0.1698],\n",
       "           [ 0.1698,  0.1698, 15.8524,  0.6213],\n",
       "           [ 0.1698,  0.4744,  0.1698,  0.1698],\n",
       "           ...,\n",
       "           [ 0.1698,  0.4937,  0.1738,  0.4543],\n",
       "           [ 0.1698,  0.1698,  1.2231,  0.1698],\n",
       "           [ 0.1698,  0.1698,  0.1698,  0.3477]],\n",
       "\n",
       "          [[ 0.2462,  0.2462,  0.2462,  0.2462],\n",
       "           [ 0.2462,  0.2462,  0.2462,  0.2462],\n",
       "           [ 0.2565,  0.3919,  0.2462,  0.2462],\n",
       "           ...,\n",
       "           [ 0.2462,  0.2462,  0.2462,  0.2462],\n",
       "           [ 0.2462,  0.3564,  0.2603,  0.2462],\n",
       "           [ 0.2462,  0.2462,  0.2462,  0.2462]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 1.1150,  0.2755,  0.2755,  0.2755],\n",
       "           [ 2.3598,  0.2755,  0.2755,  0.2755],\n",
       "           [ 0.7597,  0.2755,  0.2755,  0.2755],\n",
       "           ...,\n",
       "           [ 0.2755,  0.2755,  0.2755,  0.4848],\n",
       "           [ 0.3728,  0.3487,  0.2755,  0.2755],\n",
       "           [ 0.4074,  0.3250,  0.2755,  0.2755]],\n",
       "\n",
       "          [[ 0.2080,  0.3900,  0.2040,  0.3502],\n",
       "           [ 0.6176,  0.5990,  0.3030,  0.3604],\n",
       "           [ 0.5158,  0.3342,  0.5937,  0.2040],\n",
       "           ...,\n",
       "           [ 0.5445,  0.2815,  1.2999,  0.2040],\n",
       "           [ 0.2561,  0.5746,  0.2040,  0.2040],\n",
       "           [ 0.4448,  0.2190,  0.2040,  0.2040]],\n",
       "\n",
       "          [[ 1.0124,  0.3029,  0.2282,  0.2282],\n",
       "           [ 0.2439,  0.3286,  2.2838,  0.2282],\n",
       "           [ 0.9671,  0.6145,  0.2282,  0.2282],\n",
       "           ...,\n",
       "           [ 0.2994,  0.2282,  0.2282,  0.2282],\n",
       "           [ 1.0121,  0.4322,  0.3861,  0.2282],\n",
       "           [ 0.2282,  0.2282,  0.2282,  0.2282]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 0.4799,  0.1863,  0.1863,  0.2654],\n",
       "           [ 0.7626,  0.1863,  0.3237,  0.1863],\n",
       "           [ 0.5027,  0.1863,  1.1923,  0.1863],\n",
       "           ...,\n",
       "           [ 0.2110,  0.1920,  0.1907,  0.1863],\n",
       "           [ 0.2618,  0.1863,  0.1863,  0.1863],\n",
       "           [ 0.2358,  0.1863,  0.3166,  0.1863]],\n",
       "\n",
       "          [[ 0.8297,  0.2400,  0.2400,  0.2400],\n",
       "           [ 1.7867,  0.2569,  0.2400,  0.2400],\n",
       "           [ 0.7417,  0.2400,  0.2400,  0.2400],\n",
       "           ...,\n",
       "           [ 0.5144,  0.5684,  0.2400,  0.2400],\n",
       "           [ 2.0202,  0.3196,  0.2400,  0.2400],\n",
       "           [ 1.2557,  0.2400,  0.2525,  0.2400]],\n",
       "\n",
       "          [[ 0.2944,  0.1805,  0.1858,  0.1077],\n",
       "           [ 0.1163,  0.4505,  0.4886,  0.0718],\n",
       "           [ 0.2968,  0.2363,  0.2186,  0.0718],\n",
       "           ...,\n",
       "           [ 0.6092,  0.0874,  0.1207,  0.1260],\n",
       "           [ 0.3641,  0.0862,  0.1753,  0.0718],\n",
       "           [ 0.1328,  0.0884,  0.0718,  0.0767]]],\n",
       "\n",
       "\n",
       "         [[[ 0.2605,  0.2605,  0.2605,  0.2605],\n",
       "           [ 0.2605,  0.2605,  0.2605,  0.3506],\n",
       "           [ 0.2605,  0.2605,  0.2878,  0.2605],\n",
       "           ...,\n",
       "           [ 0.3005,  0.2605,  0.2605,  0.3627],\n",
       "           [ 0.2605,  0.2605,  0.2605,  0.2605],\n",
       "           [ 0.2605,  3.9341,  0.2605,  0.6902]],\n",
       "\n",
       "          [[ 0.1499,  0.1499,  0.1499,  0.1499],\n",
       "           [ 0.1499,  0.1499,  1.7005,  0.2907],\n",
       "           [ 0.1499,  0.1990,  0.6145,  0.2923],\n",
       "           ...,\n",
       "           [ 0.1499,  0.1499,  0.1664,  0.1499],\n",
       "           [ 0.1499,  0.1499,  0.2309,  0.3097],\n",
       "           [ 0.1499,  0.1499,  0.1499,  0.7077]],\n",
       "\n",
       "          [[ 0.1835,  0.3415,  0.1835,  0.1835],\n",
       "           [ 0.1835,  0.3647,  0.2150,  0.1835],\n",
       "           [ 0.1835,  0.4384,  0.3812,  0.1835],\n",
       "           ...,\n",
       "           [ 0.1835,  0.4606,  0.2294,  0.1835],\n",
       "           [ 0.1835,  0.1984,  0.3367,  0.2326],\n",
       "           [ 0.1835,  1.0274,  0.3491,  1.5071]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 0.1944,  0.1944,  0.1944,  0.1944],\n",
       "           [ 0.1944,  0.5108,  0.6139,  0.2221],\n",
       "           [ 0.1944,  0.1944,  0.2671,  0.1944],\n",
       "           ...,\n",
       "           [ 0.1944,  0.2185,  0.2066,  0.4268],\n",
       "           [ 0.1944,  0.2554,  0.1944,  0.2566],\n",
       "           [ 0.1944,  0.1944,  0.3475,  0.7485]],\n",
       "\n",
       "          [[ 0.1878,  0.1878,  0.3233,  0.1878],\n",
       "           [ 0.1878,  0.1878,  1.0084,  0.8574],\n",
       "           [ 0.1878,  0.7237,  2.6038,  0.3290],\n",
       "           ...,\n",
       "           [ 0.1878,  0.1878,  0.1878,  0.2782],\n",
       "           [ 0.1878,  1.7516,  0.5263,  0.3714],\n",
       "           [ 0.1878,  0.1878,  0.2711,  0.4151]],\n",
       "\n",
       "          [[ 0.2354,  0.2354,  0.2488,  0.2354],\n",
       "           [ 0.2354,  0.3245,  0.2397,  0.2354],\n",
       "           [ 0.2354,  0.5766,  0.9954,  0.5482],\n",
       "           ...,\n",
       "           [ 0.2354,  0.2468,  0.6202,  0.2354],\n",
       "           [ 0.2354,  0.2354,  0.3148,  0.2354],\n",
       "           [ 0.2354,  0.3298,  0.2897,  0.2354]]],\n",
       "\n",
       "\n",
       "         [[[ 1.8440,  0.4507,  0.3256,  0.2162],\n",
       "           [ 1.2132,  0.0734,  0.1449,  0.1992],\n",
       "           [ 0.6340,  0.0734,  0.1490,  0.1285],\n",
       "           ...,\n",
       "           [ 0.6141,  0.3900,  0.1870,  0.0859],\n",
       "           [ 0.3226,  0.1078,  0.1749,  0.1110],\n",
       "           [ 0.3959,  0.2177,  0.1394,  0.0861]],\n",
       "\n",
       "          [[ 5.8939,  0.8842,  0.1723,  0.5072],\n",
       "           [ 0.3408,  0.1459,  0.1254,  0.1254],\n",
       "           [ 0.8296,  0.1254,  0.1254,  0.1254],\n",
       "           ...,\n",
       "           [ 0.2437,  0.1490,  0.1254,  0.1254],\n",
       "           [ 0.1488,  0.1398,  0.1254,  0.1265],\n",
       "           [ 0.4718,  0.1254,  0.2711,  0.1557]],\n",
       "\n",
       "          [[ 1.3029,  0.2661,  1.4801,  0.4667],\n",
       "           [ 0.7128,  0.1968,  0.1968,  0.1968],\n",
       "           [ 1.4461,  0.1968,  0.1968,  0.2506],\n",
       "           ...,\n",
       "           [ 0.3586,  0.1968,  0.1968,  0.1968],\n",
       "           [ 0.2335,  0.3953,  0.1968,  0.1968],\n",
       "           [ 2.9325,  0.3267,  0.1968,  0.2874]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 1.0488,  0.3455,  0.2207,  0.3624],\n",
       "           [ 1.6310,  0.2207,  0.2207,  0.2895],\n",
       "           [ 0.5843,  0.2207,  0.2207,  0.2207],\n",
       "           ...,\n",
       "           [ 0.4869,  0.2207,  0.2207,  0.2751],\n",
       "           [ 0.4772,  0.2207,  0.2207,  0.2207],\n",
       "           [ 0.6950,  0.2207,  0.3053,  0.3488]],\n",
       "\n",
       "          [[ 3.2343,  1.0310,  0.4939,  1.2832],\n",
       "           [ 0.6400,  0.2344,  0.2344,  0.2344],\n",
       "           [ 0.7333,  0.2344,  0.2344,  0.2344],\n",
       "           ...,\n",
       "           [ 0.6799,  0.4986,  0.2344,  0.3285],\n",
       "           [ 0.4264,  0.2344,  0.2344,  0.2344],\n",
       "           [ 0.4029,  0.2344,  0.5545,  0.3691]],\n",
       "\n",
       "          [[ 0.6887,  0.2651,  0.8934,  0.9479],\n",
       "           [ 0.1937,  0.2223,  0.1519,  0.6104],\n",
       "           [ 0.3255,  0.1519,  0.1519,  0.2042],\n",
       "           ...,\n",
       "           [ 1.4606,  0.3284,  0.1519,  0.8478],\n",
       "           [ 0.2570,  0.1676,  0.1519,  0.2705],\n",
       "           [ 2.1962,  0.3151,  0.2532,  1.5332]]]]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_x,q_x,v_x = model(test_data)\n",
    "Cal_Patt(k_x, q_x, v_x, 1,256,16,16,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.rand((1,1,256,256,30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionBlock(\n",
       "      (conv3d_3): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv3d_1): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionBlock(\n",
       "      (conv3d_3): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv3d_1): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renset_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionBlock(\n",
       "      (conv3d_3): Sequential(\n",
       "        (0): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv3d_1): Sequential(\n",
       "        (0): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renset_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 32, 64, 128] shit\n",
      "torch.Size([1, 16, 256, 256, 30])\n",
      "run layer1\n",
      "None before downsample! torch.Size([1, 16, 256, 256, 30])\n",
      "after layer1 torch.Size([1, 16, 256, 256, 30])\n",
      "Sequential(\n",
      "  (0): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 32, 128, 128, 15])\n",
      "downsample!\n",
      "torch.Size([1, 32, 128, 128, 15]) after downsample!\n",
      "after layer2 torch.Size([1, 32, 128, 128, 15])\n",
      "Sequential(\n",
      "  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 64, 64, 64, 8])\n",
      "downsample!\n",
      "torch.Size([1, 64, 64, 64, 8]) after downsample!\n",
      "after layer3 torch.Size([1, 64, 64, 64, 8])\n",
      "Sequential(\n",
      "  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 128, 32, 32, 4])\n",
      "downsample!\n",
      "torch.Size([1, 128, 32, 32, 4]) after downsample!\n",
      "torch.Size([1, 128, 32, 32, 4]) this is x shape\n",
      "use SA block!\n",
      "this is v_x shape torch.Size([1, 128, 32, 32, 4])\n",
      "torch.Size([1, 128, 4, 32, 32]) this is Patt shape\n",
      "torch.Size([1, 128, 32, 32, 1, 4]) this is k_x_flatten shape\n",
      "torch.Size([1, 128, 32, 32, 4, 1]) this is q_x_flatten shape\n",
      "torch.Size([1, 128, 32, 32, 4, 4]) this is sigma_x shape\n",
      "torch.Size([1, 128, 4, 32, 32]) this is Patt shape torch.Size([1, 128, 4, 32, 32]) this is Datt shape\n",
      "after layer4 torch.Size([1, 128, 32, 32, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2954, -0.0271]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renset_10 = resnet10(n_input_channels=1, num_classes=2, widen_factor=1,no_max_pool=True)\n",
    "renset_10(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import re\n",
    "from collections.abc import Callable\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from monai.networks.layers.factories import Conv, Norm, Pool\n",
    "from monai.networks.layers.utils import get_pool_layer\n",
    "from monai.utils import ensure_tuple_rep\n",
    "from monai.utils.module import look_up_option, optional_import\n",
    "\n",
    "\n",
    "hf_hub_download, _ = optional_import(\"huggingface_hub\", name=\"hf_hub_download\")\n",
    "EntryNotFoundError, _ = optional_import(\"huggingface_hub.utils._errors\", name=\"EntryNotFoundError\")\n",
    "\n",
    "MEDICALNET_HUGGINGFACE_REPO_BASENAME = \"TencentMedicalNet/MedicalNet-Resnet\"\n",
    "MEDICALNET_HUGGINGFACE_FILES_BASENAME = \"resnet_\"\n",
    "\n",
    "__all__ = [\n",
    "    \"ResNet\",\n",
    "    \"ResNetBlock\",\n",
    "    \"ResNetBottleneck\",\n",
    "    \"resnet10\",\n",
    "    \"resnet18\",\n",
    "    \"resnet34\",\n",
    "    \"resnet50\",\n",
    "    \"resnet101\",\n",
    "    \"resnet152\",\n",
    "    \"resnet200\",\n",
    "]\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def get_inplanes():\n",
    "    return [64,128,256,512]\n",
    "\n",
    "\n",
    "def get_avgpool():\n",
    "    return [0, 1, (1, 1), (1, 1, 1)]\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_planes: int,\n",
    "        planes: int,\n",
    "        spatial_dims: int = 3,\n",
    "        stride: int = 1,\n",
    "        downsample: nn.Module | partial | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_planes: number of input channels.\n",
    "            planes: number of output channels.\n",
    "            spatial_dims: number of spatial dimensions of the input image.\n",
    "            stride: stride to use for first conv layer.\n",
    "            downsample: which downsample layer to use.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "\n",
    "        self.conv1 = conv_type(in_planes, planes, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.bn1 = norm_type(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv_type(planes, planes, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = norm_type(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "\n",
    "        out: torch.Tensor = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        print(self.downsample,'before downsample!',out.shape)\n",
    "        if self.downsample is not None:\n",
    "            print('downsample!')\n",
    "            residual = self.downsample(x)\n",
    "            print(residual.shape,'after downsample!')\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_planes: int,\n",
    "        planes: int,\n",
    "        spatial_dims: int = 3,\n",
    "        stride: int = 1,\n",
    "        downsample: nn.Module | partial | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_planes: number of input channels.\n",
    "            planes: number of output channels (taking expansion into account).\n",
    "            spatial_dims: number of spatial dimensions of the input image.\n",
    "            stride: stride to use for second conv layer.\n",
    "            downsample: which downsample layer to use.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "\n",
    "        self.conv1 = conv_type(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_type(planes)\n",
    "        self.conv2 = conv_type(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = norm_type(planes)\n",
    "        self.conv3 = conv_type(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_type(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "\n",
    "        out: torch.Tensor = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BottleNeckaSA(nn.Module):\n",
    "    def __init__(self,in_ch,reduction_ratio) -> None:\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = in_ch//reduction_ratio \n",
    "        self.gama = nn.Parameter(torch.tensor([0.0]))\n",
    "\n",
    "        self.conv3d = nn.Sequential(nn.Conv3d(self.in_ch,self.out_ch,kernel_size=1,padding=0),\n",
    "                                   nn.BatchNorm3d(self.out_ch),\n",
    "                                   nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv3d_3 = nn.Sequential(\n",
    "            # Conv3d input:N*C*D*H*W\n",
    "            # Conv3d output:N*C*D*H*W\n",
    "            nn.Conv3d(in_channels=self.out_ch, out_channels=self.out_ch, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.BatchNorm3d(self.out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv3d_1 = nn.Sequential(\n",
    "            # Conv3d input:N*C*D*H*W\n",
    "            # Conv3d output:N*C*D*H*W\n",
    "            nn.Conv3d(in_channels=self.out_ch, out_channels=self.out_ch, kernel_size=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(self.out_ch),\n",
    "            nn.ReLU(inplace=True), \n",
    "        )\n",
    "\n",
    "        self.conv3d_back = nn.Sequential(nn.Conv3d(self.out_ch,self.in_ch,kernel_size=1,padding=0),\n",
    "                                   nn.BatchNorm3d(self.in_ch),\n",
    "                                   nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def Cal_Patt(self,k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input : N*C*D*H*W\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "        k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "        q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "        v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        k_x_flatten = k_x.reshape((N, C, D, 1, H * W))\n",
    "        q_x_flatten = q_x.reshape((N, C, D, 1, H * W))\n",
    "        v_x_flatten = v_x.reshape((N, C, D, 1, H * W))\n",
    "        sigma_x = torch.mul(q_x_flatten.permute(0, 1, 2, 4, 3), k_x_flatten)\n",
    "        r_x = F.softmax(sigma_x, dim=4)\n",
    "        # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "        Patt = torch.matmul(v_x_flatten, r_x).reshape(N, C, D, H, W)\n",
    "        print(Patt.shape,'this is Patt shape')\n",
    "        return Patt\n",
    "\n",
    "    \n",
    "\n",
    "    def Cal_Datt(self,k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input:N*C*D*H*W\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "        k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "        q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "        v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        k_x_flatten = k_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        q_x_flatten = q_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        v_x_flatten = v_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        print(k_x_flatten.shape,'this is k_x_flatten shape')\n",
    "        print(q_x_flatten.permute(0, 1, 2, 3, 5, 4).shape,'this is q_x_flatten shape')\n",
    "        sigma_x = torch.mul(q_x_flatten.permute(0, 1, 2, 3, 5, 4), k_x_flatten)\n",
    "        print(sigma_x.shape,'this is sigma_x shape')\n",
    "        r_x = F.softmax(sigma_x, dim=5)\n",
    "        # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "        Datt = torch.matmul(v_x_flatten, r_x).reshape(N, C, H, W, D)\n",
    "        return Datt.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape,'this is x shape')\n",
    "        x = self.conv3d(x)\n",
    "        print(x.shape,'this is x shape')\n",
    "        N,C,H,W,D = x.shape\n",
    "        v_x = self.conv3d_3(x)\n",
    "        k_x = self.conv3d_1(x)\n",
    "        q_x = self.conv3d_1(x)\n",
    "        print('use SA block!')\n",
    "        print('this is v_x shape',v_x.shape)\n",
    "        Patt = self.Cal_Patt(k_x, q_x, v_x, N, C, D, H, W)\n",
    "        Datt = self.Cal_Datt(k_x, q_x, v_x, N, C, D, H, W)\n",
    "        print(Patt.shape,'this is Patt shape',Datt.shape,'this is Datt shape')\n",
    "        #reshape to N*C*H*W*D\n",
    "        Patt = Patt.permute(0, 1, 3, 4, 2)\n",
    "        Datt = Datt.permute(0, 1, 3, 4, 2)\n",
    "        Y = self.gama*(Patt + Datt) + x\n",
    "        Y = self.conv3d_back(Y)\n",
    "        return Y\n",
    "\n",
    "    \n",
    "    \n",
    "class SelfAttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    input:N*C*H*W*D\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.gama = nn.Parameter(torch.tensor([0.0]))\n",
    "\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        \n",
    "        self.conv3d_3 = nn.Sequential(\n",
    "            # Conv3d input:N*C*D*H*W\n",
    "            # Conv3d output:N*C*D*H*W\n",
    "            nn.Conv3d(in_channels=self.out_ch, out_channels=self.out_ch, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.BatchNorm3d(self.out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv3d_1 = nn.Sequential(\n",
    "            # Conv3d input:N*C*D*H*W\n",
    "            # Conv3d output:N*C*D*H*W\n",
    "            nn.Conv3d(in_channels=self.out_ch, out_channels=self.out_ch, kernel_size=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(self.out_ch),\n",
    "            nn.ReLU(inplace=True), \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def Cal_Patt(self,k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input : N*C*D*H*W\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "        k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "        q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "        v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        k_x_flatten = k_x.reshape((N, C, D, 1, H * W))\n",
    "        q_x_flatten = q_x.reshape((N, C, D, 1, H * W))\n",
    "        v_x_flatten = v_x.reshape((N, C, D, 1, H * W))\n",
    "        sigma_x = torch.mul(q_x_flatten.permute(0, 1, 2, 4, 3), k_x_flatten)\n",
    "        r_x = F.softmax(sigma_x, dim=4)\n",
    "        # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "        Patt = torch.matmul(v_x_flatten, r_x).reshape(N, C, D, H, W)\n",
    "        print(Patt.shape,'this is Patt shape')\n",
    "        return Patt\n",
    "\n",
    "    \n",
    "\n",
    "    def Cal_Datt(self,k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input:N*C*D*H*W\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "        k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "        q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "        v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        k_x_flatten = k_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        q_x_flatten = q_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        v_x_flatten = v_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        print(k_x_flatten.shape,'this is k_x_flatten shape')\n",
    "        print(q_x_flatten.permute(0, 1, 2, 3, 5, 4).shape,'this is q_x_flatten shape')\n",
    "        sigma_x = torch.mul(q_x_flatten.permute(0, 1, 2, 3, 5, 4), k_x_flatten)\n",
    "        print(sigma_x.shape,'this is sigma_x shape')\n",
    "        r_x = F.softmax(sigma_x, dim=5)\n",
    "        # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "        Datt = torch.matmul(v_x_flatten, r_x).reshape(N, C, H, W, D)\n",
    "        return Datt.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape,'this is x shape')\n",
    "        res = x\n",
    "        N,C,H,W,D = x.shape\n",
    "        v_x = self.conv3d_3(x)\n",
    "        k_x = self.conv3d_1(x)\n",
    "        q_x = self.conv3d_1(x)\n",
    "        print('use SA block!')\n",
    "        print('this is v_x shape',v_x.shape)\n",
    "        Patt = self.Cal_Patt(k_x, q_x, v_x, N, C, D, H, W)\n",
    "        Datt = self.Cal_Datt(k_x, q_x, v_x, N, C, D, H, W)\n",
    "        print(Patt.shape,'this is Patt shape',Datt.shape,'this is Datt shape')\n",
    "        #reshape to N*C*H*W*D\n",
    "        Patt = Patt.permute(0, 1, 3, 4, 2)\n",
    "        Datt = Datt.permute(0, 1, 3, 4, 2)\n",
    "        Y = self.gama*(Patt + Datt)\n",
    "        Y = self.conv3d_back(Y) + res\n",
    "        return Y\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet based on: `Deep Residual Learning for Image Recognition <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    and `Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet? <https://arxiv.org/pdf/1711.09577.pdf>`_.\n",
    "    Adapted from `<https://github.com/kenshohara/3D-ResNets-PyTorch/tree/master/models>`_.\n",
    "\n",
    "    Args:\n",
    "        block: which ResNet block to use, either Basic or Bottleneck.\n",
    "            ResNet block class or str.\n",
    "            for Basic: ResNetBlock or 'basic'\n",
    "            for Bottleneck: ResNetBottleneck or 'bottleneck'\n",
    "        layers: how many layers to use.\n",
    "        block_inplanes: determine the size of planes at each step. Also tunable with widen_factor.\n",
    "        spatial_dims: number of spatial dimensions of the input image.\n",
    "        n_input_channels: number of input channels for first convolutional layer.\n",
    "        conv1_t_size: size of first convolution layer, determines kernel and padding.\n",
    "        conv1_t_stride: stride of first convolution layer.\n",
    "        no_max_pool: bool argument to determine if to use maxpool layer.\n",
    "        shortcut_type: which downsample block to use. Options are 'A', 'B', default to 'B'.\n",
    "            - 'A': using `self._downsample_basic_block`.\n",
    "            - 'B': kernel_size 1 conv + norm.\n",
    "        widen_factor: widen output for each layer.\n",
    "        num_classes: number of output (classifications).\n",
    "        feed_forward: whether to add the FC layer for the output, default to `True`.\n",
    "        bias_downsample: whether to use bias term in the downsampling block when `shortcut_type` is 'B', default to `True`.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: type[ResNetBlock | ResNetBottleneck] | str,\n",
    "        layers: list[int],\n",
    "        block_inplanes: list[int],\n",
    "        spatial_dims: int = 3,\n",
    "        n_input_channels: int = 3,\n",
    "        conv1_t_size: tuple[int] | int = 7,\n",
    "        conv1_t_stride: tuple[int] | int = 1,\n",
    "        no_max_pool: bool = False,\n",
    "        shortcut_type: str = \"B\",\n",
    "        widen_factor: float = 1.0,\n",
    "        num_classes: int = 400,\n",
    "        feed_forward: bool = True,\n",
    "        bias_downsample: bool = True,  # for backwards compatibility (also see PR #5477)\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if isinstance(block, str):\n",
    "            if block == \"basic\":\n",
    "                block = ResNetBlock\n",
    "            elif block == \"bottleneck\":\n",
    "                block = ResNetBottleneck\n",
    "            else:\n",
    "                raise ValueError(\"Unknown block '%s', use basic or bottleneck\" % block)\n",
    "\n",
    "        conv_type: type[nn.Conv1d | nn.Conv2d | nn.Conv3d] = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: type[nn.BatchNorm1d | nn.BatchNorm2d | nn.BatchNorm3d] = Norm[Norm.BATCH, spatial_dims]\n",
    "        pool_type: type[nn.MaxPool1d | nn.MaxPool2d | nn.MaxPool3d] = Pool[Pool.MAX, spatial_dims]\n",
    "        avgp_type: type[nn.AdaptiveAvgPool1d | nn.AdaptiveAvgPool2d | nn.AdaptiveAvgPool3d] = Pool[\n",
    "            Pool.ADAPTIVEAVG, spatial_dims\n",
    "        ]\n",
    "\n",
    "        block_avgpool = get_avgpool()\n",
    "        #widen fatcor means feature map size\n",
    "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
    "        print(block_inplanes,'shit')\n",
    "\n",
    "        self.in_planes = block_inplanes[0]\n",
    "        self.no_max_pool = no_max_pool\n",
    "        self.bias_downsample = bias_downsample\n",
    "\n",
    "        conv1_kernel_size = ensure_tuple_rep(conv1_t_size, spatial_dims)\n",
    "        conv1_stride = ensure_tuple_rep(conv1_t_stride, spatial_dims)\n",
    "\n",
    "        self.conv1 = conv_type(\n",
    "            n_input_channels,\n",
    "            self.in_planes,\n",
    "            kernel_size=conv1_kernel_size,\n",
    "            stride=conv1_stride,\n",
    "            padding=tuple(k // 2 for k in conv1_kernel_size),\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = norm_type(self.in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = pool_type(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0], spatial_dims, shortcut_type)\n",
    "        self.layer2 = self._make_layer(block, block_inplanes[1], layers[1], spatial_dims, shortcut_type, stride=2,SelfAttention=True,reduction_ratio=32)\n",
    "        self.layer3 = self._make_layer(block, block_inplanes[2], layers[2], spatial_dims, shortcut_type, stride=2,SelfAttention=True,reduction_ratio=16)\n",
    "        self.layer4 = self._make_layer(block, block_inplanes[3], layers[3], spatial_dims, shortcut_type, stride=2,SelfAttention=True,reduction_ratio=8)\n",
    "        self.avgpool = avgp_type(block_avgpool[spatial_dims])\n",
    "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, num_classes) if feed_forward else None\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, conv_type):\n",
    "                nn.init.kaiming_normal_(torch.as_tensor(m.weight), mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, norm_type):\n",
    "                nn.init.constant_(torch.as_tensor(m.weight), 1)\n",
    "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
    "\n",
    "    def _downsample_basic_block(self, x: torch.Tensor, planes: int, stride: int, spatial_dims: int = 3) -> torch.Tensor:\n",
    "        out: torch.Tensor = get_pool_layer((\"avg\", {\"kernel_size\": 1, \"stride\": stride}), spatial_dims=spatial_dims)(x)\n",
    "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), *out.shape[2:], dtype=out.dtype, device=out.device)\n",
    "        out = torch.cat([out.data, zero_pads], dim=1)\n",
    "        return out\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: type[ResNetBlock | ResNetBottleneck | SelfAttentionBlock],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        spatial_dims: int,\n",
    "        shortcut_type: str,\n",
    "        stride: int = 1,\n",
    "        SelfAttention: bool = False,\n",
    "        reduction_ratio: int = 32,\n",
    "    ) -> nn.Sequential:\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
    "\n",
    "        downsample: nn.Module | partial | None = None\n",
    "        #####only stride !=1 we downsample,so the first layer don't downsample\n",
    "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
    "            if look_up_option(shortcut_type, {\"A\", \"B\"}) == \"A\":\n",
    "                downsample = partial(\n",
    "                    self._downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride,\n",
    "                    spatial_dims=spatial_dims,\n",
    "                )\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    conv_type(\n",
    "                        self.in_planes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=self.bias_downsample,\n",
    "                    ),\n",
    "                    norm_type(planes * block.expansion),\n",
    "                )\n",
    "        #here add attention block\n",
    "        if SelfAttention:                \n",
    "            layers = [\n",
    "                block(\n",
    "                    in_planes=self.in_planes, planes=planes, spatial_dims=spatial_dims, stride=stride, downsample=downsample\n",
    "                ),\n",
    "                BottleNeckaSA(planes,reduction_ratio),\n",
    "                #SelfAttentionBlock(planes, planes)\n",
    "            ]\n",
    "        else:\n",
    "            layers = [\n",
    "                block(\n",
    "                    in_planes=self.in_planes, planes=planes, spatial_dims=spatial_dims, stride=stride, downsample=downsample\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.in_planes = planes * block.expansion\n",
    "        #decide one layer with how many blocks\n",
    "        if SelfAttention:\n",
    "            for _i in range(1, blocks):\n",
    "                layers.append(block(self.in_planes, planes, spatial_dims=spatial_dims))\n",
    "                layers.append(BottleNeckaSA(planes,reduction_ratio))\n",
    "                #layers.append(SelfAttentionBlock(planes, planes))\n",
    "        else:\n",
    "            for _i in range(1, blocks):\n",
    "                layers.append(block(self.in_planes, planes, spatial_dims=spatial_dims))\n",
    "        #print('666666666666')\n",
    "        #print(layers,'this is layers')\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        if not self.no_max_pool:\n",
    "            print(x.shape)\n",
    "            x = self.maxpool(x)\n",
    "        print('run layer1')\n",
    "        x = self.layer1(x)\n",
    "        print('after layer1',x.shape)\n",
    "        x = self.layer2(x)\n",
    "        print('after layer2',x.shape)\n",
    "        x = self.layer3(x)\n",
    "        print('after layer3',x.shape)\n",
    "        x = self.layer4(x)\n",
    "        print('after layer4',x.shape)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        if self.fc is not None:\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def _resnet(\n",
    "    arch: str,\n",
    "    block: type[ResNetBlock | ResNetBottleneck],\n",
    "    layers: list[int],\n",
    "    block_inplanes: list[int],\n",
    "    pretrained: bool | str,\n",
    "    progress: bool,\n",
    "    **kwargs: Any,\n",
    ") -> ResNet:\n",
    "    model: ResNet = ResNet(block, layers, block_inplanes, **kwargs)\n",
    "    if pretrained:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        if isinstance(pretrained, str):\n",
    "            if Path(pretrained).exists():\n",
    "                logger.info(f\"Loading weights from {pretrained}...\")\n",
    "                model_state_dict = torch.load(pretrained, map_location=device)\n",
    "            else:\n",
    "                # Throw error\n",
    "                raise FileNotFoundError(\"The pretrained checkpoint file is not found\")\n",
    "        else:\n",
    "            # Also check bias downsample and shortcut.\n",
    "            if kwargs.get(\"spatial_dims\", 3) == 3:\n",
    "                if kwargs.get(\"n_input_channels\", 3) == 1 and kwargs.get(\"feed_forward\", True) is False:\n",
    "                    search_res = re.search(r\"resnet(\\d+)\", arch)\n",
    "                    if search_res:\n",
    "                        resnet_depth = int(search_res.group(1))\n",
    "                    else:\n",
    "                        raise ValueError(\"arch argument should be as 'resnet_{resnet_depth}\")\n",
    "\n",
    "                    # Check model bias_downsample and shortcut_type\n",
    "                    bias_downsample, shortcut_type = get_medicalnet_pretrained_resnet_args(resnet_depth)\n",
    "                    if shortcut_type == kwargs.get(\"shortcut_type\", \"B\") and (\n",
    "                        bool(bias_downsample) == kwargs.get(\"bias_downsample\", False) if bias_downsample != -1 else True\n",
    "                    ):\n",
    "                        # Download the MedicalNet pretrained model\n",
    "                        model_state_dict = get_pretrained_resnet_medicalnet(\n",
    "                            resnet_depth, device=device, datasets23=True\n",
    "                        )\n",
    "                    else:\n",
    "                        raise NotImplementedError(\n",
    "                            f\"Please set shortcut_type to {shortcut_type} and bias_downsample to\"\n",
    "                            f\"{bool(bias_downsample) if bias_downsample!=-1 else 'True or False'}\"\n",
    "                            f\"when using pretrained MedicalNet resnet{resnet_depth}\"\n",
    "                        )\n",
    "                else:\n",
    "                    raise NotImplementedError(\n",
    "                        \"Please set n_input_channels to 1\"\n",
    "                        \"and feed_forward to False in order to use MedicalNet pretrained weights\"\n",
    "                    )\n",
    "            else:\n",
    "                raise NotImplementedError(\"MedicalNet pretrained weights are only avalaible for 3D models\")\n",
    "        model_state_dict = {key.replace(\"module.\", \"\"): value for key, value in model_state_dict.items()}\n",
    "        model.load_state_dict(model_state_dict, strict=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet10(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    \"\"\"ResNet-10 with optional pretrained support when `spatial_dims` is 3.\n",
    "\n",
    "    Pretraining from `Med3D: Transfer Learning for 3D Medical Image Analysis <https://arxiv.org/pdf/1904.00625.pdf>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on 23 medical datasets\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet10\", ResNetBlock, [1, 1, 1, 1], get_inplanes(), pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    \"\"\"ResNet-18 with optional pretrained support when `spatial_dims` is 3.\n",
    "\n",
    "    Pretraining from `Med3D: Transfer Learning for 3D Medical Image Analysis <https://arxiv.org/pdf/1904.00625.pdf>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on 23 medical datasets\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet18\", ResNetBlock, [2, 2, 2, 2], get_inplanes(), pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    \"\"\"ResNet-34 with optional pretrained support when `spatial_dims` is 3.\n",
    "\n",
    "    Pretraining from `Med3D: Transfer Learning for 3D Medical Image Analysis <https://arxiv.org/pdf/1904.00625.pdf>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on 23 medical datasets\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet34\", ResNetBlock, [3, 4, 6, 3], get_inplanes(), pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    \"\"\"ResNet-50 with optional pretrained support when `spatial_dims` is 3.\n",
    "\n",
    "    Pretraining from `Med3D: Transfer Learning for 3D Medical Image Analysis <https://arxiv.org/pdf/1904.00625.pdf>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on 23 medical datasets\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet50\", ResNetBottleneck, [3, 4, 6, 3], get_inplanes(), pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    \"\"\"ResNet-101 with optional pretrained support when `spatial_dims` is 3.\n",
    "\n",
    "    Pretraining from `Med3D: Transfer Learning for 3D Medical Image Analysis <https://arxiv.org/pdf/1904.00625.pdf>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on 8 medical datasets\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet101\", ResNetBottleneck, [3, 4, 23, 3], get_inplanes(), pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    \"\"\"ResNet-152 with optional pretrained support when `spatial_dims` is 3.\n",
    "\n",
    "    Pretraining from `Med3D: Transfer Learning for 3D Medical Image Analysis <https://arxiv.org/pdf/1904.00625.pdf>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on 8 medical datasets\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet152\", ResNetBottleneck, [3, 8, 36, 3], get_inplanes(), pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet200(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    \"\"\"ResNet-200 with optional pretrained support when `spatial_dims` is 3.\n",
    "\n",
    "    Pretraining from `Med3D: Transfer Learning for 3D Medical Image Analysis <https://arxiv.org/pdf/1904.00625.pdf>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on 8 medical datasets\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet200\", ResNetBottleneck, [3, 24, 36, 3], get_inplanes(), pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def get_pretrained_resnet_medicalnet(resnet_depth: int, device: str = \"cpu\", datasets23: bool = True):\n",
    "    \"\"\"\n",
    "    Donwlad resnet pretrained weights from https://huggingface.co/TencentMedicalNet\n",
    "\n",
    "    Args:\n",
    "        resnet_depth: depth of the pretrained model. Supported values are 10, 18, 34, 50, 101, 152 and 200\n",
    "        device: device on which the returned state dict will be loaded. \"cpu\" or \"cuda\" for example.\n",
    "        datasets23: if True, get the weights trained on more datasets (23).\n",
    "                    Not all depths are available. If not, standard weights are returned.\n",
    "\n",
    "    Returns:\n",
    "        Pretrained state dict\n",
    "\n",
    "    Raises:\n",
    "        huggingface_hub.utils._errors.EntryNotFoundError: if pretrained weights are not found on huggingface hub\n",
    "        NotImplementedError: if `resnet_depth` is not supported\n",
    "    \"\"\"\n",
    "\n",
    "    medicalnet_huggingface_repo_basename = \"TencentMedicalNet/MedicalNet-Resnet\"\n",
    "    medicalnet_huggingface_files_basename = \"resnet_\"\n",
    "    supported_depth = [10, 18, 34, 50, 101, 152, 200]\n",
    "\n",
    "    logger.info(\n",
    "        f\"Loading MedicalNet pretrained model from https://huggingface.co/{medicalnet_huggingface_repo_basename}{resnet_depth}\"\n",
    "    )\n",
    "\n",
    "    if resnet_depth in supported_depth:\n",
    "        filename = (\n",
    "            f\"{medicalnet_huggingface_files_basename}{resnet_depth}.pth\"\n",
    "            if not datasets23\n",
    "            else f\"{medicalnet_huggingface_files_basename}{resnet_depth}_23dataset.pth\"\n",
    "        )\n",
    "        try:\n",
    "            pretrained_path = hf_hub_download(\n",
    "                repo_id=f\"{medicalnet_huggingface_repo_basename}{resnet_depth}\", filename=filename\n",
    "            )\n",
    "        except Exception:\n",
    "            if datasets23:\n",
    "                logger.info(f\"{filename} not available for resnet{resnet_depth}\")\n",
    "                filename = f\"{medicalnet_huggingface_files_basename}{resnet_depth}.pth\"\n",
    "                logger.info(f\"Trying with {filename}\")\n",
    "                pretrained_path = hf_hub_download(\n",
    "                    repo_id=f\"{medicalnet_huggingface_repo_basename}{resnet_depth}\", filename=filename\n",
    "                )\n",
    "            else:\n",
    "                raise EntryNotFoundError(\n",
    "                    f\"{filename} not found on {medicalnet_huggingface_repo_basename}{resnet_depth}\"\n",
    "                ) from None\n",
    "        checkpoint = torch.load(pretrained_path, map_location=torch.device(device))\n",
    "    else:\n",
    "        raise NotImplementedError(\"Supported resnet_depth are: [10, 18, 34, 50, 101, 152, 200]\")\n",
    "    logger.info(f\"{filename} downloaded\")\n",
    "    return checkpoint.get(\"state_dict\")\n",
    "\n",
    "\n",
    "def get_medicalnet_pretrained_resnet_args(resnet_depth: int):\n",
    "    \"\"\"\n",
    "    Return correct shortcut_type and bias_downsample\n",
    "    for pretrained MedicalNet weights according to resnet depth\n",
    "    \"\"\"\n",
    "    # After testing\n",
    "    # False: 10, 50, 101, 152, 200\n",
    "    # Any: 18, 34\n",
    "    bias_downsample = -1 if resnet_depth in [18, 34] else 0  # 18, 10, 34\n",
    "    shortcut_type = \"A\" if resnet_depth in [18, 34] else \"B\"\n",
    "    return bias_downsample, shortcut_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 128, 256, 512] shit\n"
     ]
    }
   ],
   "source": [
    "SACNN_model = resnet10(n_input_channels=1, num_classes=2, widen_factor=1,no_max_pool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 32, 256, 256])\n",
      "run layer1\n",
      "None before downsample! torch.Size([1, 64, 32, 256, 256])\n",
      "after layer1 torch.Size([1, 64, 32, 256, 256])\n",
      "Sequential(\n",
      "  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 128, 16, 128, 128])\n",
      "downsample!\n",
      "torch.Size([1, 128, 16, 128, 128]) after downsample!\n",
      "torch.Size([1, 128, 16, 128, 128]) this is x shape\n",
      "torch.Size([1, 4, 16, 128, 128]) this is x shape\n",
      "use SA block!\n",
      "this is v_x shape torch.Size([1, 4, 16, 128, 128])\n",
      "torch.Size([1, 4, 128, 16, 128]) this is Patt shape\n",
      "torch.Size([1, 4, 16, 128, 1, 128]) this is k_x_flatten shape\n",
      "torch.Size([1, 4, 16, 128, 128, 1]) this is q_x_flatten shape\n",
      "torch.Size([1, 4, 16, 128, 128, 128]) this is sigma_x shape\n",
      "torch.Size([1, 4, 128, 16, 128]) this is Patt shape torch.Size([1, 4, 128, 16, 128]) this is Datt shape\n",
      "after layer2 torch.Size([1, 128, 16, 128, 128])\n",
      "Sequential(\n",
      "  (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 256, 8, 64, 64])\n",
      "downsample!\n",
      "torch.Size([1, 256, 8, 64, 64]) after downsample!\n",
      "torch.Size([1, 256, 8, 64, 64]) this is x shape\n",
      "torch.Size([1, 16, 8, 64, 64]) this is x shape\n",
      "use SA block!\n",
      "this is v_x shape torch.Size([1, 16, 8, 64, 64])\n",
      "torch.Size([1, 16, 64, 8, 64]) this is Patt shape\n",
      "torch.Size([1, 16, 8, 64, 1, 64]) this is k_x_flatten shape\n",
      "torch.Size([1, 16, 8, 64, 64, 1]) this is q_x_flatten shape\n",
      "torch.Size([1, 16, 8, 64, 64, 64]) this is sigma_x shape\n",
      "torch.Size([1, 16, 64, 8, 64]) this is Patt shape torch.Size([1, 16, 64, 8, 64]) this is Datt shape\n",
      "after layer3 torch.Size([1, 256, 8, 64, 64])\n",
      "Sequential(\n",
      "  (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 512, 4, 32, 32])\n",
      "downsample!\n",
      "torch.Size([1, 512, 4, 32, 32]) after downsample!\n",
      "torch.Size([1, 512, 4, 32, 32]) this is x shape\n",
      "torch.Size([1, 64, 4, 32, 32]) this is x shape\n",
      "use SA block!\n",
      "this is v_x shape torch.Size([1, 64, 4, 32, 32])\n",
      "torch.Size([1, 64, 32, 4, 32]) this is Patt shape\n",
      "torch.Size([1, 64, 4, 32, 1, 32]) this is k_x_flatten shape\n",
      "torch.Size([1, 64, 4, 32, 32, 1]) this is q_x_flatten shape\n",
      "torch.Size([1, 64, 4, 32, 32, 32]) this is sigma_x shape\n",
      "torch.Size([1, 64, 32, 4, 32]) this is Patt shape torch.Size([1, 64, 32, 4, 32]) this is Datt shape\n",
      "after layer4 torch.Size([1, 512, 4, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2645, 0.1149]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SACNN_model(torch.randn(1,1,32,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conv3d_back \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mConv3d(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mout_ch,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_ch,kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m      2\u001b[0m                                    nn\u001b[38;5;241m.\u001b[39mBatchNorm3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_ch),\n\u001b[0;32m      3\u001b[0m                                    nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m         )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "conv3d_back = nn.Sequential(nn.Conv3d(4,128,kernel_size=1,padding=0),\n",
    "                                   nn.BatchNorm3d(),\n",
    "                                   nn.ReLU(inplace=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BottleNeckaSA(nn.Module):\n",
    "    def __init__(self,in_ch,reduction_ratio) -> None:\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = in_ch//reduction_ratio \n",
    "        self.gama = nn.Parameter(torch.tensor([0.0]))\n",
    "        self.conv3d = nn.Sequential(nn.Conv3d(self.in_ch,self.out_ch,kernel_size=1,padding=0)\n",
    "                                   # nn.BatchNorm3d(self.out_ch),\n",
    "                                   # nn.ReLU(inplace=True))\n",
    "        )\n",
    "        self.conv3d_3 = nn.Sequential(\n",
    "            # Conv3d input:N*C*D*H*W\n",
    "            # Conv3d output:N*C*D*H*W\n",
    "            nn.Conv3d(in_channels=self.out_ch, out_channels=self.out_ch, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.BatchNorm3d(self.out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv3d_1 = nn.Sequential(\n",
    "            # Conv3d input:N*C*D*H*W\n",
    "            # Conv3d output:N*C*D*H*W\n",
    "            nn.Conv3d(in_channels=self.out_ch, out_channels=self.out_ch, kernel_size=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(self.out_ch),\n",
    "            nn.ReLU(inplace=True), \n",
    "        )\n",
    "\n",
    "        self.conv3d_back = nn.Conv3d(self.out_ch,self.in_ch,kernel_size=1,padding=0)\n",
    "\n",
    "    def Cal_Patt(self,k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input : N*C*D*H*W\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "        k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "        q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "        v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        k_x_flatten = k_x.reshape((N, C, D, 1, H * W))\n",
    "        q_x_flatten = q_x.reshape((N, C, D, 1, H * W))\n",
    "        v_x_flatten = v_x.reshape((N, C, D, 1, H * W))\n",
    "        sigma_x = torch.mul(q_x_flatten.permute(0, 1, 2, 4, 3), k_x_flatten)\n",
    "        r_x = F.softmax(sigma_x, dim=4)\n",
    "        # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "        Patt = torch.matmul(v_x_flatten, r_x).reshape(N, C, D, H, W)\n",
    "        print(Patt.shape,'this is Patt shape')\n",
    "        return Patt\n",
    "\n",
    "    \n",
    "\n",
    "    def Cal_Datt(self,k_x, q_x, v_x, N, C, D, H, W):\n",
    "        \"\"\"\n",
    "        input:N*C*D*H*W\n",
    "        \"\"\"\n",
    "        ##first permute the input to N*C*D*H*W\n",
    "        k_x = k_x.permute(0, 1, 4, 2, 3)\n",
    "        q_x = q_x.permute(0, 1, 4, 2, 3)\n",
    "        v_x = v_x.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "\n",
    "        k_x_flatten = k_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        q_x_flatten = q_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        v_x_flatten = v_x.permute(0, 1, 3, 4, 2).reshape((N, C, H, W, 1, D))\n",
    "        print(k_x_flatten.shape,'this is k_x_flatten shape')\n",
    "        print(q_x_flatten.permute(0, 1, 2, 3, 5, 4).shape,'this is q_x_flatten shape')\n",
    "        sigma_x = torch.mul(q_x_flatten.permute(0, 1, 2, 3, 5, 4), k_x_flatten)\n",
    "        print(sigma_x.shape,'this is sigma_x shape')\n",
    "        r_x = F.softmax(sigma_x, dim=5)\n",
    "        # r_x = F.softmax(sigma_x.float(), dim=4)\n",
    "        Datt = torch.matmul(v_x_flatten, r_x).reshape(N, C, H, W, D)\n",
    "        return Datt.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape,'this is x shape')\n",
    "        x = self.conv3d(x)\n",
    "        N,C,H,W,D = x.shape\n",
    "        v_x = self.conv3d_3(x)\n",
    "        k_x = self.conv3d_1(x)\n",
    "        q_x = self.conv3d_1(x)\n",
    "        print('use SA block!')\n",
    "        print('this is v_x shape',v_x.shape)\n",
    "        Patt = self.Cal_Patt(k_x, q_x, v_x, N, C, D, H, W)\n",
    "        Datt = self.Cal_Datt(k_x, q_x, v_x, N, C, D, H, W)\n",
    "        print(Patt.shape,'this is Patt shape',Datt.shape,'this is Datt shape')\n",
    "        #reshape to N*C*H*W*D\n",
    "        Patt = Patt.permute(0, 1, 3, 4, 2)\n",
    "        Datt = Datt.permute(0, 1, 3, 4, 2)\n",
    "        Y = self.gama*(Patt + Datt) + x\n",
    "        Y = self.conv3d_back(Y)\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 32, 64, 64]) this is x shape\n",
      "use SA block!\n",
      "this is v_x shape torch.Size([1, 8, 32, 64, 64])\n",
      "torch.Size([1, 8, 64, 32, 64]) this is Patt shape\n",
      "torch.Size([1, 8, 32, 64, 1, 64]) this is k_x_flatten shape\n",
      "torch.Size([1, 8, 32, 64, 64, 1]) this is q_x_flatten shape\n",
      "torch.Size([1, 8, 32, 64, 64, 64]) this is sigma_x shape\n",
      "torch.Size([1, 8, 64, 32, 64]) this is Patt shape torch.Size([1, 8, 64, 32, 64]) this is Datt shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 1.1525e-01,  6.6346e-01,  3.1252e-01,  ...,  3.6658e-01,\n",
       "             3.2741e-01,  2.9626e-01],\n",
       "           [ 3.9656e-01, -3.0501e-01,  2.4778e-01,  ...,  7.9540e-01,\n",
       "             2.3046e-01,  6.5893e-01],\n",
       "           [ 2.9296e-01,  1.3077e-01, -1.4115e-01,  ...,  4.5326e-02,\n",
       "             5.7972e-01,  1.4928e-01],\n",
       "           ...,\n",
       "           [ 1.4158e-01,  3.9428e-01,  1.9215e-01,  ...,  2.3309e-01,\n",
       "            -8.6583e-03,  5.6914e-01],\n",
       "           [ 2.5204e-01,  5.3430e-01, -1.7072e-01,  ...,  5.8252e-01,\n",
       "            -1.8313e-01,  4.4504e-01],\n",
       "           [ 2.5722e-01,  6.7633e-01,  1.6469e-01,  ...,  2.9207e-01,\n",
       "             4.5034e-02,  6.7359e-01]],\n",
       "\n",
       "          [[ 4.9394e-01,  2.6833e-01,  8.1382e-02,  ..., -4.7966e-01,\n",
       "             5.2477e-01,  6.8762e-01],\n",
       "           [ 6.2212e-01,  5.4941e-01,  4.5430e-01,  ...,  6.0388e-01,\n",
       "             6.2243e-03,  4.6679e-01],\n",
       "           [ 1.2348e-02,  3.5363e-01,  6.7065e-01,  ..., -3.3760e-03,\n",
       "             5.2703e-01, -1.2464e-01],\n",
       "           ...,\n",
       "           [ 2.5156e-01,  3.3834e-01,  1.5462e-01,  ...,  2.3734e-01,\n",
       "             8.1488e-02,  2.9754e-01],\n",
       "           [ 5.0483e-01,  8.8974e-01,  3.1794e-01,  ...,  8.4384e-02,\n",
       "            -1.8457e-01,  5.3433e-02],\n",
       "           [ 4.9621e-01,  3.7704e-01,  5.7413e-01,  ..., -7.6573e-02,\n",
       "             5.8259e-01, -2.2366e-01]],\n",
       "\n",
       "          [[ 4.7678e-01,  3.1315e-01,  5.9696e-01,  ...,  1.3059e-01,\n",
       "            -4.3106e-01,  3.7317e-01],\n",
       "           [ 1.1419e-01, -1.0164e-01,  3.1848e-01,  ..., -8.2522e-02,\n",
       "             9.5673e-02,  5.3019e-01],\n",
       "           [ 4.8680e-01,  4.2392e-01, -9.2658e-02,  ...,  1.6856e-01,\n",
       "             5.7417e-01, -1.0585e-01],\n",
       "           ...,\n",
       "           [ 3.6450e-01,  3.7905e-01,  2.6835e-01,  ...,  1.3378e-01,\n",
       "            -5.0635e-02,  2.7943e-01],\n",
       "           [ 5.8201e-01,  4.3856e-01,  3.0958e-01,  ...,  8.9759e-01,\n",
       "             4.5988e-01, -8.5130e-02],\n",
       "           [ 4.6022e-01, -4.1770e-01,  1.4629e-01,  ..., -7.1980e-03,\n",
       "             2.1100e-01,  6.9162e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-8.2691e-02,  1.8261e-01,  3.8730e-02,  ...,  7.8617e-01,\n",
       "             6.2668e-01, -6.8490e-01],\n",
       "           [ 6.2843e-01,  9.3720e-02,  3.1337e-01,  ...,  6.1676e-01,\n",
       "             4.6970e-01,  2.2370e-01],\n",
       "           [-3.7096e-03,  5.1380e-01,  2.0517e-01,  ...,  8.2428e-01,\n",
       "             5.9296e-01,  6.5422e-01],\n",
       "           ...,\n",
       "           [ 2.7536e-01, -2.1894e-02,  2.6564e-01,  ...,  7.6973e-01,\n",
       "             6.0738e-01,  3.9870e-01],\n",
       "           [ 1.0758e+00,  2.4035e-01,  5.9868e-01,  ...,  6.4898e-01,\n",
       "             4.0822e-01,  5.1196e-01],\n",
       "           [-7.6290e-02,  4.9309e-01,  3.4050e-02,  ...,  4.4898e-01,\n",
       "             7.8141e-01, -1.9882e-01]],\n",
       "\n",
       "          [[ 7.8202e-01,  2.0800e-01,  1.3209e-01,  ...,  4.2417e-01,\n",
       "             1.0650e-01,  6.5644e-01],\n",
       "           [ 2.0784e-01,  8.8850e-02,  5.3263e-01,  ...,  6.9409e-02,\n",
       "             5.3530e-02, -1.5615e-01],\n",
       "           [ 9.0633e-01,  3.0037e-01,  2.7786e-01,  ...,  6.8444e-01,\n",
       "             2.2791e-01,  1.9662e-01],\n",
       "           ...,\n",
       "           [ 6.3367e-01,  6.0336e-01,  6.6561e-01,  ...,  4.2361e-01,\n",
       "             3.9357e-01,  6.4894e-01],\n",
       "           [ 5.6759e-01,  8.3422e-01,  4.4167e-01,  ...,  5.5417e-01,\n",
       "             1.5561e-01,  9.5949e-01],\n",
       "           [-6.0575e-02,  5.0766e-01,  2.7732e-01,  ...,  6.4966e-01,\n",
       "            -3.4894e-02,  3.7630e-01]],\n",
       "\n",
       "          [[-3.1162e-02,  1.7812e-01,  5.8907e-01,  ..., -9.3191e-02,\n",
       "            -4.1319e-02,  9.9053e-02],\n",
       "           [-3.6940e-02,  2.3216e-01,  6.3018e-01,  ...,  8.0657e-02,\n",
       "             4.8605e-01,  1.7039e-02],\n",
       "           [-3.6272e-01,  1.0753e-01,  3.1653e-02,  ...,  2.9267e-01,\n",
       "             5.7093e-01,  2.1576e-01],\n",
       "           ...,\n",
       "           [ 2.8172e-01,  2.4921e-01,  4.0669e-01,  ...,  4.5850e-01,\n",
       "             3.9335e-01,  2.1335e-01],\n",
       "           [ 9.2887e-02,  8.0003e-02, -7.7261e-02,  ..., -2.7271e-01,\n",
       "             3.6246e-01,  4.2689e-01],\n",
       "           [ 8.4400e-02,  2.1845e-01, -1.6652e-01,  ...,  2.2073e-01,\n",
       "             7.0749e-02,  5.0553e-01]]],\n",
       "\n",
       "\n",
       "         [[[-2.9357e-01, -8.3291e-01,  2.6014e-01,  ..., -6.5095e-01,\n",
       "            -3.5271e-01, -2.9848e-01],\n",
       "           [-5.3294e-01, -4.6581e-01,  1.0748e-01,  ..., -6.2005e-01,\n",
       "            -6.2187e-01, -9.5338e-01],\n",
       "           [-5.6514e-02, -3.0507e-01,  2.3476e-02,  ..., -1.8063e-01,\n",
       "            -8.4476e-01, -2.1116e-01],\n",
       "           ...,\n",
       "           [-2.5334e-03, -7.3873e-01, -8.9414e-01,  ..., -7.6190e-01,\n",
       "            -4.8802e-01, -6.2997e-01],\n",
       "           [-1.5961e-01, -3.1966e-01,  2.0202e-01,  ..., -5.8582e-01,\n",
       "            -4.6711e-01, -3.5851e-01],\n",
       "           [-1.4772e-01, -7.1587e-02, -6.9490e-03,  ..., -6.6537e-02,\n",
       "            -5.4785e-01, -3.9502e-01]],\n",
       "\n",
       "          [[-7.6116e-01, -3.6187e-01, -1.8045e-01,  ..., -3.5183e-01,\n",
       "            -5.5483e-01, -6.8227e-01],\n",
       "           [-4.6184e-01, -7.3612e-01, -3.9072e-01,  ..., -2.2517e-01,\n",
       "            -3.2839e-01, -1.0539e-01],\n",
       "           [-6.1043e-02,  1.1953e-01, -4.9912e-01,  ..., -3.0558e-01,\n",
       "            -6.1669e-01, -4.0981e-01],\n",
       "           ...,\n",
       "           [-8.4678e-01, -4.1724e-01, -4.8004e-01,  ...,  1.4515e-01,\n",
       "            -3.1362e-01, -6.3709e-01],\n",
       "           [-5.3550e-01, -9.0871e-01, -3.8217e-01,  ..., -2.9744e-01,\n",
       "            -9.4288e-03, -3.4698e-01],\n",
       "           [-7.0811e-01, -2.3380e-01, -8.9090e-01,  ...,  8.7887e-02,\n",
       "             8.3431e-02,  7.6710e-02]],\n",
       "\n",
       "          [[-5.7681e-01, -2.6020e-01, -1.2388e-01,  ..., -4.0578e-01,\n",
       "            -1.9528e-02, -2.9056e-01],\n",
       "           [-1.4448e-01,  1.8792e-01, -1.8465e-01,  ..., -3.2862e-01,\n",
       "            -2.1534e-01, -3.5898e-01],\n",
       "           [-1.0921e+00, -6.0104e-01, -2.6831e-01,  ...,  5.1554e-03,\n",
       "            -5.6659e-01, -1.0550e-01],\n",
       "           ...,\n",
       "           [-6.7303e-01, -2.6120e-02, -3.9344e-01,  ..., -1.2580e-01,\n",
       "            -7.7167e-02, -1.0526e-01],\n",
       "           [-5.5334e-01, -3.5976e-01, -7.1090e-01,  ...,  8.8080e-02,\n",
       "            -4.9047e-03, -2.0396e-01],\n",
       "           [-2.9927e-01, -3.8011e-01,  8.1223e-02,  ..., -4.7858e-01,\n",
       "            -5.2289e-01, -7.8597e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-1.6138e-01, -2.6592e-01, -3.9294e-01,  ..., -2.8938e-01,\n",
       "            -2.4887e-01,  2.0535e-01],\n",
       "           [-5.0648e-01,  4.3478e-02,  3.1122e-02,  ..., -6.6538e-01,\n",
       "            -4.3996e-01, -1.0647e-01],\n",
       "           [-3.1056e-01, -2.9504e-01, -5.0607e-01,  ..., -8.5002e-01,\n",
       "            -2.8812e-01, -6.6351e-01],\n",
       "           ...,\n",
       "           [-2.3661e-01, -7.7140e-01,  5.4743e-02,  ..., -2.4889e-01,\n",
       "            -3.1340e-01, -4.4845e-01],\n",
       "           [-9.0017e-01, -3.5562e-01, -7.8993e-01,  ..., -5.3018e-01,\n",
       "            -7.8990e-01, -2.0701e-01],\n",
       "           [-4.2690e-02, -6.7882e-01, -3.7827e-01,  ..., -3.2982e-01,\n",
       "            -5.6644e-01, -5.1699e-01]],\n",
       "\n",
       "          [[-7.0588e-01, -1.3655e-01, -3.8093e-01,  ..., -6.3270e-01,\n",
       "            -4.6290e-01, -6.3743e-01],\n",
       "           [-4.4657e-01, -7.8690e-02, -1.4601e-01,  ..., -5.9910e-01,\n",
       "            -1.8493e-01,  1.4235e-01],\n",
       "           [-6.2141e-01, -1.8474e-01,  7.3981e-02,  ..., -4.5509e-01,\n",
       "            -5.4191e-01, -3.1600e-01],\n",
       "           ...,\n",
       "           [-1.8486e-01, -2.7236e-01, -5.0148e-01,  ..., -4.9400e-01,\n",
       "            -8.0897e-01, -7.8706e-01],\n",
       "           [-1.5889e-01, -4.5037e-01, -5.6632e-01,  ...,  1.5475e-01,\n",
       "            -7.1529e-01, -6.9080e-01],\n",
       "           [-4.7093e-01, -1.0494e+00, -6.1651e-02,  ..., -6.3697e-01,\n",
       "            -2.3141e-01, -6.5647e-01]],\n",
       "\n",
       "          [[-2.9999e-01, -4.0800e-01, -2.4869e-01,  ..., -9.6240e-01,\n",
       "            -1.2661e-01, -6.3550e-04],\n",
       "           [-2.3566e-01, -5.6575e-02,  1.3065e-01,  ..., -5.1561e-01,\n",
       "            -3.3035e-01,  2.9879e-01],\n",
       "           [-3.2429e-01, -3.7765e-01, -9.6974e-02,  ..., -3.4568e-01,\n",
       "            -2.5752e-01, -4.2203e-01],\n",
       "           ...,\n",
       "           [-1.2451e-01, -1.2756e-01, -8.4581e-01,  ..., -3.3487e-01,\n",
       "            -6.7409e-01, -3.0878e-01],\n",
       "           [-9.7446e-02, -1.9138e-01, -3.2210e-01,  ..., -4.1676e-02,\n",
       "            -7.4046e-01, -5.3622e-01],\n",
       "           [-1.3874e-01, -7.1633e-01, -6.1260e-02,  ...,  1.4340e-01,\n",
       "            -3.9892e-01, -5.2860e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 2.2956e-02, -2.4878e-01, -3.0215e-02,  ..., -1.2017e-01,\n",
       "            -3.7342e-01, -7.2306e-02],\n",
       "           [-4.9875e-01, -3.3306e-01, -1.7271e-01,  ..., -6.4387e-02,\n",
       "            -8.2025e-02, -1.5295e-01],\n",
       "           [ 1.2541e-01, -6.8578e-02, -2.5909e-01,  ..., -2.4560e-01,\n",
       "            -3.8021e-01, -1.0044e-04],\n",
       "           ...,\n",
       "           [ 1.2489e-01, -4.9334e-02, -1.3630e-01,  ...,  6.7174e-02,\n",
       "            -1.5008e-01, -3.0524e-01],\n",
       "           [-3.9540e-01, -3.7954e-01, -1.4960e-01,  ...,  3.3585e-01,\n",
       "             3.2274e-01, -3.6431e-01],\n",
       "           [ 3.2090e-02, -2.4981e-01,  6.7644e-02,  ..., -4.0076e-01,\n",
       "            -9.2639e-02, -1.5426e-01]],\n",
       "\n",
       "          [[-2.0057e-01, -3.0248e-01, -4.1598e-02,  ..., -2.8022e-01,\n",
       "             1.3539e-01, -2.7101e-03],\n",
       "           [-3.5508e-01, -6.7853e-01, -1.7090e-01,  ..., -2.1343e-01,\n",
       "            -7.0315e-02, -1.0190e-01],\n",
       "           [ 1.0037e-01, -1.8593e-01, -2.7551e-02,  ...,  5.9905e-03,\n",
       "            -4.1310e-01, -5.1441e-01],\n",
       "           ...,\n",
       "           [-4.3005e-01, -1.3198e-01, -1.5681e-01,  ...,  2.4172e-01,\n",
       "             1.6373e-01,  1.2677e-01],\n",
       "           [-2.4383e-01,  4.7416e-02,  5.6949e-02,  ..., -1.3420e-02,\n",
       "            -7.6754e-03, -7.7521e-02],\n",
       "           [-1.4611e-01, -7.0601e-02, -1.7176e-01,  ...,  8.1488e-02,\n",
       "            -4.5645e-02, -1.8769e-01]],\n",
       "\n",
       "          [[-2.4779e-01, -1.3249e-01,  1.0596e-02,  ..., -2.7628e-01,\n",
       "            -2.7782e-01, -2.3177e-01],\n",
       "           [-5.2927e-01,  8.3404e-02,  5.3991e-02,  ..., -5.1063e-01,\n",
       "            -1.8385e-01,  1.8971e-02],\n",
       "           [-2.1151e-01, -8.1603e-02, -3.3140e-01,  ...,  2.1757e-01,\n",
       "            -1.5228e-01, -3.0262e-01],\n",
       "           ...,\n",
       "           [-1.3496e-01, -1.6874e-01, -5.5293e-02,  ...,  4.4779e-03,\n",
       "            -1.7229e-01, -3.0460e-01],\n",
       "           [-2.6242e-01, -3.4734e-01, -1.8911e-01,  ...,  2.3854e-01,\n",
       "             2.9092e-01, -2.1084e-01],\n",
       "           [ 4.0548e-02, -2.7629e-01,  2.0700e-01,  ...,  2.2107e-01,\n",
       "            -2.4669e-01, -5.4802e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-2.9379e-01, -2.2155e-01, -8.3108e-02,  ..., -1.1050e-01,\n",
       "            -3.2428e-01, -4.4833e-01],\n",
       "           [ 1.5555e-01, -1.6244e-01,  3.0279e-02,  ..., -3.3031e-01,\n",
       "            -2.2527e-02,  1.8786e-01],\n",
       "           [-1.3393e-01, -4.7523e-02, -9.2420e-02,  ..., -3.5223e-01,\n",
       "            -1.2601e-01, -1.5563e-01],\n",
       "           ...,\n",
       "           [-1.8539e-01, -2.1191e-01,  6.1644e-02,  ..., -3.4185e-01,\n",
       "            -3.0401e-01, -6.9698e-02],\n",
       "           [ 1.4245e-02, -7.3582e-02, -2.3112e-01,  ..., -2.2310e-01,\n",
       "            -1.6988e-01, -1.7915e-01],\n",
       "           [-9.5769e-03, -1.2562e-01,  9.8921e-02,  ..., -2.3432e-02,\n",
       "             4.1832e-02, -2.1538e-01]],\n",
       "\n",
       "          [[-1.5600e-01, -1.8219e-01, -1.4836e-02,  ..., -5.0145e-02,\n",
       "             8.5592e-02, -3.0023e-01],\n",
       "           [-5.9416e-01, -4.9700e-01, -3.4909e-01,  ..., -3.2616e-02,\n",
       "             1.3499e-01, -1.2995e-01],\n",
       "           [ 2.4957e-03, -1.5377e-02, -1.9256e-01,  ..., -2.2867e-02,\n",
       "            -1.5888e-01, -5.5295e-02],\n",
       "           ...,\n",
       "           [ 5.2411e-02, -4.6008e-01, -3.8833e-01,  ...,  1.6882e-01,\n",
       "             1.8322e-01, -2.3295e-01],\n",
       "           [-2.4419e-01, -6.3226e-02, -3.1056e-01,  ..., -3.0027e-01,\n",
       "            -6.1132e-01, -3.2776e-02],\n",
       "           [-1.9688e-01, -2.5531e-01, -1.1130e-01,  ..., -8.4847e-02,\n",
       "            -1.4367e-01,  9.9641e-04]],\n",
       "\n",
       "          [[-4.2047e-01,  9.8636e-02, -1.4235e-01,  ..., -2.3038e-01,\n",
       "             4.6990e-02, -2.9425e-01],\n",
       "           [-1.7938e-02, -2.0244e-01,  1.9879e-01,  ..., -3.6980e-01,\n",
       "            -3.1718e-02, -3.0788e-01],\n",
       "           [-2.5788e-01,  1.8956e-01,  2.0068e-02,  ..., -7.7906e-02,\n",
       "            -1.1444e-01, -9.1741e-03],\n",
       "           ...,\n",
       "           [-5.0507e-02,  2.7369e-01, -1.6910e-01,  ...,  7.3802e-02,\n",
       "             2.4977e-01, -3.1706e-01],\n",
       "           [-3.7826e-01, -5.1766e-02, -1.2547e-01,  ..., -2.0531e-01,\n",
       "             5.3524e-04, -3.2015e-02],\n",
       "           [-3.5320e-01, -3.3570e-01, -1.8150e-01,  ...,  1.8642e-01,\n",
       "            -8.5720e-02, -9.2141e-03]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[-5.4026e-02, -6.5204e-01,  5.5433e-01,  ...,  9.1423e-02,\n",
       "            -3.5669e-02, -1.5058e-01],\n",
       "           [-2.6936e-01,  1.0099e-01, -8.5101e-02,  ..., -2.1769e-01,\n",
       "             3.6552e-01, -5.6097e-01],\n",
       "           [ 9.0266e-02, -1.2001e-01,  1.9498e-01,  ...,  6.4857e-01,\n",
       "            -4.4842e-01,  2.3746e-01],\n",
       "           ...,\n",
       "           [-8.7457e-02,  3.1219e-01, -9.7776e-03,  ...,  1.5760e-01,\n",
       "             1.2473e-01, -3.4170e-01],\n",
       "           [-5.0859e-01,  8.1478e-02,  6.9562e-02,  ..., -1.3619e-02,\n",
       "             6.2895e-01, -4.9563e-01],\n",
       "           [ 4.4644e-01, -6.5281e-01, -2.7122e-02,  ...,  3.2338e-02,\n",
       "             6.2915e-02, -1.1524e-01]],\n",
       "\n",
       "          [[-5.3216e-01,  1.9670e-01,  1.8253e-01,  ...,  3.7569e-02,\n",
       "             1.0460e-01,  2.0966e-01],\n",
       "           [-1.9806e-02,  1.1669e-02,  2.8596e-01,  ..., -1.8503e-01,\n",
       "             3.6833e-01, -6.7016e-04],\n",
       "           [ 4.4850e-01, -8.2695e-02, -2.0612e-01,  ...,  1.9633e-01,\n",
       "            -5.2793e-02,  4.0381e-02],\n",
       "           ...,\n",
       "           [-2.6475e-03,  4.5570e-02, -5.4148e-01,  ...,  3.3587e-01,\n",
       "            -4.2167e-02, -2.8676e-01],\n",
       "           [-1.9089e-01, -1.4991e-01,  2.1363e-01,  ...,  5.3635e-01,\n",
       "             2.6696e-01, -3.5381e-01],\n",
       "           [-9.7502e-02, -2.7302e-01,  2.3639e-01,  ...,  3.5650e-01,\n",
       "            -3.5185e-01,  6.8115e-01]],\n",
       "\n",
       "          [[-2.9300e-01, -1.7348e-01,  6.4255e-01,  ...,  4.3958e-01,\n",
       "            -2.8959e-03,  9.5732e-02],\n",
       "           [ 7.9599e-02,  2.2271e-01,  1.9780e-01,  ...,  9.8514e-02,\n",
       "            -3.5363e-01,  4.2972e-01],\n",
       "           [-3.6598e-01,  2.0181e-01,  7.0169e-02,  ...,  2.1609e-01,\n",
       "            -1.4275e-01, -6.5638e-02],\n",
       "           ...,\n",
       "           [-2.8310e-02, -5.4100e-02, -1.4257e-01,  ...,  2.7271e-01,\n",
       "             1.4078e-01, -6.7765e-01],\n",
       "           [ 8.1498e-02, -3.8954e-01, -2.8541e-01,  ..., -4.0336e-01,\n",
       "             1.8493e-01, -1.6292e-01],\n",
       "           [-3.0161e-01, -3.5703e-02,  4.2518e-02,  ...,  3.0595e-01,\n",
       "             1.3979e-01, -5.0930e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-4.2649e-01, -3.5269e-01, -9.6661e-02,  ..., -1.3709e-01,\n",
       "            -3.2090e-01,  3.1786e-01],\n",
       "           [ 1.3583e-01,  1.4139e-01, -1.4209e-02,  ...,  5.7665e-01,\n",
       "             3.5554e-01, -8.8053e-02],\n",
       "           [-2.7529e-01,  3.3744e-01, -2.5978e-01,  ..., -1.1218e-01,\n",
       "             2.3431e-01, -1.5751e-01],\n",
       "           ...,\n",
       "           [-3.4964e-01,  3.7677e-01,  2.8717e-01,  ..., -3.3768e-01,\n",
       "            -2.0736e-01, -7.3171e-02],\n",
       "           [-1.3108e-01,  2.3180e-01, -2.3882e-01,  ..., -1.9870e-01,\n",
       "            -3.3841e-01, -4.4704e-01],\n",
       "           [-4.0173e-02,  3.9323e-02,  6.7211e-01,  ...,  1.4289e-01,\n",
       "            -1.0448e-01,  2.8312e-01]],\n",
       "\n",
       "          [[-6.2947e-01,  3.7518e-01,  5.0781e-02,  ..., -1.6024e-01,\n",
       "             1.5493e-01,  1.1792e-01],\n",
       "           [-4.7535e-01, -5.7881e-01,  3.8795e-01,  ...,  5.1466e-01,\n",
       "             1.5029e-01,  1.7811e-01],\n",
       "           [-3.4768e-01,  5.1722e-01, -6.1493e-02,  ..., -2.4545e-02,\n",
       "             3.5467e-01,  3.4332e-01],\n",
       "           ...,\n",
       "           [-2.0598e-01, -6.4281e-01, -2.8539e-01,  ...,  1.7316e-01,\n",
       "            -2.6489e-02, -3.8458e-01],\n",
       "           [-4.4974e-01,  1.4175e-01, -5.4161e-01,  ...,  4.1921e-01,\n",
       "             1.3970e-02, -2.6619e-02],\n",
       "           [-3.4156e-01,  1.8291e-01, -3.0609e-01,  ...,  7.2884e-02,\n",
       "            -1.3828e-01, -8.5460e-02]],\n",
       "\n",
       "          [[ 9.9956e-02, -4.6328e-01, -1.1583e-01,  ...,  7.1649e-02,\n",
       "             4.0922e-01,  2.3219e-01],\n",
       "           [ 5.8247e-02,  1.6032e-01, -4.5034e-01,  ...,  2.2087e-01,\n",
       "             9.3069e-02,  1.6362e-02],\n",
       "           [ 2.3144e-01, -3.2199e-01,  2.3126e-01,  ...,  3.2007e-02,\n",
       "             1.9393e-01,  3.0548e-01],\n",
       "           ...,\n",
       "           [ 2.4977e-01,  2.7582e-01, -9.6134e-02,  ...,  3.2619e-01,\n",
       "             6.6907e-02,  2.6953e-02],\n",
       "           [ 4.8495e-02,  2.7635e-01, -7.7888e-02,  ...,  2.9741e-01,\n",
       "            -2.0734e-01, -7.3194e-02],\n",
       "           [-2.7588e-01, -6.9814e-02,  4.2543e-01,  ...,  2.3375e-01,\n",
       "             3.2408e-01,  1.2462e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 2.4306e-01,  8.3360e-01,  2.3836e-01,  ...,  5.7741e-01,\n",
       "             2.2637e-01,  3.0524e-01],\n",
       "           [ 6.0368e-01, -1.8934e-01,  2.0089e-01,  ...,  7.5838e-01,\n",
       "             1.9007e-01,  1.0909e+00],\n",
       "           [ 2.7441e-01,  2.9234e-01, -2.0809e-01,  ..., -1.2703e-01,\n",
       "             1.0571e+00,  2.0966e-01],\n",
       "           ...,\n",
       "           [ 1.4553e-01,  2.8835e-01,  4.0955e-01,  ...,  4.2410e-01,\n",
       "             1.5806e-01,  7.2153e-01],\n",
       "           [ 1.7082e-01,  5.5345e-01, -3.4973e-01,  ...,  6.1070e-01,\n",
       "            -1.3390e-01,  4.7614e-01],\n",
       "           [ 3.4101e-01,  4.2246e-01,  1.2237e-01,  ...,  3.4668e-01,\n",
       "             1.8713e-01,  7.5000e-01]],\n",
       "\n",
       "          [[ 8.3530e-01,  4.0872e-01,  4.7512e-02,  ..., -5.0307e-01,\n",
       "             5.9813e-01,  1.0814e+00],\n",
       "           [ 6.5941e-01,  7.4641e-01,  6.0280e-01,  ...,  7.6806e-01,\n",
       "            -6.7305e-03,  5.9355e-01],\n",
       "           [-1.3440e-02,  4.0396e-01,  6.1925e-01,  ...,  1.6829e-02,\n",
       "             8.5336e-01, -1.7487e-01],\n",
       "           ...,\n",
       "           [ 4.4009e-01,  5.0969e-01,  3.5289e-01,  ...,  5.1779e-02,\n",
       "             1.3079e-01,  6.0251e-01],\n",
       "           [ 7.9872e-01,  1.0881e+00,  4.1916e-01,  ...,  2.5341e-01,\n",
       "            -2.3569e-01,  3.1801e-02],\n",
       "           [ 6.2344e-01,  4.1392e-01,  9.3524e-01,  ..., -1.5974e-01,\n",
       "             5.8828e-01, -2.5374e-01]],\n",
       "\n",
       "          [[ 6.3656e-01,  5.9197e-01,  4.0555e-01,  ...,  1.3126e-01,\n",
       "            -4.8524e-01,  5.2334e-01],\n",
       "           [-1.9503e-02, -1.4197e-01,  3.9151e-01,  ..., -4.0176e-02,\n",
       "             3.8367e-02,  4.5433e-01],\n",
       "           [ 7.5517e-01,  6.7255e-01,  4.9747e-02,  ...,  2.2725e-01,\n",
       "             6.9176e-01, -1.4823e-02],\n",
       "           ...,\n",
       "           [ 5.5519e-01,  2.6070e-01,  3.4324e-01,  ..., -6.6984e-04,\n",
       "            -6.9216e-03,  4.4802e-01],\n",
       "           [ 7.5222e-01,  6.2157e-01,  5.3028e-01,  ...,  9.2212e-01,\n",
       "             5.6970e-01,  2.4516e-02],\n",
       "           [ 5.2126e-01, -5.0243e-01,  4.9965e-02,  ...,  1.5024e-01,\n",
       "             1.7429e-01,  1.0398e+00]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 3.5650e-02,  5.0703e-01,  1.4461e-02,  ...,  8.3599e-01,\n",
       "             6.7935e-01, -1.0172e+00],\n",
       "           [ 7.5303e-01, -7.4687e-03,  2.8247e-01,  ...,  6.7680e-01,\n",
       "             5.9594e-01,  3.8944e-01],\n",
       "           [-5.8291e-02,  4.8920e-01,  2.8237e-01,  ...,  1.2486e+00,\n",
       "             6.1981e-01,  8.2064e-01],\n",
       "           ...,\n",
       "           [ 2.2096e-01,  2.1905e-01,  1.0365e-01,  ...,  7.2958e-01,\n",
       "             6.7728e-01,  5.7709e-01],\n",
       "           [ 1.3919e+00,  2.3776e-01,  8.4132e-01,  ...,  7.8213e-01,\n",
       "             5.8764e-01,  3.2248e-01],\n",
       "           [-2.0400e-01,  6.9993e-01, -9.2360e-02,  ...,  5.5210e-01,\n",
       "             8.5601e-01, -1.0778e-01]],\n",
       "\n",
       "          [[ 1.0483e+00,  2.3925e-01,  1.8986e-01,  ...,  6.6052e-01,\n",
       "             2.5146e-01,  7.3728e-01],\n",
       "           [ 3.0108e-02,  2.0540e-01,  5.4945e-01,  ...,  3.2209e-02,\n",
       "             4.9377e-02, -1.0996e-01],\n",
       "           [ 1.1424e+00, -6.5736e-03,  2.4829e-01,  ...,  1.0299e+00,\n",
       "             4.9459e-01,  2.5755e-01],\n",
       "           ...,\n",
       "           [ 6.4546e-01,  7.7310e-01,  7.8411e-01,  ...,  4.7663e-02,\n",
       "             5.3020e-01,  8.9007e-01],\n",
       "           [ 6.5556e-01,  7.0697e-01,  7.3635e-01,  ...,  4.9698e-01,\n",
       "             4.0095e-01,  1.3422e+00],\n",
       "           [ 2.2380e-01,  7.9886e-01,  2.3729e-01,  ...,  7.2276e-01,\n",
       "            -1.1549e-01,  6.8997e-01]],\n",
       "\n",
       "          [[-7.1181e-02,  1.4213e-01,  5.0422e-01,  ...,  1.8934e-01,\n",
       "            -1.7075e-01,  4.3486e-03],\n",
       "           [-3.6942e-03,  1.5850e-01,  5.8105e-01,  ...,  1.4635e-01,\n",
       "             5.7734e-01, -1.1688e-01],\n",
       "           [-4.4920e-01,  8.6892e-02,  2.7672e-02,  ...,  3.7827e-01,\n",
       "             5.9742e-01,  3.9024e-01],\n",
       "           ...,\n",
       "           [ 2.4729e-01,  2.3886e-01,  7.3274e-01,  ...,  5.3218e-01,\n",
       "             2.7769e-01,  3.4455e-01],\n",
       "           [ 4.7103e-03,  1.6839e-01, -4.3506e-02,  ..., -2.5912e-01,\n",
       "             5.7717e-01,  6.5420e-01],\n",
       "           [ 2.8082e-01,  4.9592e-01, -1.8423e-01,  ...,  1.4993e-01,\n",
       "             1.5121e-01,  5.7075e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 4.1854e-02, -3.1057e-01, -3.1567e-01,  ...,  3.7600e-01,\n",
       "            -2.4525e-01, -1.0245e-01],\n",
       "           [-2.3878e-01, -2.5876e-01, -4.7141e-01,  ..., -5.4856e-02,\n",
       "            -2.2188e-01,  3.1786e-01],\n",
       "           [-3.5439e-01,  2.2745e-01, -6.3580e-01,  ..., -1.3398e-01,\n",
       "             3.5091e-01,  1.4294e-01],\n",
       "           ...,\n",
       "           [-1.1017e-01, -2.5665e-01,  1.3959e-01,  ...,  2.2359e-01,\n",
       "            -1.5683e-01, -4.0716e-02],\n",
       "           [-4.5864e-01, -2.1144e-01, -6.2509e-01,  ...,  2.6333e-01,\n",
       "             2.5738e-01, -5.0809e-01],\n",
       "           [ 4.7192e-01, -4.2960e-01, -7.5480e-02,  ..., -6.0588e-01,\n",
       "             6.9196e-02, -9.8880e-02]],\n",
       "\n",
       "          [[ 3.1520e-02, -4.9536e-02, -1.0586e-01,  ...,  4.9153e-02,\n",
       "             2.9760e-01,  2.5225e-01],\n",
       "           [-2.8555e-01, -2.3524e-01, -1.5601e-01,  ..., -1.2256e-01,\n",
       "            -4.6810e-01,  1.1138e-01],\n",
       "           [ 1.6633e-01, -1.9024e-01, -1.4818e-01,  ...,  3.4584e-01,\n",
       "             4.3739e-02, -4.0897e-01],\n",
       "           ...,\n",
       "           [-6.6762e-03, -2.5296e-02,  1.7042e-01,  ...,  1.5389e-03,\n",
       "             5.1398e-02,  3.1173e-01],\n",
       "           [ 3.0716e-01,  1.1031e-01, -1.2392e-01,  ...,  1.2538e-01,\n",
       "             3.8612e-02,  3.5270e-02],\n",
       "           [ 1.4318e-01, -9.4900e-02,  3.6726e-01,  ..., -1.3365e-01,\n",
       "            -1.3252e-01, -4.3243e-01]],\n",
       "\n",
       "          [[-1.6753e-01,  3.1455e-02, -2.6321e-01,  ..., -7.5246e-02,\n",
       "            -3.5495e-01, -1.6970e-01],\n",
       "           [-7.6843e-01, -1.1789e-01,  1.3473e-01,  ..., -3.8088e-01,\n",
       "            -1.2644e-01,  8.9777e-02],\n",
       "           [ 5.6193e-02,  2.4472e-01, -4.2956e-01,  ..., -3.8841e-02,\n",
       "            -2.1512e-02, -2.2236e-01],\n",
       "           ...,\n",
       "           [-1.9397e-02, -3.3857e-01,  3.8743e-02,  ..., -1.7798e-02,\n",
       "             2.0939e-02, -1.8388e-01],\n",
       "           [-4.1638e-01,  2.1417e-01,  3.6479e-01,  ...,  2.6683e-01,\n",
       "             7.1747e-02,  8.4259e-02],\n",
       "           [-5.9511e-02, -3.3180e-01,  1.8289e-01,  ...,  3.9910e-01,\n",
       "            -2.5898e-01, -7.2207e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-1.7191e-01,  3.3592e-02,  4.9309e-02,  ..., -2.8364e-01,\n",
       "            -1.6327e-01, -7.0532e-01],\n",
       "           [ 5.6375e-02, -1.0574e-01, -3.8099e-01,  ..., -6.1897e-01,\n",
       "             3.5179e-01,  2.5573e-01],\n",
       "           [-4.7858e-01, -5.7291e-01, -9.9352e-03,  ...,  9.0134e-02,\n",
       "            -1.4491e-01, -2.5616e-01],\n",
       "           ...,\n",
       "           [-1.6579e-01,  6.3685e-02, -2.3426e-01,  ..., -4.8531e-01,\n",
       "            -5.7862e-01,  2.4968e-01],\n",
       "           [ 4.7130e-01, -8.2835e-02,  1.8314e-01,  ...,  1.3149e-01,\n",
       "             5.6989e-02, -4.3739e-01],\n",
       "           [-1.2444e-01, -2.0568e-02, -4.7266e-02,  ...,  1.1635e-01,\n",
       "            -1.7718e-01,  3.9428e-02]],\n",
       "\n",
       "          [[ 5.4573e-02,  4.7973e-03,  4.9743e-02,  ...,  1.0635e-01,\n",
       "             2.1749e-01, -1.3185e-01],\n",
       "           [-4.6612e-01, -2.9571e-01, -5.6752e-01,  ...,  6.1099e-02,\n",
       "             1.6683e-01,  1.3470e-02],\n",
       "           [-3.0594e-02, -3.9427e-01, -3.1821e-01,  ...,  2.8860e-01,\n",
       "             1.0078e-01, -1.0308e-01],\n",
       "           ...,\n",
       "           [-8.9734e-02, -4.2033e-01, -6.1870e-01,  ..., -6.1047e-01,\n",
       "             5.2998e-01, -4.1216e-01],\n",
       "           [-6.5005e-01, -3.2874e-01, -2.2713e-01,  ..., -5.2243e-01,\n",
       "            -3.5698e-01,  2.6255e-01],\n",
       "           [-1.2052e-01, -5.5557e-02, -3.4352e-01,  ...,  1.3641e-01,\n",
       "            -2.5296e-01,  1.6089e-01]],\n",
       "\n",
       "          [[-4.1804e-01,  8.0376e-02, -1.8084e-01,  ...,  8.8804e-02,\n",
       "            -1.1647e-02, -3.0325e-01],\n",
       "           [-3.4646e-01, -7.2000e-01, -1.8572e-01,  ..., -3.5504e-01,\n",
       "            -4.4974e-02, -3.7990e-01],\n",
       "           [-1.4848e-01,  6.3200e-01,  3.9798e-01,  ..., -1.0348e-01,\n",
       "             1.0433e-02,  2.4763e-02],\n",
       "           ...,\n",
       "           [-1.2467e-01,  9.6503e-02,  5.3382e-02,  ...,  4.8035e-01,\n",
       "             2.4960e-01, -3.6593e-01],\n",
       "           [-9.3481e-01,  3.1217e-01, -3.7306e-02,  ..., -1.2429e-01,\n",
       "             2.2526e-01,  3.1363e-01],\n",
       "           [-1.8960e-01, -1.7472e-02, -1.6397e-01,  ..., -2.1790e-01,\n",
       "            -6.3605e-02,  6.2179e-02]]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BottleNeckaSA(256,32)\n",
    "model(torch.randn(1,256,32,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[655], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 定义损失函数和优化器\u001b[39;00m\n\u001b[0;32m     24\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m---> 25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n\u001b[0;32m     28\u001b[0m pre_y \u001b[38;5;241m=\u001b[39m model(x)\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\optim\\sgd.py:109\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov \u001b[38;5;129;01mand\u001b[39;00m (momentum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dampening \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSGD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\098986\\AppData\\Local\\anaconda3\\envs\\CILM\\lib\\site-packages\\torch\\optim\\optimizer.py:61\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     59\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     63\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net4, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linears[0](x)\n",
    "        x = self.linears[1](x)\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "        self.linears = nn.ModuleList([nn.Linear(5, 10), nn.Linear(10,1)])\n",
    "\n",
    "        return x\n",
    "\n",
    "# 随机数据\n",
    "\n",
    "\n",
    "# 实例化模型\n",
    "model = net4()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# 前向传播\n",
    "pre_y = model(x)\n",
    "\n",
    "# 计算损失\n",
    "loss = criterion(pre_y, y)\n",
    "\n",
    "# 反向传播和优化\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# 打印损失值\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[[ 2.2439e-02,  3.2549e-03, -1.6726e-02,  ..., -3.2928e-03,\n",
      "            -1.8176e-02, -2.8409e-03],\n",
      "           [ 2.9321e-02,  4.5281e-02, -6.9433e-03,  ..., -3.2345e-02,\n",
      "            -3.1847e-03, -2.6872e-02],\n",
      "           [ 2.5449e-02,  3.1545e-02,  1.6983e-02,  ...,  1.2646e-02,\n",
      "            -1.3209e-02,  3.0104e-02],\n",
      "           ...,\n",
      "           [-4.1175e-03, -1.6986e-02, -2.5687e-03,  ..., -1.0740e-02,\n",
      "             2.1712e-02,  1.0143e-02],\n",
      "           [-8.0403e-03,  6.3648e-03,  2.7567e-02,  ..., -2.6513e-02,\n",
      "            -1.2469e-02,  3.3873e-02],\n",
      "           [ 2.0681e-02,  2.8296e-02,  2.4978e-02,  ..., -4.2387e-03,\n",
      "            -1.1834e-02,  4.5992e-02]],\n",
      "\n",
      "          [[ 2.3898e-03, -4.1775e-03,  1.9018e-02,  ...,  6.0406e-03,\n",
      "            -6.4748e-03, -3.3573e-02],\n",
      "           [ 2.4411e-02,  1.4594e-02, -1.3210e-02,  ...,  1.2709e-02,\n",
      "            -6.5090e-03,  2.0306e-02],\n",
      "           [-4.5963e-03, -8.5706e-03,  1.1059e-02,  ...,  4.7477e-03,\n",
      "            -2.4863e-02, -4.0586e-03],\n",
      "           ...,\n",
      "           [-5.4323e-03,  2.2031e-02,  1.5309e-02,  ..., -3.2621e-02,\n",
      "             2.2716e-02, -3.3125e-02],\n",
      "           [ 2.3165e-03, -1.9623e-03, -4.1169e-02,  ...,  2.9735e-03,\n",
      "            -2.7642e-02, -1.3873e-02],\n",
      "           [-2.5064e-02,  2.5144e-02, -8.3289e-03,  ...,  9.8806e-03,\n",
      "             3.7510e-02,  3.0686e-03]],\n",
      "\n",
      "          [[ 1.4203e-02,  2.8785e-02, -6.2378e-03,  ..., -6.9376e-03,\n",
      "            -5.5781e-03,  1.4932e-02],\n",
      "           [-5.4376e-04, -2.0232e-02, -1.4013e-02,  ...,  1.4148e-02,\n",
      "            -6.7113e-03, -1.8802e-02],\n",
      "           [ 8.4099e-03,  4.8225e-02, -2.4514e-04,  ...,  2.9920e-02,\n",
      "             4.2439e-03,  1.0342e-02],\n",
      "           ...,\n",
      "           [-2.2693e-02, -2.4797e-02,  4.7577e-03,  ..., -6.6821e-03,\n",
      "            -1.6925e-02,  8.8587e-03],\n",
      "           [-4.1744e-02, -2.1466e-02, -7.9959e-03,  ...,  1.4705e-02,\n",
      "            -3.6333e-04,  4.6255e-04],\n",
      "           [ 1.2401e-02, -3.4300e-02,  1.6542e-02,  ...,  2.9721e-03,\n",
      "             8.4017e-03,  1.6611e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-2.0281e-02, -2.4217e-02,  2.2494e-02,  ..., -9.4588e-03,\n",
      "             2.0939e-02,  1.5114e-02],\n",
      "           [-2.0332e-03, -2.0085e-02,  1.6472e-02,  ...,  3.6473e-03,\n",
      "             1.5064e-02,  4.1035e-02],\n",
      "           [-5.6061e-03, -3.0407e-02, -1.1562e-02,  ...,  1.0303e-02,\n",
      "            -4.8830e-03,  4.8440e-03],\n",
      "           ...,\n",
      "           [ 1.6231e-02,  1.5104e-02, -2.6152e-02,  ..., -1.4188e-02,\n",
      "             1.0548e-02,  2.1017e-02],\n",
      "           [-1.2855e-02, -1.4734e-02,  2.1619e-02,  ...,  7.9773e-03,\n",
      "             6.8329e-03,  7.9459e-03],\n",
      "           [-1.3211e-02, -1.9084e-02, -3.1672e-02,  ...,  6.0773e-02,\n",
      "             1.1475e-02,  1.3127e-02]],\n",
      "\n",
      "          [[ 1.0169e-02,  3.2783e-03, -2.3738e-02,  ...,  2.7551e-03,\n",
      "            -9.2467e-03,  2.3152e-02],\n",
      "           [-2.4245e-02,  1.1901e-02,  3.0180e-02,  ...,  4.3345e-02,\n",
      "            -1.6309e-02,  6.0670e-03],\n",
      "           [-1.6686e-02, -1.4405e-02,  1.1081e-02,  ..., -9.6074e-03,\n",
      "             5.1782e-03, -1.5310e-02],\n",
      "           ...,\n",
      "           [ 4.7160e-03,  3.7919e-02,  2.3626e-02,  ..., -2.5070e-02,\n",
      "            -1.8963e-02,  1.2164e-02],\n",
      "           [-1.4303e-02, -2.3596e-02, -2.2762e-03,  ...,  7.9688e-04,\n",
      "             3.0715e-03,  2.9645e-02],\n",
      "           [ 1.6398e-03, -8.8734e-04, -8.2389e-03,  ...,  6.0034e-03,\n",
      "            -7.8935e-03, -1.9635e-02]],\n",
      "\n",
      "          [[ 1.2643e-02, -1.4055e-02,  7.2203e-03,  ...,  5.5112e-03,\n",
      "             1.8267e-02,  1.7957e-02],\n",
      "           [-2.2754e-02, -1.0285e-03,  1.2403e-02,  ...,  4.0853e-03,\n",
      "            -1.3836e-03,  2.1414e-02],\n",
      "           [-2.7804e-03, -1.3581e-02, -2.0958e-02,  ...,  2.4712e-02,\n",
      "            -1.1690e-02, -1.0201e-02],\n",
      "           ...,\n",
      "           [ 1.3226e-02,  4.7816e-03,  2.3957e-04,  ...,  6.2437e-04,\n",
      "            -2.1551e-02,  4.1961e-02],\n",
      "           [ 1.8133e-02, -3.6540e-02,  3.3035e-02,  ..., -7.7863e-03,\n",
      "             3.2847e-02, -3.1451e-02],\n",
      "           [ 8.8037e-03, -1.6680e-02,  2.7590e-02,  ...,  8.7376e-03,\n",
      "             1.2824e-02,  4.4241e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.0182e-02, -5.5862e-04, -2.2637e-02,  ..., -2.0081e-02,\n",
      "             1.6906e-03,  2.8054e-02],\n",
      "           [ 1.4631e-02,  1.6152e-03,  1.9747e-02,  ...,  1.3391e-02,\n",
      "            -1.4337e-02, -1.2485e-02],\n",
      "           [ 8.7130e-03,  7.4962e-03, -1.3067e-02,  ...,  1.6804e-02,\n",
      "            -1.7027e-02, -6.8712e-03],\n",
      "           ...,\n",
      "           [ 1.7513e-03, -2.6833e-02, -9.6744e-03,  ..., -1.4474e-03,\n",
      "            -8.3169e-03, -2.1711e-02],\n",
      "           [ 1.7653e-02, -1.2235e-02,  3.6266e-02,  ..., -1.6976e-02,\n",
      "            -1.1756e-02,  2.2575e-02],\n",
      "           [ 1.8116e-02,  1.6407e-02, -3.9042e-03,  ...,  8.1734e-03,\n",
      "             5.9642e-03,  1.4757e-02]],\n",
      "\n",
      "          [[ 1.8545e-03, -2.8283e-03, -1.7433e-02,  ...,  2.0705e-02,\n",
      "             1.9495e-02, -4.2052e-03],\n",
      "           [ 1.6301e-02, -4.2118e-03, -2.0872e-02,  ..., -3.3863e-03,\n",
      "             5.1511e-03, -4.7707e-02],\n",
      "           [-1.6694e-02,  2.0812e-03,  2.3339e-02,  ..., -3.1343e-02,\n",
      "            -2.3215e-02,  4.2508e-02],\n",
      "           ...,\n",
      "           [-5.9767e-03, -3.6606e-03,  1.8004e-02,  ..., -2.1627e-02,\n",
      "             5.7896e-04, -5.5330e-04],\n",
      "           [ 1.2417e-02,  1.0207e-02, -1.2745e-02,  ..., -2.0145e-02,\n",
      "             1.8990e-02,  7.7889e-03],\n",
      "           [ 1.9528e-02,  5.1201e-04, -1.1258e-02,  ..., -9.4616e-03,\n",
      "             7.0091e-03,  1.2547e-02]],\n",
      "\n",
      "          [[ 3.6880e-05, -2.7827e-03, -4.1668e-03,  ...,  4.4453e-03,\n",
      "            -1.5945e-02,  2.5750e-02],\n",
      "           [ 2.3406e-02, -1.9843e-02, -2.1663e-03,  ..., -1.2921e-02,\n",
      "             4.8467e-02,  1.2482e-03],\n",
      "           [-2.7836e-02,  4.4812e-02,  1.2242e-02,  ..., -2.3687e-03,\n",
      "            -1.8077e-02, -7.1682e-03],\n",
      "           ...,\n",
      "           [ 1.9912e-02,  7.1707e-03,  1.1781e-02,  ...,  2.4954e-02,\n",
      "            -1.8395e-02, -2.2405e-02],\n",
      "           [ 1.3283e-03,  2.6041e-02, -6.2231e-03,  ...,  3.6492e-03,\n",
      "            -4.0172e-03, -3.3875e-02],\n",
      "           [ 3.5228e-02,  2.5511e-04,  1.4645e-02,  ..., -2.4057e-02,\n",
      "             1.2014e-02,  1.4753e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 6.6272e-03,  1.4543e-02,  1.9028e-02,  ...,  1.1127e-03,\n",
      "            -1.8755e-02,  2.8265e-02],\n",
      "           [-3.4340e-03, -4.4699e-03,  3.1258e-02,  ...,  5.0107e-03,\n",
      "             3.0121e-04, -4.8903e-02],\n",
      "           [-7.6844e-03, -5.0223e-02,  3.2446e-02,  ..., -2.3005e-02,\n",
      "            -2.4935e-02,  4.0341e-02],\n",
      "           ...,\n",
      "           [ 2.0549e-02, -2.0413e-02,  2.9612e-02,  ...,  9.1264e-03,\n",
      "            -6.7068e-03,  1.2242e-03],\n",
      "           [ 6.6726e-03, -1.7424e-02,  2.2728e-02,  ..., -2.1315e-02,\n",
      "             1.1938e-02, -4.1123e-02],\n",
      "           [-1.8789e-02,  6.5099e-04,  3.8325e-02,  ..., -2.7610e-02,\n",
      "            -1.0864e-02, -6.1627e-04]],\n",
      "\n",
      "          [[ 3.8727e-02,  2.2868e-02,  1.9288e-02,  ...,  1.0092e-02,\n",
      "            -1.6693e-03, -1.1569e-03],\n",
      "           [-1.5328e-02,  6.5240e-03, -1.3963e-02,  ..., -2.5389e-02,\n",
      "             1.0321e-03, -1.2883e-02],\n",
      "           [ 1.6495e-02,  3.3089e-02,  2.4049e-03,  ...,  1.1468e-02,\n",
      "             1.1037e-02, -6.4474e-03],\n",
      "           ...,\n",
      "           [-2.3347e-02,  1.0041e-02,  2.8450e-02,  ...,  1.8675e-02,\n",
      "            -7.8773e-03, -4.0168e-03],\n",
      "           [ 3.8942e-02,  8.3327e-03,  2.0997e-02,  ..., -5.2898e-03,\n",
      "            -8.2093e-03, -1.2692e-02],\n",
      "           [ 6.3657e-03,  3.0845e-02,  2.4939e-02,  ...,  2.2669e-02,\n",
      "            -1.2473e-02, -1.8734e-02]],\n",
      "\n",
      "          [[-3.5142e-02, -1.1724e-02,  8.7314e-04,  ..., -1.7328e-02,\n",
      "            -1.8204e-03,  3.0733e-03],\n",
      "           [ 1.4408e-02,  2.2174e-02, -9.1955e-03,  ...,  1.6402e-02,\n",
      "            -4.1594e-02, -1.2743e-02],\n",
      "           [ 5.2973e-03,  2.5645e-02,  2.2412e-02,  ..., -8.2802e-03,\n",
      "             1.3441e-02,  8.9526e-03],\n",
      "           ...,\n",
      "           [-1.8755e-02,  1.0268e-02, -4.1020e-03,  ...,  4.4900e-03,\n",
      "             1.1960e-02,  1.0904e-02],\n",
      "           [ 2.1045e-02,  1.1025e-02,  1.2522e-02,  ..., -6.2756e-03,\n",
      "            -8.7465e-03, -2.0791e-02],\n",
      "           [ 8.7025e-03,  1.2018e-02, -1.6589e-03,  ...,  1.8099e-02,\n",
      "             4.0538e-03,  1.6001e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.4845e-02, -6.5641e-03, -2.1288e-02,  ..., -4.6786e-03,\n",
      "            -1.4492e-02, -8.2980e-03],\n",
      "           [-3.2434e-03, -3.1073e-02, -3.5170e-02,  ..., -1.1369e-02,\n",
      "             2.4852e-02,  2.3120e-02],\n",
      "           [-2.8350e-03,  1.8879e-02,  3.4388e-02,  ..., -2.8703e-03,\n",
      "            -4.2917e-03, -2.3269e-02],\n",
      "           ...,\n",
      "           [ 1.8179e-03,  2.2550e-02,  1.0965e-02,  ...,  5.8989e-03,\n",
      "             4.6841e-02, -5.9518e-03],\n",
      "           [-8.9371e-03, -2.2337e-02, -2.4114e-02,  ..., -2.3450e-03,\n",
      "             4.6870e-05, -3.5782e-03],\n",
      "           [ 2.3014e-02,  2.3956e-02,  9.6882e-03,  ..., -1.9057e-02,\n",
      "            -3.0679e-02, -3.9570e-02]],\n",
      "\n",
      "          [[ 2.0405e-02, -1.6151e-02,  5.3610e-03,  ...,  1.7153e-02,\n",
      "            -1.4558e-02,  4.3746e-02],\n",
      "           [-1.1393e-02, -3.8167e-03,  1.5159e-02,  ...,  8.5589e-03,\n",
      "            -2.3394e-02,  1.0118e-02],\n",
      "           [ 3.5970e-02,  1.9601e-03,  2.6003e-03,  ..., -5.5538e-03,\n",
      "             2.6377e-02,  1.0739e-02],\n",
      "           ...,\n",
      "           [ 5.0259e-03,  2.2056e-02, -2.1595e-02,  ..., -8.7635e-03,\n",
      "            -1.9288e-02,  1.7350e-02],\n",
      "           [ 1.0813e-02, -2.2245e-03,  2.0480e-02,  ..., -2.0424e-02,\n",
      "            -4.5951e-03,  1.2765e-02],\n",
      "           [-4.6670e-04,  1.9092e-02, -2.1859e-02,  ..., -9.4775e-04,\n",
      "             1.9404e-02,  2.7163e-02]],\n",
      "\n",
      "          [[-4.9606e-03, -2.1471e-03, -9.3617e-03,  ..., -3.6168e-02,\n",
      "            -1.8901e-02, -8.5589e-03],\n",
      "           [-1.9173e-02, -2.6978e-02, -3.6633e-03,  ...,  3.6216e-03,\n",
      "            -4.3293e-03, -2.3912e-02],\n",
      "           [-1.7866e-02,  5.6873e-03,  1.0740e-03,  ...,  1.2344e-02,\n",
      "             3.3204e-04,  1.1574e-03],\n",
      "           ...,\n",
      "           [-2.5031e-02,  3.2516e-02, -1.8753e-02,  ..., -2.6717e-03,\n",
      "            -2.3649e-02, -1.9493e-02],\n",
      "           [ 1.9143e-02, -1.1645e-02,  3.7616e-03,  ..., -5.7475e-03,\n",
      "             4.4806e-03,  3.2997e-02],\n",
      "           [ 1.7975e-02, -3.7285e-03,  1.2450e-03,  ..., -1.9595e-02,\n",
      "             1.0840e-03,  2.5615e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-8.9378e-03, -9.2348e-03,  3.3418e-02,  ..., -4.2163e-02,\n",
      "            -3.0776e-02, -2.4498e-03],\n",
      "           [-5.7631e-03, -2.3533e-02, -3.0531e-03,  ...,  4.6468e-02,\n",
      "            -5.7779e-04,  9.0645e-03],\n",
      "           [-1.1564e-02, -3.9098e-03,  1.2008e-03,  ..., -2.0911e-02,\n",
      "             4.5461e-02, -3.1879e-02],\n",
      "           ...,\n",
      "           [-1.5041e-02, -6.0222e-03,  7.7173e-03,  ..., -3.5705e-03,\n",
      "             9.4758e-03, -1.4213e-02],\n",
      "           [-1.0723e-02,  9.3634e-03, -4.2278e-03,  ...,  1.3072e-02,\n",
      "             5.8473e-03, -2.0304e-02],\n",
      "           [ 4.0979e-02,  3.8414e-02,  2.1154e-02,  ..., -3.1090e-02,\n",
      "             2.5054e-02, -1.0368e-02]],\n",
      "\n",
      "          [[-2.0446e-02,  1.9453e-02, -4.2126e-03,  ..., -9.4256e-03,\n",
      "             3.4398e-02, -1.1682e-02],\n",
      "           [-3.0138e-02,  7.9004e-03,  7.3355e-03,  ...,  1.4904e-02,\n",
      "             1.0925e-04,  9.4939e-03],\n",
      "           [ 1.9257e-03,  1.2950e-02,  2.4474e-02,  ..., -3.4509e-02,\n",
      "            -1.5161e-02, -6.4260e-03],\n",
      "           ...,\n",
      "           [-8.1663e-05,  2.9176e-02,  8.3996e-03,  ..., -2.3056e-02,\n",
      "             6.3312e-03,  2.0568e-02],\n",
      "           [-1.2548e-02, -6.4109e-04,  1.7883e-02,  ...,  1.5303e-02,\n",
      "            -1.7126e-03, -2.3638e-02],\n",
      "           [ 1.3771e-02,  5.0167e-03,  1.7643e-02,  ..., -6.7390e-03,\n",
      "             9.0529e-03,  1.8279e-02]],\n",
      "\n",
      "          [[ 1.7260e-02, -1.1291e-02, -2.4782e-02,  ..., -2.6443e-03,\n",
      "             2.6631e-03,  3.8928e-04],\n",
      "           [ 1.4440e-02, -2.0391e-02, -1.0452e-02,  ...,  2.0854e-03,\n",
      "             6.6259e-03, -1.4071e-02],\n",
      "           [-9.1457e-03,  1.2057e-02,  3.2782e-02,  ..., -5.2981e-03,\n",
      "            -9.0842e-03,  3.3658e-02],\n",
      "           ...,\n",
      "           [ 5.3304e-03, -1.7238e-02,  4.8636e-03,  ...,  2.0896e-02,\n",
      "             8.4884e-03, -5.2223e-03],\n",
      "           [ 1.3964e-02, -7.0113e-03, -6.2105e-03,  ...,  3.6446e-03,\n",
      "            -2.8326e-03,  2.7167e-03],\n",
      "           [ 3.0726e-02,  9.8011e-03, -1.2401e-02,  ...,  1.7222e-02,\n",
      "            -1.8281e-02,  2.2328e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.7688e-02, -1.9349e-03, -3.9465e-03,  ...,  1.2074e-02,\n",
      "             2.0595e-02,  2.4521e-02],\n",
      "           [ 1.7428e-03,  1.1406e-02, -1.4843e-02,  ..., -1.3312e-02,\n",
      "             1.9307e-02, -1.3882e-02],\n",
      "           [-2.8447e-02, -4.2258e-02,  2.6923e-02,  ..., -8.3796e-03,\n",
      "             1.0826e-02, -1.2549e-02],\n",
      "           ...,\n",
      "           [ 2.0306e-02, -3.7684e-02,  3.4969e-02,  ...,  1.8201e-03,\n",
      "            -3.3792e-03, -9.9980e-04],\n",
      "           [ 4.5212e-02,  2.0952e-02,  9.9943e-03,  ..., -3.1925e-02,\n",
      "            -1.0703e-02, -2.0237e-02],\n",
      "           [-5.4179e-03,  1.0334e-02, -8.6266e-03,  ..., -2.4715e-02,\n",
      "            -2.6429e-02,  3.9714e-02]],\n",
      "\n",
      "          [[-8.7499e-03,  6.6758e-03, -4.8504e-03,  ...,  5.8214e-03,\n",
      "            -1.3148e-02, -1.5430e-02],\n",
      "           [-2.3060e-03, -7.2727e-03,  2.8622e-02,  ..., -1.3818e-03,\n",
      "            -1.2624e-03, -9.6049e-03],\n",
      "           [ 2.3251e-02,  9.2612e-03,  9.3951e-03,  ...,  1.3506e-02,\n",
      "            -2.6311e-02, -1.0767e-02],\n",
      "           ...,\n",
      "           [ 1.2290e-02,  8.8944e-04,  3.9591e-04,  ...,  1.1940e-02,\n",
      "            -1.9767e-03, -4.7278e-03],\n",
      "           [-3.4174e-02,  3.6627e-02, -4.0671e-02,  ...,  1.9081e-02,\n",
      "            -6.1358e-03, -6.1920e-03],\n",
      "           [-5.8392e-03,  1.1333e-02, -1.7671e-02,  ..., -2.1453e-02,\n",
      "            -1.5391e-02,  3.4181e-02]],\n",
      "\n",
      "          [[ 5.6800e-03,  5.2347e-03, -1.7309e-03,  ...,  3.0058e-02,\n",
      "            -8.0709e-03,  7.1213e-03],\n",
      "           [-7.5796e-03, -5.4546e-03, -3.1426e-03,  ...,  1.9178e-03,\n",
      "            -8.9770e-03,  9.3828e-03],\n",
      "           [-3.0373e-02,  2.7651e-02, -4.0044e-03,  ..., -1.1088e-02,\n",
      "             4.1029e-03,  1.2804e-03],\n",
      "           ...,\n",
      "           [-2.0809e-02,  9.9484e-03,  3.6157e-03,  ..., -3.2645e-02,\n",
      "            -1.8389e-03,  3.4925e-03],\n",
      "           [-4.9865e-03, -1.1023e-02, -9.6971e-03,  ..., -2.5337e-03,\n",
      "            -1.1164e-02, -1.1590e-02],\n",
      "           [ 4.6495e-03,  2.5433e-02, -1.4377e-02,  ..., -2.2777e-02,\n",
      "            -1.5959e-02, -1.0096e-03]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.3987e-02, -1.5318e-02, -4.7952e-03,  ..., -1.9342e-02,\n",
      "            -3.2842e-03, -7.9390e-03],\n",
      "           [ 2.0665e-02, -4.8394e-03, -2.5330e-02,  ..., -5.8107e-03,\n",
      "             2.7640e-02, -8.8808e-03],\n",
      "           [ 3.1363e-03,  2.5501e-02,  2.2300e-02,  ..., -4.7043e-03,\n",
      "            -4.7302e-04,  2.0704e-02],\n",
      "           ...,\n",
      "           [-1.9997e-02,  2.8060e-02, -2.7527e-02,  ..., -3.0158e-02,\n",
      "            -2.7176e-02, -1.3919e-02],\n",
      "           [-2.3710e-02,  3.5851e-02, -2.6300e-03,  ..., -6.2854e-03,\n",
      "            -4.5431e-03, -2.6029e-02],\n",
      "           [ 1.9517e-03,  1.6156e-03, -1.3914e-02,  ..., -9.3854e-03,\n",
      "             3.2114e-03, -1.4184e-03]],\n",
      "\n",
      "          [[ 3.9728e-02, -1.7179e-03,  5.8721e-02,  ..., -1.4566e-02,\n",
      "            -4.2191e-03,  3.8396e-03],\n",
      "           [ 9.6394e-03, -1.3701e-02,  2.6326e-02,  ...,  7.6316e-03,\n",
      "             2.1639e-02, -2.5243e-03],\n",
      "           [-9.0936e-03,  5.6263e-03,  3.2237e-02,  ...,  7.5983e-03,\n",
      "             1.2477e-02,  1.0048e-02],\n",
      "           ...,\n",
      "           [ 1.6078e-02, -1.8082e-02,  1.6191e-02,  ..., -3.6524e-02,\n",
      "            -4.1986e-02, -1.3898e-02],\n",
      "           [-1.0688e-02, -6.2605e-03,  8.2223e-03,  ..., -2.8165e-03,\n",
      "             4.3246e-03,  1.1908e-02],\n",
      "           [-9.7471e-03, -2.3186e-02,  6.2586e-04,  ..., -2.0208e-02,\n",
      "            -2.0550e-03,  4.5549e-02]],\n",
      "\n",
      "          [[-1.0003e-02, -3.1141e-04, -3.9854e-02,  ..., -2.0514e-02,\n",
      "             7.7200e-03,  3.6315e-02],\n",
      "           [ 1.8339e-02, -2.7523e-02,  2.0528e-02,  ...,  5.0532e-03,\n",
      "            -3.5017e-02,  1.8750e-02],\n",
      "           [ 2.0447e-03,  2.3416e-02, -1.5451e-02,  ..., -1.2197e-02,\n",
      "            -3.5409e-02, -2.2183e-03],\n",
      "           ...,\n",
      "           [ 4.1296e-03, -1.4561e-02,  1.1821e-02,  ..., -1.0864e-03,\n",
      "            -1.3189e-02,  2.9723e-02],\n",
      "           [ 7.2413e-03, -9.7294e-03,  2.3684e-02,  ..., -3.9288e-03,\n",
      "            -3.1374e-03,  4.1517e-03],\n",
      "           [ 1.3807e-02,  1.1511e-02, -2.0212e-02,  ..., -1.9379e-03,\n",
      "             5.6872e-03,  9.5840e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.5703e-03,  3.9897e-03, -1.4469e-02,  ...,  2.5293e-02,\n",
      "            -2.1861e-02, -3.8677e-03],\n",
      "           [ 3.0545e-02,  1.3098e-03,  2.6702e-02,  ..., -9.6592e-04,\n",
      "            -7.7155e-04, -4.9447e-02],\n",
      "           [ 8.7182e-04,  2.8060e-02,  6.7870e-04,  ..., -3.7993e-02,\n",
      "             1.2250e-02,  2.1390e-02],\n",
      "           ...,\n",
      "           [-1.4519e-02, -4.6302e-03, -7.0935e-03,  ..., -3.3734e-02,\n",
      "            -3.7113e-02,  2.5751e-02],\n",
      "           [-3.1739e-02, -6.3847e-03, -2.9949e-03,  ...,  3.6060e-03,\n",
      "             3.1642e-04,  1.0567e-02],\n",
      "           [ 2.9549e-02, -1.4137e-02,  3.2413e-03,  ...,  1.5294e-02,\n",
      "            -9.1234e-03, -3.7710e-04]],\n",
      "\n",
      "          [[-1.0566e-02,  2.5312e-02, -2.2162e-02,  ...,  2.9857e-03,\n",
      "             2.8839e-03,  2.1556e-02],\n",
      "           [ 1.6293e-02,  2.9246e-02, -3.3306e-02,  ...,  2.3268e-02,\n",
      "            -1.7749e-02, -2.3864e-02],\n",
      "           [-4.6199e-02, -1.4397e-02, -1.8785e-02,  ...,  4.6294e-02,\n",
      "             7.3132e-03,  6.0971e-04],\n",
      "           ...,\n",
      "           [ 2.6800e-03,  1.6702e-02,  1.1209e-02,  ..., -1.8939e-02,\n",
      "            -2.4527e-04, -5.1844e-03],\n",
      "           [ 5.0717e-04,  3.9354e-04, -4.6420e-03,  ...,  1.4142e-02,\n",
      "             1.4387e-02, -2.9502e-02],\n",
      "           [-2.9808e-02,  9.8996e-03, -1.2234e-03,  ..., -6.6557e-03,\n",
      "            -2.0111e-02,  1.1202e-02]],\n",
      "\n",
      "          [[-2.2843e-02,  7.8587e-04,  8.1237e-03,  ..., -1.6658e-02,\n",
      "             2.3701e-03, -1.3216e-02],\n",
      "           [-1.9678e-02,  1.0654e-02, -1.7329e-02,  ...,  3.8710e-02,\n",
      "            -9.4835e-03,  1.7083e-02],\n",
      "           [-9.6765e-04,  1.3504e-02,  6.6928e-05,  ...,  2.6828e-03,\n",
      "            -1.4452e-02,  6.2443e-03],\n",
      "           ...,\n",
      "           [-8.2496e-03, -8.7400e-03,  3.8273e-02,  ..., -1.9479e-02,\n",
      "            -1.5920e-02, -1.1786e-02],\n",
      "           [-5.7773e-03, -1.5090e-02, -2.7850e-02,  ..., -4.2230e-02,\n",
      "             1.2916e-02,  2.8738e-03],\n",
      "           [-6.6144e-03, -2.4575e-02,  1.2144e-02,  ..., -1.2974e-02,\n",
      "             2.5152e-02, -2.2026e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-6.2225e-03,  1.1495e-02,  1.9268e-02,  ..., -9.4278e-03,\n",
      "            -5.0731e-02,  1.6150e-02],\n",
      "           [ 4.1936e-02,  2.7521e-02,  1.2746e-02,  ..., -2.2482e-02,\n",
      "             6.7432e-03, -1.7199e-02],\n",
      "           [-1.1944e-02,  1.0961e-05, -2.4667e-02,  ..., -2.2905e-02,\n",
      "             4.3255e-03,  3.1602e-03],\n",
      "           ...,\n",
      "           [-6.4617e-03, -1.1486e-02,  7.9486e-03,  ..., -4.0222e-02,\n",
      "            -6.7218e-03,  4.4268e-04],\n",
      "           [ 2.9084e-02, -1.3674e-03, -4.9108e-03,  ...,  7.3452e-03,\n",
      "             2.6273e-03,  4.3184e-03],\n",
      "           [-2.4671e-02,  7.7895e-03,  1.6360e-03,  ..., -1.1111e-02,\n",
      "             8.9439e-03,  6.6920e-04]],\n",
      "\n",
      "          [[-2.2193e-02, -9.2379e-05, -8.0461e-03,  ..., -3.3852e-02,\n",
      "            -1.8141e-02, -2.8527e-02],\n",
      "           [ 2.8130e-03,  2.4057e-02,  2.2049e-03,  ..., -2.9669e-03,\n",
      "             5.0102e-03, -4.9847e-03],\n",
      "           [ 1.0225e-02, -1.0021e-04,  1.2984e-02,  ...,  2.4269e-02,\n",
      "             2.0343e-02, -2.3596e-02],\n",
      "           ...,\n",
      "           [ 1.6905e-02, -3.5054e-02,  2.9926e-03,  ..., -1.3932e-02,\n",
      "            -7.7041e-03,  4.3155e-03],\n",
      "           [ 9.5840e-03,  7.5821e-03, -5.1403e-03,  ..., -3.3050e-02,\n",
      "            -2.6790e-02,  1.7291e-02],\n",
      "           [-3.7982e-03, -1.8847e-02,  3.0582e-03,  ...,  7.5890e-03,\n",
      "            -7.4861e-03, -4.6282e-02]],\n",
      "\n",
      "          [[ 9.2963e-03,  3.6094e-03, -1.5492e-02,  ...,  2.1143e-02,\n",
      "             2.3137e-02, -8.5683e-03],\n",
      "           [ 1.0543e-02,  2.0966e-02,  1.2338e-02,  ...,  2.4128e-03,\n",
      "             2.9072e-02,  2.6886e-02],\n",
      "           [ 1.2314e-02, -3.5029e-02,  9.0340e-03,  ...,  2.7426e-02,\n",
      "            -5.8757e-04, -8.4986e-03],\n",
      "           ...,\n",
      "           [-2.1490e-03,  3.6270e-02,  5.8810e-04,  ..., -6.2934e-03,\n",
      "            -1.0568e-02,  4.5200e-03],\n",
      "           [ 5.6984e-03, -3.3268e-03,  1.6833e-02,  ...,  1.9739e-03,\n",
      "             7.0677e-03,  1.2293e-02],\n",
      "           [ 4.2011e-03, -1.4363e-02,  2.7711e-02,  ...,  2.3474e-02,\n",
      "            -8.6907e-03, -1.8368e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.1279e-02,  1.5092e-02,  8.1677e-03,  ...,  1.2115e-02,\n",
      "            -2.3930e-02,  1.6299e-02],\n",
      "           [ 1.6418e-02,  1.2084e-02,  2.3975e-03,  ...,  1.5122e-02,\n",
      "            -4.3084e-02,  8.9495e-03],\n",
      "           [-2.4943e-02, -3.3146e-03, -1.0981e-02,  ...,  2.8278e-02,\n",
      "             1.4276e-02, -5.7737e-02],\n",
      "           ...,\n",
      "           [ 1.4864e-02, -2.7003e-02, -5.2035e-03,  ...,  4.3047e-04,\n",
      "            -2.9985e-03, -1.6012e-02],\n",
      "           [-1.8695e-02,  3.3704e-03,  2.4803e-02,  ...,  1.2718e-02,\n",
      "            -3.3404e-02, -6.6478e-04],\n",
      "           [-4.2985e-03, -1.1321e-02,  9.9366e-03,  ..., -1.3273e-02,\n",
      "            -2.3290e-02, -3.8683e-02]],\n",
      "\n",
      "          [[-8.8594e-03,  1.7361e-02, -3.6505e-02,  ..., -5.9471e-04,\n",
      "             3.1290e-04,  3.2822e-02],\n",
      "           [-1.6047e-02, -2.0077e-02, -4.1122e-04,  ...,  8.1613e-03,\n",
      "             3.2306e-02, -1.3678e-02],\n",
      "           [ 6.0630e-03,  3.3107e-02,  3.7215e-02,  ..., -6.5180e-03,\n",
      "            -5.0388e-03, -7.8538e-04],\n",
      "           ...,\n",
      "           [ 2.0106e-02, -1.5072e-02, -1.5859e-02,  ..., -3.6807e-02,\n",
      "            -1.4807e-02,  1.7409e-02],\n",
      "           [ 5.5113e-03, -1.3207e-02,  2.5190e-02,  ...,  1.4322e-02,\n",
      "            -2.2181e-02,  3.1784e-02],\n",
      "           [-1.4823e-02,  1.3742e-02,  5.8396e-03,  ..., -1.8865e-03,\n",
      "            -2.6220e-02,  1.3815e-02]],\n",
      "\n",
      "          [[-1.4665e-02,  1.0855e-03, -2.7945e-05,  ...,  1.2824e-02,\n",
      "             8.5052e-03,  1.2366e-02],\n",
      "           [ 1.4184e-02,  2.7963e-02, -9.9105e-03,  ...,  4.3983e-03,\n",
      "            -4.1836e-03,  2.3331e-04],\n",
      "           [ 1.5960e-02,  2.8877e-02, -2.5256e-03,  ...,  1.4937e-02,\n",
      "            -9.6951e-03,  8.2239e-03],\n",
      "           ...,\n",
      "           [ 5.0070e-02, -4.2726e-02, -4.6915e-02,  ..., -2.2964e-03,\n",
      "             3.6788e-02,  2.1807e-02],\n",
      "           [-3.1184e-03, -3.9751e-02, -8.9162e-03,  ...,  1.5263e-02,\n",
      "            -1.9715e-02,  1.6968e-02],\n",
      "           [ 1.4223e-03,  3.9779e-04, -9.6196e-03,  ..., -1.3660e-03,\n",
      "            -1.4230e-02,  1.7702e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-3.9157e-02, -8.1654e-03,  6.1678e-03,  ..., -1.8439e-02,\n",
      "            -1.0668e-03,  7.6857e-03],\n",
      "           [ 2.4235e-02,  1.9705e-03,  5.4712e-03,  ..., -9.3090e-03,\n",
      "            -1.2174e-02,  3.3508e-02],\n",
      "           [ 1.3185e-02,  8.5691e-03, -5.9765e-03,  ...,  4.3582e-03,\n",
      "            -1.3558e-02, -2.4279e-02],\n",
      "           ...,\n",
      "           [-8.7734e-03,  5.4348e-04, -1.2605e-02,  ..., -6.1859e-03,\n",
      "            -3.4149e-02,  1.3568e-02],\n",
      "           [-1.6549e-02,  1.6082e-02, -2.4069e-02,  ..., -7.5410e-03,\n",
      "             2.7504e-02,  1.4285e-02],\n",
      "           [ 9.0924e-03,  2.7040e-02, -6.2404e-03,  ..., -2.0372e-02,\n",
      "             2.6803e-02,  3.1898e-03]],\n",
      "\n",
      "          [[ 5.4429e-03,  6.8933e-03, -1.3158e-03,  ..., -2.7314e-02,\n",
      "            -1.0004e-02, -1.3225e-02],\n",
      "           [ 2.7252e-02, -1.9360e-02, -4.3299e-02,  ..., -2.2804e-02,\n",
      "             2.0259e-03, -1.9065e-02],\n",
      "           [ 3.0434e-03,  6.2875e-03,  4.7456e-03,  ...,  2.3671e-02,\n",
      "            -3.0673e-02,  2.8967e-02],\n",
      "           ...,\n",
      "           [ 7.6504e-03, -9.8903e-03, -1.3325e-02,  ...,  2.7776e-02,\n",
      "            -2.1262e-02,  8.7493e-03],\n",
      "           [ 2.6284e-03,  4.4159e-04, -6.3381e-04,  ...,  2.6299e-02,\n",
      "             2.4251e-02,  3.3852e-03],\n",
      "           [ 1.2154e-02,  1.1209e-03, -1.1584e-02,  ..., -2.6249e-02,\n",
      "             6.3916e-03, -1.8701e-02]],\n",
      "\n",
      "          [[ 1.8595e-02, -3.0178e-02, -1.7458e-02,  ..., -4.0025e-02,\n",
      "             4.8407e-02,  1.5876e-02],\n",
      "           [ 3.4797e-03, -2.9511e-03,  3.2410e-03,  ..., -1.1023e-02,\n",
      "            -3.8718e-02, -3.0524e-02],\n",
      "           [ 5.4748e-03, -1.1777e-02, -1.3173e-02,  ..., -2.0384e-02,\n",
      "             1.3720e-02, -7.8690e-03],\n",
      "           ...,\n",
      "           [ 3.0419e-02, -3.3465e-03, -1.3424e-02,  ..., -1.6981e-02,\n",
      "             2.5106e-02, -1.7189e-02],\n",
      "           [-9.3992e-03,  2.3843e-02, -1.1732e-02,  ..., -2.7089e-03,\n",
      "             8.9849e-03, -3.4864e-03],\n",
      "           [ 1.0293e-02,  2.5794e-02,  3.8996e-03,  ...,  1.0731e-02,\n",
      "            -1.2616e-02,  1.7947e-02]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[-0.0950, -0.0646, -0.0256],\n",
      "           [ 0.0428,  0.0576,  0.1115],\n",
      "           [-0.0801,  0.0548,  0.1199]],\n",
      "\n",
      "          [[-0.0400, -0.0127, -0.1112],\n",
      "           [-0.0736,  0.1072, -0.0415],\n",
      "           [-0.0709,  0.0622,  0.0124]],\n",
      "\n",
      "          [[-0.0533, -0.0278,  0.0174],\n",
      "           [-0.0450, -0.0681,  0.0371],\n",
      "           [ 0.0740, -0.0440, -0.0138]]],\n",
      "\n",
      "\n",
      "         [[[-0.0120,  0.0242,  0.0392],\n",
      "           [ 0.0479, -0.1905, -0.0277],\n",
      "           [ 0.0771, -0.0203,  0.0022]],\n",
      "\n",
      "          [[-0.1080, -0.0494, -0.0272],\n",
      "           [ 0.0216, -0.1357, -0.1687],\n",
      "           [-0.0630, -0.0265,  0.0389]],\n",
      "\n",
      "          [[-0.0073, -0.0049, -0.0433],\n",
      "           [-0.0233,  0.0523, -0.0036],\n",
      "           [-0.0154, -0.0737,  0.0421]]],\n",
      "\n",
      "\n",
      "         [[[-0.0039, -0.0184, -0.0210],\n",
      "           [ 0.0713, -0.0318, -0.0379],\n",
      "           [ 0.0413, -0.1014, -0.0360]],\n",
      "\n",
      "          [[ 0.0323,  0.0883,  0.0816],\n",
      "           [-0.0287, -0.1668,  0.0732],\n",
      "           [-0.0341, -0.0423, -0.0242]],\n",
      "\n",
      "          [[-0.0280,  0.0836,  0.0019],\n",
      "           [ 0.0234,  0.0168, -0.1455],\n",
      "           [ 0.0380,  0.0314,  0.0190]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0848, -0.0068,  0.0857],\n",
      "           [-0.0502, -0.0569,  0.0384],\n",
      "           [-0.0691, -0.1644,  0.0532]],\n",
      "\n",
      "          [[-0.1090, -0.0418, -0.0168],\n",
      "           [-0.0146, -0.0870, -0.0080],\n",
      "           [-0.0318, -0.0028, -0.0685]],\n",
      "\n",
      "          [[-0.0488,  0.0488, -0.0509],\n",
      "           [-0.0343,  0.0768, -0.0820],\n",
      "           [-0.0701, -0.0337, -0.1042]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0283,  0.0295,  0.0260],\n",
      "           [-0.1224, -0.0965,  0.1162],\n",
      "           [ 0.0705, -0.0379,  0.0678]],\n",
      "\n",
      "          [[-0.0991, -0.0386, -0.0390],\n",
      "           [-0.0739, -0.0191,  0.0266],\n",
      "           [-0.1278, -0.0388, -0.0323]],\n",
      "\n",
      "          [[-0.0191,  0.0732,  0.0481],\n",
      "           [-0.0604,  0.0303,  0.0236],\n",
      "           [-0.0793, -0.0151,  0.0494]]],\n",
      "\n",
      "\n",
      "         [[[-0.0519,  0.0600, -0.0105],\n",
      "           [ 0.0583, -0.0543, -0.1289],\n",
      "           [ 0.0586,  0.0040, -0.1078]],\n",
      "\n",
      "          [[ 0.0714,  0.0038, -0.0876],\n",
      "           [ 0.0026,  0.1184,  0.0140],\n",
      "           [ 0.0006, -0.1223,  0.0259]],\n",
      "\n",
      "          [[-0.0336,  0.0728,  0.0093],\n",
      "           [ 0.0905, -0.0369,  0.0240],\n",
      "           [-0.0227, -0.0775,  0.1730]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0368, -0.0536,  0.0466],\n",
      "           [-0.0268, -0.0098, -0.1224],\n",
      "           [ 0.0058, -0.0636,  0.0190]],\n",
      "\n",
      "          [[ 0.0522,  0.0142,  0.0264],\n",
      "           [-0.0056, -0.0498,  0.0972],\n",
      "           [ 0.0288,  0.0037, -0.0027]],\n",
      "\n",
      "          [[ 0.1016, -0.0107, -0.2299],\n",
      "           [-0.1063, -0.0700, -0.1345],\n",
      "           [-0.0596,  0.0562,  0.0004]]],\n",
      "\n",
      "\n",
      "         [[[-0.0877, -0.0388, -0.0547],\n",
      "           [ 0.0040, -0.0074,  0.0327],\n",
      "           [-0.0351, -0.0536, -0.0281]],\n",
      "\n",
      "          [[ 0.0034,  0.0410, -0.0687],\n",
      "           [ 0.0934, -0.0145, -0.0604],\n",
      "           [-0.0585,  0.1377,  0.1620]],\n",
      "\n",
      "          [[ 0.0175,  0.0137, -0.0436],\n",
      "           [-0.0502,  0.0147, -0.0228],\n",
      "           [-0.0610,  0.0941,  0.0407]]],\n",
      "\n",
      "\n",
      "         [[[-0.1302,  0.0625, -0.0376],\n",
      "           [-0.0704,  0.0829, -0.0798],\n",
      "           [-0.0220,  0.0151,  0.0232]],\n",
      "\n",
      "          [[-0.1466, -0.0389, -0.0070],\n",
      "           [ 0.0073,  0.0004, -0.0587],\n",
      "           [ 0.1377, -0.0917,  0.0993]],\n",
      "\n",
      "          [[ 0.0902, -0.0042,  0.0053],\n",
      "           [-0.0878,  0.0997,  0.0121],\n",
      "           [-0.0890,  0.0453, -0.0107]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0138, -0.0281, -0.0310],\n",
      "           [ 0.0204,  0.0440, -0.0447],\n",
      "           [ 0.1953,  0.0244,  0.0846]],\n",
      "\n",
      "          [[-0.0687, -0.0684, -0.0230],\n",
      "           [ 0.0064, -0.0339,  0.1124],\n",
      "           [-0.0382, -0.0146,  0.0528]],\n",
      "\n",
      "          [[-0.0384,  0.0226, -0.0092],\n",
      "           [-0.0507,  0.0394,  0.0091],\n",
      "           [ 0.0495,  0.0066,  0.0599]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0455,  0.1063, -0.0278],\n",
      "           [-0.1085, -0.0057, -0.0491],\n",
      "           [ 0.0555, -0.0114,  0.0604]],\n",
      "\n",
      "          [[-0.0571, -0.1780, -0.0171],\n",
      "           [-0.0381,  0.0217,  0.0427],\n",
      "           [-0.0167,  0.1630,  0.0510]],\n",
      "\n",
      "          [[-0.0237,  0.0405, -0.0702],\n",
      "           [ 0.0376,  0.0119, -0.0604],\n",
      "           [-0.0043,  0.0429, -0.0094]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1497,  0.0635,  0.0174],\n",
      "           [ 0.0415,  0.0011, -0.1307],\n",
      "           [ 0.1525,  0.0272,  0.0199]],\n",
      "\n",
      "          [[-0.1237,  0.0005, -0.0921],\n",
      "           [ 0.0894, -0.0414,  0.0158],\n",
      "           [-0.0478, -0.0679,  0.0056]],\n",
      "\n",
      "          [[-0.0599, -0.0354, -0.0457],\n",
      "           [ 0.0421, -0.0056,  0.0029],\n",
      "           [-0.0813, -0.0488, -0.0789]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0410,  0.0317, -0.1120],\n",
      "           [-0.1145,  0.0565, -0.0443],\n",
      "           [-0.0804,  0.1418,  0.1012]],\n",
      "\n",
      "          [[-0.0224,  0.0233,  0.1798],\n",
      "           [ 0.0315,  0.0111, -0.0498],\n",
      "           [ 0.0351,  0.0937,  0.1278]],\n",
      "\n",
      "          [[ 0.1186, -0.0267, -0.0213],\n",
      "           [ 0.0206, -0.0631,  0.1002],\n",
      "           [-0.0286,  0.0287, -0.0540]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0688, -0.0197,  0.0369],\n",
      "           [ 0.0529,  0.0462,  0.0900],\n",
      "           [-0.0253,  0.0967, -0.0059]],\n",
      "\n",
      "          [[-0.1724, -0.0733, -0.0256],\n",
      "           [-0.0119,  0.0152,  0.0262],\n",
      "           [ 0.1486,  0.0839,  0.0182]],\n",
      "\n",
      "          [[ 0.0295,  0.0842, -0.0993],\n",
      "           [-0.0895,  0.0135, -0.0592],\n",
      "           [ 0.0131, -0.0555,  0.1069]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0889, -0.0940, -0.0710],\n",
      "           [ 0.0412,  0.0974,  0.0590],\n",
      "           [ 0.0555, -0.0407,  0.1049]],\n",
      "\n",
      "          [[-0.0439, -0.0466,  0.1161],\n",
      "           [-0.0543, -0.0736, -0.0826],\n",
      "           [-0.0912,  0.0432, -0.0134]],\n",
      "\n",
      "          [[ 0.0367,  0.0579,  0.0028],\n",
      "           [-0.0200, -0.0849,  0.0370],\n",
      "           [ 0.0062,  0.0380,  0.1712]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0963,  0.0995, -0.0925],\n",
      "           [-0.0489,  0.0934, -0.1479],\n",
      "           [ 0.0274, -0.0671,  0.0545]],\n",
      "\n",
      "          [[ 0.0054,  0.0167,  0.0152],\n",
      "           [-0.0421, -0.0643,  0.0838],\n",
      "           [ 0.1220, -0.0518,  0.0857]],\n",
      "\n",
      "          [[-0.0311,  0.0300,  0.0269],\n",
      "           [ 0.1234,  0.0546,  0.0353],\n",
      "           [-0.0008, -0.0008, -0.0325]]],\n",
      "\n",
      "\n",
      "         [[[-0.0015,  0.0241,  0.0587],\n",
      "           [ 0.0179,  0.0389,  0.0512],\n",
      "           [ 0.0081, -0.0302,  0.0307]],\n",
      "\n",
      "          [[ 0.0157,  0.0220, -0.0260],\n",
      "           [-0.0430, -0.0764, -0.1994],\n",
      "           [-0.0035, -0.1172,  0.0142]],\n",
      "\n",
      "          [[ 0.0421, -0.1986, -0.0423],\n",
      "           [-0.0040, -0.0050,  0.0243],\n",
      "           [-0.0164, -0.0202,  0.1188]]],\n",
      "\n",
      "\n",
      "         [[[-0.0041,  0.0715,  0.0546],\n",
      "           [-0.0092, -0.0081, -0.1135],\n",
      "           [ 0.0597, -0.0052, -0.0428]],\n",
      "\n",
      "          [[-0.0149, -0.0559, -0.0174],\n",
      "           [ 0.1779, -0.0353,  0.0983],\n",
      "           [-0.0917, -0.0853,  0.0278]],\n",
      "\n",
      "          [[-0.0581,  0.0445,  0.0073],\n",
      "           [-0.0407, -0.1392, -0.0215],\n",
      "           [ 0.0999, -0.0725,  0.0771]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0233, -0.1087,  0.0957],\n",
      "           [ 0.0125,  0.0911,  0.0549],\n",
      "           [ 0.1474, -0.0003, -0.0665]],\n",
      "\n",
      "          [[ 0.0471, -0.0307, -0.0032],\n",
      "           [-0.0556,  0.0367,  0.0491],\n",
      "           [ 0.0098, -0.0302, -0.0334]],\n",
      "\n",
      "          [[ 0.0318, -0.0444, -0.0657],\n",
      "           [-0.0950, -0.0799,  0.1021],\n",
      "           [-0.0896, -0.0380,  0.0052]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0420,  0.0903,  0.0255],\n",
      "           [-0.0145, -0.0194,  0.0984],\n",
      "           [ 0.0944, -0.1742, -0.0381]],\n",
      "\n",
      "          [[-0.0343, -0.1296,  0.0990],\n",
      "           [-0.0668, -0.1254,  0.0226],\n",
      "           [-0.0814, -0.0236,  0.0552]],\n",
      "\n",
      "          [[-0.0326, -0.1336,  0.0864],\n",
      "           [ 0.0634, -0.0323, -0.0382],\n",
      "           [ 0.0661, -0.0261,  0.0302]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0711, -0.0529, -0.0368],\n",
      "           [ 0.0917, -0.0691,  0.1115],\n",
      "           [-0.0753,  0.0669, -0.1675]],\n",
      "\n",
      "          [[ 0.0378,  0.0820, -0.0159],\n",
      "           [ 0.0505,  0.0075,  0.0817],\n",
      "           [-0.1057, -0.1709,  0.0581]],\n",
      "\n",
      "          [[-0.0093, -0.0059,  0.0492],\n",
      "           [-0.0026, -0.0094, -0.1099],\n",
      "           [ 0.0010, -0.1215, -0.0629]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0066, -0.0673, -0.0005],\n",
      "           [-0.1703, -0.1053, -0.0240],\n",
      "           [ 0.0477,  0.0231, -0.0211]],\n",
      "\n",
      "          [[-0.0418, -0.0356, -0.0769],\n",
      "           [-0.0770, -0.0085, -0.0147],\n",
      "           [ 0.0055,  0.1022,  0.0248]],\n",
      "\n",
      "          [[ 0.0564,  0.1050,  0.1025],\n",
      "           [-0.0947,  0.0314,  0.1407],\n",
      "           [ 0.0478,  0.0159, -0.0674]]],\n",
      "\n",
      "\n",
      "         [[[-0.0525,  0.0221,  0.0790],\n",
      "           [-0.0153, -0.0024, -0.0094],\n",
      "           [ 0.0399,  0.1234, -0.0291]],\n",
      "\n",
      "          [[-0.0751, -0.0597, -0.0722],\n",
      "           [-0.0303,  0.0092, -0.0047],\n",
      "           [-0.0171, -0.0627,  0.0399]],\n",
      "\n",
      "          [[ 0.0370,  0.0569,  0.0907],\n",
      "           [ 0.0405, -0.0061, -0.0410],\n",
      "           [-0.0329, -0.0777, -0.0175]]],\n",
      "\n",
      "\n",
      "         [[[-0.1634,  0.0020,  0.0201],\n",
      "           [-0.0180,  0.0804,  0.0061],\n",
      "           [-0.0398,  0.0855,  0.0057]],\n",
      "\n",
      "          [[ 0.0059,  0.1446, -0.0522],\n",
      "           [-0.0459, -0.0742,  0.0151],\n",
      "           [-0.0083,  0.0056,  0.0221]],\n",
      "\n",
      "          [[ 0.0571,  0.0087,  0.0747],\n",
      "           [-0.0043,  0.0720,  0.1088],\n",
      "           [ 0.0780, -0.0977,  0.0152]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0987, -0.0723, -0.1110],\n",
      "           [-0.0047,  0.0729, -0.1054],\n",
      "           [-0.0078,  0.0598,  0.0313]],\n",
      "\n",
      "          [[ 0.0847,  0.1152,  0.0444],\n",
      "           [ 0.1059, -0.0661,  0.0226],\n",
      "           [ 0.0075, -0.0027, -0.0235]],\n",
      "\n",
      "          [[ 0.0313,  0.0538,  0.0474],\n",
      "           [ 0.0783,  0.0286, -0.0351],\n",
      "           [ 0.0317, -0.0616,  0.0285]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0678,  0.0156, -0.0405],\n",
      "           [-0.0854,  0.0005,  0.0285],\n",
      "           [-0.0297, -0.1483,  0.0409]],\n",
      "\n",
      "          [[-0.0449, -0.0177,  0.0306],\n",
      "           [ 0.0421, -0.1452,  0.0073],\n",
      "           [ 0.0509, -0.0373, -0.0016]],\n",
      "\n",
      "          [[ 0.0241, -0.0836,  0.0683],\n",
      "           [ 0.0544,  0.0928,  0.1482],\n",
      "           [ 0.0250, -0.0783, -0.0322]]],\n",
      "\n",
      "\n",
      "         [[[-0.0926,  0.0055, -0.1541],\n",
      "           [-0.0358, -0.0566,  0.0046],\n",
      "           [-0.0383, -0.1186,  0.0964]],\n",
      "\n",
      "          [[ 0.0208, -0.1327,  0.0198],\n",
      "           [ 0.1105, -0.0631, -0.0680],\n",
      "           [ 0.0993,  0.0410,  0.0770]],\n",
      "\n",
      "          [[-0.1078,  0.0973, -0.0910],\n",
      "           [ 0.0310,  0.1595,  0.0938],\n",
      "           [ 0.0575, -0.0067, -0.0473]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0288, -0.0893,  0.0343],\n",
      "           [ 0.0245,  0.0262, -0.0059],\n",
      "           [-0.0955,  0.0305, -0.0786]],\n",
      "\n",
      "          [[ 0.0315, -0.0259, -0.0095],\n",
      "           [-0.1166, -0.0088, -0.0085],\n",
      "           [ 0.0205, -0.0679,  0.0785]],\n",
      "\n",
      "          [[-0.0395, -0.0862, -0.0226],\n",
      "           [-0.1162, -0.0319, -0.0198],\n",
      "           [-0.0330,  0.1234, -0.0921]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0495,  0.0665,  0.0077],\n",
      "           [-0.0174, -0.0328, -0.0254],\n",
      "           [ 0.0127,  0.0059,  0.0469]],\n",
      "\n",
      "          [[ 0.0310,  0.0767, -0.1074],\n",
      "           [-0.0353,  0.0082,  0.0056],\n",
      "           [-0.0829,  0.0013,  0.1195]],\n",
      "\n",
      "          [[ 0.0732, -0.0420,  0.0139],\n",
      "           [ 0.0424,  0.0290, -0.0065],\n",
      "           [ 0.0430, -0.0053, -0.0487]]],\n",
      "\n",
      "\n",
      "         [[[-0.0664, -0.0517,  0.0736],\n",
      "           [ 0.0841,  0.0297, -0.0249],\n",
      "           [ 0.0215, -0.0029,  0.0335]],\n",
      "\n",
      "          [[-0.0626,  0.0104, -0.0581],\n",
      "           [ 0.0323, -0.0181, -0.0767],\n",
      "           [-0.0750,  0.0094,  0.1073]],\n",
      "\n",
      "          [[ 0.0577,  0.0406, -0.0006],\n",
      "           [ 0.0900,  0.1526, -0.0821],\n",
      "           [ 0.0270, -0.0580, -0.0683]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1299, -0.0252,  0.0843],\n",
      "           [-0.0169,  0.0005,  0.0328],\n",
      "           [-0.1405, -0.0008,  0.0495]],\n",
      "\n",
      "          [[ 0.0517, -0.0280,  0.0284],\n",
      "           [-0.0409, -0.0809, -0.0094],\n",
      "           [-0.0077,  0.0830, -0.0060]],\n",
      "\n",
      "          [[ 0.0729, -0.0535, -0.0143],\n",
      "           [-0.0752, -0.0402,  0.0148],\n",
      "           [-0.1160, -0.0230,  0.0498]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0856, -0.0194,  0.0183],\n",
      "           [ 0.0398,  0.0366,  0.0573],\n",
      "           [ 0.0568, -0.0393,  0.0777]],\n",
      "\n",
      "          [[-0.0875, -0.0111, -0.1296],\n",
      "           [ 0.1050,  0.1112,  0.0246],\n",
      "           [-0.1051,  0.0037, -0.0557]],\n",
      "\n",
      "          [[-0.0622,  0.0725, -0.0940],\n",
      "           [-0.0490, -0.0514, -0.0112],\n",
      "           [-0.0748, -0.0504, -0.0561]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0928, -0.0034,  0.0050],\n",
      "           [-0.0322,  0.0461,  0.0992],\n",
      "           [-0.0711, -0.0830,  0.0677]],\n",
      "\n",
      "          [[-0.0368,  0.0226, -0.1100],\n",
      "           [ 0.0359,  0.1058,  0.0409],\n",
      "           [-0.0555, -0.0067,  0.0590]],\n",
      "\n",
      "          [[ 0.0633,  0.0179, -0.0761],\n",
      "           [-0.1133,  0.0083, -0.0131],\n",
      "           [-0.0013, -0.0254,  0.0546]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0417,  0.1174, -0.0975],\n",
      "           [ 0.0162, -0.0082, -0.0597],\n",
      "           [ 0.0556, -0.0190, -0.0642]],\n",
      "\n",
      "          [[ 0.0270,  0.0710,  0.0047],\n",
      "           [ 0.0503, -0.0262,  0.0309],\n",
      "           [-0.0177, -0.0878,  0.0631]],\n",
      "\n",
      "          [[-0.0231, -0.1154,  0.1314],\n",
      "           [-0.1015, -0.0781, -0.0538],\n",
      "           [ 0.0146, -0.0477,  0.0598]]],\n",
      "\n",
      "\n",
      "         [[[-0.1230, -0.1386,  0.0114],\n",
      "           [ 0.1410,  0.0322, -0.0015],\n",
      "           [-0.1376, -0.0841, -0.0057]],\n",
      "\n",
      "          [[ 0.0165, -0.0860,  0.0253],\n",
      "           [-0.0444, -0.0625, -0.0266],\n",
      "           [ 0.1613, -0.0147,  0.0569]],\n",
      "\n",
      "          [[-0.1878,  0.1539,  0.0693],\n",
      "           [ 0.0136,  0.0667, -0.1390],\n",
      "           [ 0.0038, -0.0793, -0.1247]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0751, -0.0763, -0.0100],\n",
      "           [ 0.1018, -0.0174,  0.1112],\n",
      "           [-0.0728, -0.0313, -0.0177]],\n",
      "\n",
      "          [[ 0.1135,  0.0710,  0.0748],\n",
      "           [-0.0299,  0.0714,  0.0720],\n",
      "           [-0.0659, -0.0291, -0.1090]],\n",
      "\n",
      "          [[ 0.1893,  0.0282,  0.0044],\n",
      "           [-0.0791, -0.0718,  0.0057],\n",
      "           [-0.0757,  0.0145, -0.0530]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[ 1.0292e-01, -7.3037e-02, -3.4213e-03],\n",
      "           [-3.7380e-02, -1.5799e-01, -3.6933e-02],\n",
      "           [ 1.1576e-01,  3.5855e-02,  1.8382e-02]],\n",
      "\n",
      "          [[ 3.4562e-02,  7.3847e-02, -2.9448e-03],\n",
      "           [-1.9558e-03, -1.7149e-02, -3.2393e-04],\n",
      "           [-3.2489e-02,  8.0636e-02, -6.5833e-02]],\n",
      "\n",
      "          [[ 1.3226e-01,  1.7613e-03,  9.6404e-02],\n",
      "           [-4.3767e-02, -1.0883e-01,  1.5842e-01],\n",
      "           [-9.7663e-03,  5.9778e-02, -4.7436e-03]]],\n",
      "\n",
      "\n",
      "         [[[-8.2800e-03,  7.3952e-02,  7.1486e-02],\n",
      "           [ 6.9614e-02,  6.6953e-02, -7.2272e-02],\n",
      "           [ 2.7659e-02, -8.2192e-03, -2.2528e-02]],\n",
      "\n",
      "          [[ 5.4027e-02,  8.6868e-02,  4.9390e-02],\n",
      "           [-3.4952e-02, -7.2060e-02, -6.7340e-03],\n",
      "           [-3.4487e-02, -1.1949e-02,  5.6696e-02]],\n",
      "\n",
      "          [[ 7.1650e-02,  4.0529e-02,  5.2733e-03],\n",
      "           [ 4.4993e-02, -9.8197e-03, -7.5960e-02],\n",
      "           [-5.4653e-02, -1.2070e-02, -1.3063e-01]]],\n",
      "\n",
      "\n",
      "         [[[-8.4692e-03,  2.7504e-02,  4.9464e-02],\n",
      "           [-3.2023e-02,  2.1399e-02,  2.1422e-03],\n",
      "           [ 6.3772e-02, -3.2571e-02, -2.2435e-02]],\n",
      "\n",
      "          [[-1.3433e-01, -5.6183e-02,  3.0282e-02],\n",
      "           [-2.1110e-03,  1.1313e-02,  3.4396e-02],\n",
      "           [ 2.4342e-03,  1.8651e-02,  2.5400e-02]],\n",
      "\n",
      "          [[ 9.2597e-02,  7.8692e-03,  4.1896e-03],\n",
      "           [ 2.8551e-02,  3.1116e-02, -3.9088e-03],\n",
      "           [-3.0402e-02,  2.7870e-02,  1.7612e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.1266e-02,  7.2356e-02,  3.1755e-02],\n",
      "           [-7.5645e-02,  7.2324e-03, -2.4025e-02],\n",
      "           [ 5.6543e-02, -5.6417e-02, -2.1250e-02]],\n",
      "\n",
      "          [[-5.7249e-02, -1.2110e-02, -1.0024e-01],\n",
      "           [ 1.5524e-01,  7.1619e-02, -9.3447e-02],\n",
      "           [-2.7963e-02,  4.4631e-02, -7.2370e-02]],\n",
      "\n",
      "          [[-2.7780e-02,  3.3237e-02,  2.9971e-02],\n",
      "           [ 2.6812e-02, -4.1331e-02,  4.9685e-03],\n",
      "           [ 2.8876e-02, -1.4478e-02, -7.6452e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.5610e-02, -5.7023e-02,  5.5590e-02],\n",
      "           [-6.4086e-02, -2.7073e-02, -3.6879e-02],\n",
      "           [-5.3420e-02,  4.5789e-02, -6.3654e-02]],\n",
      "\n",
      "          [[-4.0305e-02,  7.6000e-02, -3.8740e-02],\n",
      "           [-5.9209e-02, -8.3123e-02, -2.8930e-02],\n",
      "           [ 3.0960e-03, -7.3132e-03,  8.6009e-02]],\n",
      "\n",
      "          [[ 9.5158e-02,  3.9366e-02, -8.6799e-03],\n",
      "           [ 1.7763e-01, -5.1237e-02, -6.7701e-02],\n",
      "           [-2.8518e-02,  7.5102e-02, -6.0653e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.9100e-02,  5.3959e-02, -9.7881e-02],\n",
      "           [ 1.0792e-01,  8.8453e-02,  5.7560e-02],\n",
      "           [ 8.2551e-03, -9.9531e-02,  3.8449e-02]],\n",
      "\n",
      "          [[ 4.1567e-02, -9.4468e-02, -1.3989e-02],\n",
      "           [ 4.8026e-02, -1.9815e-02, -6.6333e-02],\n",
      "           [-7.1824e-03, -9.5309e-02,  1.6664e-01]],\n",
      "\n",
      "          [[-2.8158e-02, -1.0212e-02,  1.6032e-01],\n",
      "           [-3.5738e-02,  1.4055e-01, -5.7257e-02],\n",
      "           [ 4.4202e-02, -5.2400e-02, -6.4494e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.1106e-02, -7.0857e-02,  1.6415e-02],\n",
      "           [ 4.7616e-02,  1.5498e-02,  5.0303e-03],\n",
      "           [ 8.2714e-02,  4.4921e-02,  1.6997e-02]],\n",
      "\n",
      "          [[-1.0104e-01, -6.1247e-02,  4.1048e-02],\n",
      "           [-1.7547e-01,  8.5457e-03, -3.5603e-02],\n",
      "           [ 6.2935e-02, -1.6328e-02,  2.5096e-02]],\n",
      "\n",
      "          [[ 2.0592e-02, -1.2345e-02, -1.1371e-02],\n",
      "           [ 1.7830e-01, -3.4593e-03, -1.0579e-01],\n",
      "           [-8.4760e-02,  9.4099e-02, -3.4731e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.9699e-02, -1.7108e-01,  5.6645e-02],\n",
      "           [-1.7619e-01, -1.7284e-02,  1.9997e-02],\n",
      "           [-1.1476e-02,  2.9686e-02, -2.1648e-02]],\n",
      "\n",
      "          [[-2.4949e-02, -2.6413e-02,  1.1493e-01],\n",
      "           [ 3.3575e-02, -1.1216e-01, -1.2310e-02],\n",
      "           [ 1.0507e-01,  1.6620e-02,  1.0001e-01]],\n",
      "\n",
      "          [[-1.4484e-02, -3.9177e-02,  3.0076e-02],\n",
      "           [ 3.9351e-02,  9.3972e-03,  7.5649e-02],\n",
      "           [-3.5249e-02, -3.2153e-03, -1.1647e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 1.9869e-02, -8.1267e-03, -9.2483e-02],\n",
      "           [-2.2630e-02, -5.2700e-02, -3.6989e-02],\n",
      "           [ 1.2760e-02,  4.2800e-02,  7.1797e-02]],\n",
      "\n",
      "          [[ 2.5354e-02, -4.0842e-02,  2.7395e-02],\n",
      "           [ 4.9432e-02, -3.3086e-02, -4.7151e-02],\n",
      "           [ 1.2139e-01, -1.4151e-02, -6.2189e-02]],\n",
      "\n",
      "          [[ 7.4997e-02, -1.3122e-01, -5.9080e-02],\n",
      "           [-9.4079e-02,  9.8713e-02, -4.7993e-02],\n",
      "           [-1.0853e-01, -8.2081e-04,  3.0023e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0129e-01,  4.1528e-02,  9.7501e-02],\n",
      "           [ 2.5178e-02, -6.1626e-02, -1.1574e-01],\n",
      "           [ 4.2388e-02, -3.7641e-02,  4.0912e-02]],\n",
      "\n",
      "          [[ 1.4280e-01,  1.1123e-02, -3.4949e-02],\n",
      "           [-4.1672e-02,  1.5258e-01,  1.1101e-01],\n",
      "           [ 5.6070e-02,  2.6993e-02,  3.0521e-02]],\n",
      "\n",
      "          [[ 1.0099e-01, -5.8404e-02, -8.4163e-02],\n",
      "           [-8.9568e-02, -5.4461e-06,  5.1642e-02],\n",
      "           [-6.3450e-02,  6.4730e-02,  1.3015e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5344e-04, -5.8457e-03, -2.6210e-01],\n",
      "           [-1.2154e-01,  3.3475e-02,  4.3604e-02],\n",
      "           [-2.5901e-02,  3.2636e-02, -8.1801e-02]],\n",
      "\n",
      "          [[-2.2253e-02,  1.7186e-01, -1.2501e-01],\n",
      "           [ 1.3351e-02,  1.2801e-03, -7.7526e-03],\n",
      "           [-5.3440e-02, -3.9985e-02, -3.7841e-02]],\n",
      "\n",
      "          [[ 5.2679e-02, -2.8001e-02, -2.3513e-02],\n",
      "           [ 1.3622e-02, -4.3506e-02, -8.0005e-03],\n",
      "           [ 5.5200e-02,  3.1408e-02, -2.6051e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.4591e-02, -5.9178e-03, -5.9923e-02],\n",
      "           [ 3.1214e-02,  6.6803e-02,  8.7645e-02],\n",
      "           [-4.9119e-02,  1.9589e-02,  7.9558e-02]],\n",
      "\n",
      "          [[ 2.1519e-02, -3.4370e-02,  1.0638e-03],\n",
      "           [ 6.8845e-02, -4.0000e-03,  3.5784e-02],\n",
      "           [ 1.0868e-01,  6.9173e-02, -6.3273e-02]],\n",
      "\n",
      "          [[-3.1289e-03,  3.5870e-02, -3.6887e-02],\n",
      "           [-5.6934e-02, -6.6470e-02, -1.5631e-02],\n",
      "           [ 2.8933e-02, -2.9172e-02, -1.8701e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-8.0583e-02,  1.0282e-03, -3.5229e-04],\n",
      "           [-1.1247e-01, -3.9119e-02, -4.2847e-02],\n",
      "           [-5.9876e-02,  1.3825e-02, -2.7973e-02]],\n",
      "\n",
      "          [[ 7.2431e-03, -8.2548e-02,  4.8605e-02],\n",
      "           [ 5.4132e-02,  5.2337e-02, -9.4726e-03],\n",
      "           [ 6.6975e-02, -8.7869e-02,  2.1538e-02]],\n",
      "\n",
      "          [[-8.2944e-02, -2.5413e-03, -7.4534e-03],\n",
      "           [ 2.7907e-02,  3.3349e-03, -6.3245e-02],\n",
      "           [ 5.5125e-02,  5.6424e-02,  2.9584e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2530e-01,  7.6219e-03,  1.4917e-01],\n",
      "           [ 2.6461e-02, -6.4253e-03,  2.0383e-02],\n",
      "           [ 1.9950e-02, -3.0399e-02, -1.6633e-01]],\n",
      "\n",
      "          [[-1.9262e-03,  1.0469e-03,  3.8135e-02],\n",
      "           [-4.3116e-02,  7.6976e-02, -6.3457e-02],\n",
      "           [-1.2747e-01,  4.3970e-04,  6.3464e-02]],\n",
      "\n",
      "          [[ 1.0645e-01, -4.9746e-02,  7.9108e-02],\n",
      "           [ 3.7745e-02,  7.9512e-02,  3.4867e-02],\n",
      "           [-4.7683e-02,  1.7922e-02, -9.7617e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0326e-03,  6.9124e-02, -1.0311e-02],\n",
      "           [-3.5908e-02, -8.4568e-02, -6.4733e-03],\n",
      "           [-5.0498e-04, -5.8868e-02,  2.2580e-02]],\n",
      "\n",
      "          [[ 1.1132e-01, -4.4178e-02, -1.0865e-01],\n",
      "           [ 6.0975e-02, -1.6876e-02,  9.1956e-03],\n",
      "           [ 1.5661e-04, -1.6031e-02, -1.1492e-01]],\n",
      "\n",
      "          [[ 2.2423e-02,  1.0080e-01,  6.4992e-02],\n",
      "           [ 5.8327e-02,  2.4166e-02, -3.0297e-02],\n",
      "           [ 2.2796e-02, -1.4912e-02,  1.2740e-01]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.5315e-02,  9.4145e-02,  8.3777e-02],\n",
      "           [ 6.5342e-02,  3.8639e-02,  1.1705e-01],\n",
      "           [ 8.3717e-02, -1.1803e-01,  5.6608e-03]],\n",
      "\n",
      "          [[ 1.9706e-03,  2.0768e-02, -1.5306e-02],\n",
      "           [-9.1169e-02,  6.1150e-02,  1.3868e-01],\n",
      "           [ 2.7239e-02,  3.1049e-02,  8.7817e-02]],\n",
      "\n",
      "          [[ 2.5716e-02,  3.7175e-02, -1.4271e-02],\n",
      "           [ 1.1681e-01, -2.3915e-02,  3.2022e-02],\n",
      "           [ 6.8012e-03, -1.3067e-03, -7.3576e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0346e-01,  2.7349e-02, -4.6665e-02],\n",
      "           [-7.3937e-02,  5.7229e-03,  3.6548e-02],\n",
      "           [ 2.8143e-02,  4.1677e-02, -2.3189e-02]],\n",
      "\n",
      "          [[-6.5085e-02, -9.2322e-02, -1.1673e-01],\n",
      "           [-1.7071e-02,  7.7096e-02, -9.9323e-02],\n",
      "           [-1.2294e-02, -8.0188e-02, -2.7484e-02]],\n",
      "\n",
      "          [[ 7.4689e-03,  2.6279e-02,  5.1342e-02],\n",
      "           [-2.9311e-02,  9.4924e-02, -1.1904e-02],\n",
      "           [ 1.1282e-01,  7.0550e-03,  1.0823e-01]]],\n",
      "\n",
      "\n",
      "         [[[-1.2398e-02,  3.8912e-02,  3.9358e-02],\n",
      "           [ 9.0509e-02,  1.4837e-02,  2.1760e-02],\n",
      "           [ 1.8496e-02,  4.1992e-02, -4.9372e-02]],\n",
      "\n",
      "          [[-5.9712e-02,  1.5538e-01,  6.3936e-02],\n",
      "           [-8.5705e-02, -3.3114e-03,  1.3171e-01],\n",
      "           [-6.7777e-02,  4.2121e-02, -2.2945e-02]],\n",
      "\n",
      "          [[ 4.8205e-02, -6.1613e-02,  9.5716e-02],\n",
      "           [-9.7859e-02, -4.4967e-02,  1.8782e-02],\n",
      "           [ 2.0291e-02,  2.2272e-02, -2.1848e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 9.1896e-02,  1.3230e-01,  3.6164e-02],\n",
      "           [ 5.8187e-02, -3.5609e-02, -3.2606e-02],\n",
      "           [-1.5583e-02, -6.1077e-02, -3.9123e-02]],\n",
      "\n",
      "          [[ 2.5063e-02,  1.2276e-01, -4.2513e-02],\n",
      "           [-4.2315e-03,  9.2781e-02,  2.1006e-02],\n",
      "           [-9.2364e-02,  5.2078e-02, -3.7738e-02]],\n",
      "\n",
      "          [[-1.3218e-02, -2.7963e-02,  1.0601e-01],\n",
      "           [ 8.7742e-02,  4.7791e-02,  7.8986e-02],\n",
      "           [ 2.0319e-02, -1.8907e-02, -8.3863e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.6290e-01, -1.7245e-02,  8.9428e-02],\n",
      "           [ 8.2832e-02, -4.4103e-02,  9.2343e-02],\n",
      "           [-2.2914e-02, -1.4896e-01, -4.0112e-02]],\n",
      "\n",
      "          [[ 9.0138e-03, -7.6127e-03,  1.0239e-02],\n",
      "           [ 8.5756e-02, -2.6007e-02,  3.2883e-02],\n",
      "           [-4.0953e-02, -4.2253e-02,  2.8221e-02]],\n",
      "\n",
      "          [[-1.4921e-02,  8.1866e-02, -5.7947e-02],\n",
      "           [ 7.7224e-02, -7.1683e-02, -1.2486e-01],\n",
      "           [-1.5743e-02, -1.1492e-04, -1.5561e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 6.6989e-03,  1.1226e-02,  8.7980e-02],\n",
      "           [-2.8405e-02, -7.9013e-02, -7.7337e-03],\n",
      "           [ 3.9979e-02,  5.7966e-02,  4.5337e-04]],\n",
      "\n",
      "          [[ 1.9788e-02,  1.3784e-01, -6.4619e-03],\n",
      "           [ 1.3746e-01,  1.7718e-01, -8.4322e-02],\n",
      "           [-1.6495e-02, -5.8411e-03, -5.6890e-02]],\n",
      "\n",
      "          [[ 2.9063e-02, -1.1404e-01, -4.6576e-02],\n",
      "           [-7.3087e-02,  2.8407e-02, -8.6151e-02],\n",
      "           [ 1.4715e-02,  1.4622e-02, -5.1283e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.5753e-02, -6.0852e-02, -3.7722e-02],\n",
      "           [ 2.4026e-02,  3.8283e-02, -9.6875e-03],\n",
      "           [ 6.8824e-02,  2.5741e-02,  1.9946e-01]],\n",
      "\n",
      "          [[-3.5985e-02, -2.0841e-02,  1.8776e-02],\n",
      "           [-1.1177e-01,  5.1446e-02,  9.8412e-02],\n",
      "           [-1.4522e-02,  1.6497e-01,  5.1221e-02]],\n",
      "\n",
      "          [[ 1.2800e-01,  4.3465e-02, -1.1926e-01],\n",
      "           [-9.2793e-02, -1.5748e-01, -2.5257e-02],\n",
      "           [ 5.9231e-02, -6.7299e-02, -5.7601e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.6140e-02,  9.0062e-02,  1.3367e-01],\n",
      "           [ 4.7704e-02, -4.9224e-02, -7.5353e-02],\n",
      "           [-9.8424e-02,  2.5772e-02,  6.6741e-02]],\n",
      "\n",
      "          [[-1.0644e-01,  2.6841e-02,  7.9355e-02],\n",
      "           [ 3.2918e-02, -8.4255e-02,  4.0413e-02],\n",
      "           [-6.7867e-03, -4.1333e-02, -3.3385e-02]],\n",
      "\n",
      "          [[ 1.1160e-03,  1.3844e-01, -5.6433e-02],\n",
      "           [-4.6742e-02,  1.1356e-02, -8.0651e-02],\n",
      "           [-1.6683e-02, -2.5592e-02, -1.2077e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 5.3218e-02,  1.5274e-01,  8.1546e-03],\n",
      "           [-4.4488e-02, -9.8425e-02, -2.4982e-02],\n",
      "           [ 4.1432e-02,  7.9977e-02, -1.3158e-01]],\n",
      "\n",
      "          [[ 9.6852e-02, -2.7771e-03,  1.0665e-01],\n",
      "           [ 3.3998e-02, -9.3652e-02, -1.6306e-01],\n",
      "           [ 8.4314e-02, -9.0627e-02,  2.9220e-03]],\n",
      "\n",
      "          [[-7.1848e-03,  4.9001e-02, -5.2929e-02],\n",
      "           [-1.0048e-01, -1.1742e-01, -6.5513e-02],\n",
      "           [ 8.0906e-02, -1.0115e-01,  8.2260e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.1805e-02,  4.5671e-03, -4.1013e-02],\n",
      "           [ 9.9499e-02, -1.3250e-02,  1.1744e-02],\n",
      "           [-4.0278e-03, -9.1896e-02, -9.1332e-02]],\n",
      "\n",
      "          [[ 2.5452e-02, -2.3402e-03,  1.4437e-01],\n",
      "           [ 9.7691e-02,  1.2348e-01, -2.7963e-02],\n",
      "           [ 2.6882e-02, -7.6403e-03,  3.6731e-02]],\n",
      "\n",
      "          [[ 7.2606e-02,  1.7533e-01,  5.3531e-02],\n",
      "           [-8.7124e-02, -9.3292e-02, -9.7549e-02],\n",
      "           [-1.0769e-01,  4.1036e-02,  4.1358e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.1831e-02, -3.8089e-03, -2.9089e-02],\n",
      "           [-9.3868e-02, -6.7187e-02,  1.3405e-01],\n",
      "           [ 4.7325e-03, -5.9751e-02, -4.1966e-02]],\n",
      "\n",
      "          [[-2.1223e-02, -6.5987e-02, -4.7210e-02],\n",
      "           [-2.5858e-02,  7.4332e-02, -4.1429e-02],\n",
      "           [ 2.6932e-02, -7.3134e-03, -1.6419e-02]],\n",
      "\n",
      "          [[-2.1355e-01, -7.1672e-03,  6.0538e-02],\n",
      "           [ 1.8944e-02,  5.6785e-02, -5.9809e-02],\n",
      "           [ 1.0026e-02, -3.1838e-02, -7.1006e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.4696e-03, -3.8753e-02, -8.1489e-03],\n",
      "           [-2.7787e-02,  6.1285e-02, -7.5896e-02],\n",
      "           [ 2.0362e-02,  2.3223e-02, -5.1242e-03]],\n",
      "\n",
      "          [[ 5.7758e-02, -1.6887e-02,  4.3511e-02],\n",
      "           [-4.2087e-03,  8.8879e-03,  1.0740e-02],\n",
      "           [ 1.2486e-01, -1.1619e-04,  8.8222e-02]],\n",
      "\n",
      "          [[-1.2558e-02,  4.4400e-02,  1.6730e-01],\n",
      "           [ 7.4746e-02, -8.2707e-02, -4.3750e-02],\n",
      "           [ 7.9789e-02,  7.4191e-02,  1.4777e-01]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.3925e-01,  2.8629e-03, -4.9045e-03],\n",
      "           [-2.7688e-02,  9.5320e-02, -3.3210e-02],\n",
      "           [ 8.5654e-02,  1.1820e-02,  1.8918e-02]],\n",
      "\n",
      "          [[-5.8285e-02, -3.0485e-02,  2.3240e-02],\n",
      "           [ 6.6640e-02, -1.4812e-02, -7.7014e-02],\n",
      "           [ 1.8937e-01,  9.6894e-02, -1.7382e-02]],\n",
      "\n",
      "          [[-3.8917e-02, -4.6777e-02, -6.3222e-02],\n",
      "           [ 1.7866e-02,  2.9614e-02,  1.7818e-01],\n",
      "           [ 8.1214e-03, -6.3363e-02,  3.6707e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 8.5678e-02,  8.3534e-02, -1.9089e-02],\n",
      "           [-3.7018e-02, -1.7752e-01, -7.3247e-03],\n",
      "           [-1.0054e-01,  9.2546e-03,  8.0261e-02]],\n",
      "\n",
      "          [[ 7.2041e-02, -5.2374e-02,  2.7926e-02],\n",
      "           [ 2.4554e-02, -1.4127e-01,  2.4047e-02],\n",
      "           [ 2.9244e-02,  5.2285e-02, -2.7434e-02]],\n",
      "\n",
      "          [[-1.4240e-02, -9.6636e-02,  5.3596e-02],\n",
      "           [-4.8494e-02,  1.0981e-01, -1.2886e-01],\n",
      "           [ 4.6628e-02,  1.6384e-02, -3.8794e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 8.7320e-02,  3.1049e-02, -2.6673e-02],\n",
      "           [-4.2707e-02, -3.5312e-02,  9.3273e-02],\n",
      "           [-7.6428e-02,  3.6413e-02,  5.7032e-02]],\n",
      "\n",
      "          [[-9.4085e-02,  1.3689e-02, -9.0232e-02],\n",
      "           [-2.5003e-02,  4.0991e-02, -4.9277e-02],\n",
      "           [-6.5956e-02, -3.5229e-02, -3.5097e-02]],\n",
      "\n",
      "          [[-5.2834e-02,  2.9157e-02, -5.1365e-02],\n",
      "           [ 8.7900e-02,  4.3955e-02, -2.5846e-02],\n",
      "           [ 7.7848e-02,  3.6586e-02, -4.2791e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.7354e-02,  2.9190e-02, -1.7114e-01],\n",
      "           [-3.9921e-02, -8.1276e-03, -3.0211e-02],\n",
      "           [-2.4997e-02,  8.9240e-02, -2.6966e-02]],\n",
      "\n",
      "          [[ 6.5651e-02, -3.2383e-02,  8.1853e-02],\n",
      "           [-6.9826e-03,  8.9903e-03, -8.8503e-02],\n",
      "           [ 3.7580e-02, -5.3316e-02, -6.0178e-02]],\n",
      "\n",
      "          [[ 4.8321e-02, -1.0036e-02,  1.1274e-01],\n",
      "           [-1.4290e-01, -9.4758e-02,  4.8370e-02],\n",
      "           [ 8.5228e-02,  7.6880e-03, -1.9183e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.4839e-03,  3.6920e-02,  5.9834e-03],\n",
      "           [-2.5657e-02,  5.5573e-02,  2.9160e-02],\n",
      "           [-9.9490e-03,  1.1236e-01, -6.9163e-02]],\n",
      "\n",
      "          [[ 1.3551e-02, -3.2950e-02, -2.5669e-02],\n",
      "           [-7.5754e-03, -7.9516e-03,  3.5337e-02],\n",
      "           [-8.8875e-02, -7.2338e-02, -2.3812e-03]],\n",
      "\n",
      "          [[ 1.3866e-01,  2.9810e-02, -4.2857e-02],\n",
      "           [ 3.9379e-03, -3.5353e-02, -1.1412e-02],\n",
      "           [-4.8004e-03,  2.7123e-02,  2.6384e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.0949e-01, -3.5264e-03, -1.0350e-02],\n",
      "           [-1.0997e-02, -3.5769e-02, -7.7286e-02],\n",
      "           [ 3.5855e-03,  9.9599e-02,  2.7182e-02]],\n",
      "\n",
      "          [[-2.4952e-02,  8.7862e-03,  1.6737e-02],\n",
      "           [ 6.2319e-02,  2.5562e-02,  4.6385e-02],\n",
      "           [-8.0724e-02,  1.2364e-01, -1.8434e-02]],\n",
      "\n",
      "          [[-4.3264e-02, -1.8249e-01, -7.9943e-03],\n",
      "           [ 4.8100e-02, -3.4680e-02,  8.8708e-02],\n",
      "           [-1.4136e-01, -1.5624e-01,  1.3810e-01]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.3356e-01, -1.1168e-01, -1.4865e-02],\n",
      "           [-1.8180e-02, -4.1556e-02,  8.1249e-02],\n",
      "           [ 1.3582e-02, -4.6183e-03, -3.1118e-02]],\n",
      "\n",
      "          [[-4.6261e-02,  5.2143e-02, -2.9217e-03],\n",
      "           [-2.3543e-02, -2.1008e-02,  5.3761e-02],\n",
      "           [-1.6394e-02,  9.8243e-02,  1.9157e-02]],\n",
      "\n",
      "          [[ 5.1917e-02,  1.5715e-02, -4.5529e-02],\n",
      "           [-7.6919e-02, -1.0209e-02, -1.0460e-01],\n",
      "           [ 8.5016e-02,  6.2915e-02, -1.5721e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.8907e-02, -5.4480e-02,  1.6757e-02],\n",
      "           [-9.4878e-02,  7.2519e-03, -1.8635e-02],\n",
      "           [-3.2262e-02, -6.3646e-02,  7.6848e-02]],\n",
      "\n",
      "          [[ 2.5462e-02, -1.3201e-02,  7.6920e-02],\n",
      "           [ 5.5182e-02,  5.0666e-02, -3.3039e-02],\n",
      "           [ 2.4507e-02, -3.2159e-03, -1.6126e-02]],\n",
      "\n",
      "          [[ 1.1428e-01, -2.9615e-03, -6.7825e-02],\n",
      "           [ 9.1418e-02,  1.6549e-02, -2.2598e-02],\n",
      "           [-7.4824e-02,  7.3663e-02,  6.0956e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.0018e-02, -2.8438e-02,  1.5272e-01],\n",
      "           [-3.8582e-02,  8.6486e-02, -1.1912e-01],\n",
      "           [-8.0101e-02, -2.4630e-02,  2.9545e-02]],\n",
      "\n",
      "          [[-3.0726e-02,  5.5699e-02, -7.3271e-02],\n",
      "           [-8.3447e-02,  1.6135e-01, -4.2805e-02],\n",
      "           [-5.6487e-02,  2.2198e-02,  8.6147e-02]],\n",
      "\n",
      "          [[ 1.4582e-02, -1.2358e-01, -1.4462e-02],\n",
      "           [-4.4725e-02,  1.1120e-01,  8.5866e-02],\n",
      "           [-4.2272e-02, -5.3093e-02,  1.6579e-02]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[ 7.9555e-02,  1.1716e-01,  9.6048e-03],\n",
      "           [-6.0173e-02,  6.6265e-02, -5.9457e-02],\n",
      "           [ 5.8368e-03,  1.0705e-02,  2.7720e-02]],\n",
      "\n",
      "          [[ 2.0632e-02, -3.2379e-02,  8.0419e-02],\n",
      "           [ 7.4383e-02,  8.5836e-02, -1.9320e-02],\n",
      "           [ 2.8667e-02,  5.7581e-02,  3.7101e-03]],\n",
      "\n",
      "          [[ 1.0825e-01, -5.7688e-02, -1.2525e-02],\n",
      "           [ 1.6349e-02, -9.8880e-02,  4.7663e-02],\n",
      "           [-4.4418e-03,  3.1619e-02, -1.5880e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.6047e-03, -7.7077e-02, -4.2992e-02],\n",
      "           [-3.5761e-02,  1.6915e-02, -2.0943e-02],\n",
      "           [ 2.8361e-02, -6.5782e-02,  7.6503e-02]],\n",
      "\n",
      "          [[ 1.6871e-02, -4.5506e-02,  8.6248e-03],\n",
      "           [-5.8117e-02, -4.0987e-02,  7.2227e-02],\n",
      "           [-7.3983e-03,  3.4837e-02,  3.7161e-03]],\n",
      "\n",
      "          [[-3.9735e-02,  4.8462e-02, -3.0891e-02],\n",
      "           [ 9.7193e-03,  5.2311e-02, -4.8521e-02],\n",
      "           [-2.1630e-02, -2.8327e-02, -4.1146e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.9747e-02,  4.3700e-02,  1.0446e-02],\n",
      "           [ 6.7345e-02, -1.2293e-01,  1.7194e-02],\n",
      "           [-4.8986e-02,  4.0080e-04,  1.2701e-01]],\n",
      "\n",
      "          [[-1.7853e-02,  6.0793e-02,  1.4061e-02],\n",
      "           [-3.7241e-02,  7.4584e-03,  8.9620e-02],\n",
      "           [-5.1452e-02, -3.0978e-03, -1.3974e-02]],\n",
      "\n",
      "          [[-1.1464e-02, -4.8155e-02,  2.0594e-02],\n",
      "           [-8.9387e-03,  1.2125e-02,  2.0499e-03],\n",
      "           [-6.2285e-02,  6.8002e-03,  1.6562e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.2561e-02,  3.9554e-03, -5.1118e-03],\n",
      "           [-2.1363e-03,  4.1661e-03,  1.9137e-02],\n",
      "           [-2.8715e-02, -5.3852e-02,  9.6073e-03]],\n",
      "\n",
      "          [[-4.0341e-02,  4.0236e-02,  3.2356e-02],\n",
      "           [ 1.0651e-02, -9.1879e-02,  1.2032e-01],\n",
      "           [ 5.2267e-02, -3.7252e-03, -3.6871e-02]],\n",
      "\n",
      "          [[-1.6512e-02, -9.3930e-02,  2.3757e-02],\n",
      "           [-1.3202e-02, -6.5406e-03, -2.8830e-02],\n",
      "           [-4.2314e-03,  5.3677e-02,  6.1656e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.7706e-02, -7.0291e-02, -6.3013e-02],\n",
      "           [-3.8919e-02, -3.8265e-02,  8.9332e-02],\n",
      "           [-3.0776e-02,  1.4914e-01,  5.8592e-03]],\n",
      "\n",
      "          [[-8.2632e-03, -4.9078e-02, -1.4049e-01],\n",
      "           [-6.3679e-02, -6.5820e-02,  5.9024e-02],\n",
      "           [-8.1401e-02, -2.9346e-02,  3.9697e-02]],\n",
      "\n",
      "          [[ 5.1426e-03, -3.5956e-02,  4.9355e-02],\n",
      "           [-6.7251e-02,  2.0856e-02, -9.5561e-03],\n",
      "           [ 2.5409e-02, -4.0043e-02,  9.2575e-03]]],\n",
      "\n",
      "\n",
      "         [[[-6.5457e-03,  7.6838e-02,  6.3537e-02],\n",
      "           [ 6.3723e-02, -9.5775e-03, -5.1357e-02],\n",
      "           [ 5.6814e-02, -1.7174e-02, -4.5398e-03]],\n",
      "\n",
      "          [[ 5.6709e-02,  4.1420e-02, -6.9503e-02],\n",
      "           [-3.9469e-02,  7.8040e-02,  2.4375e-02],\n",
      "           [ 4.0354e-02,  3.8083e-02,  6.8124e-02]],\n",
      "\n",
      "          [[-1.1045e-02,  9.9106e-03, -1.7756e-02],\n",
      "           [ 6.7788e-03,  8.2240e-02,  5.5869e-02],\n",
      "           [ 1.0239e-02, -7.9362e-02, -2.7973e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-8.9300e-03,  8.0812e-03,  2.4205e-02],\n",
      "           [-6.6476e-02,  8.8250e-02, -5.8700e-03],\n",
      "           [-5.4628e-03, -5.0887e-02,  1.6889e-02]],\n",
      "\n",
      "          [[-4.2285e-02,  2.1336e-02,  6.8186e-02],\n",
      "           [-3.2784e-02, -3.7324e-03, -6.6353e-04],\n",
      "           [ 1.3176e-03, -7.8450e-02, -9.2931e-03]],\n",
      "\n",
      "          [[ 2.2628e-02, -6.9809e-02,  4.2155e-02],\n",
      "           [ 6.0904e-02, -9.3817e-02,  1.1532e-02],\n",
      "           [ 1.5460e-02, -7.2456e-02,  5.4917e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.6728e-02, -1.1391e-01,  3.5892e-02],\n",
      "           [-5.0028e-03, -3.8637e-02, -7.9362e-02],\n",
      "           [ 2.9259e-02,  1.1421e-01, -1.3434e-02]],\n",
      "\n",
      "          [[-8.0833e-02, -1.1534e-02, -3.5370e-02],\n",
      "           [ 4.7599e-02,  6.0882e-03, -2.8712e-02],\n",
      "           [-6.2129e-02,  1.4282e-01,  1.8217e-02]],\n",
      "\n",
      "          [[-7.2827e-02, -7.5970e-02, -2.4403e-02],\n",
      "           [ 4.5660e-03,  5.8067e-02, -9.4099e-03],\n",
      "           [ 1.2290e-02,  7.1828e-02, -4.1346e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0721e-02, -7.1653e-02, -2.1553e-02],\n",
      "           [-4.4369e-02,  5.8329e-02,  4.5254e-02],\n",
      "           [ 7.7803e-02,  3.6851e-02, -8.0934e-02]],\n",
      "\n",
      "          [[ 8.0510e-03,  1.8863e-02,  3.2794e-02],\n",
      "           [ 1.7683e-02,  3.9456e-02, -9.3545e-03],\n",
      "           [ 5.8461e-02, -1.3455e-01, -5.1574e-02]],\n",
      "\n",
      "          [[ 1.0805e-01, -5.9425e-03,  3.7518e-02],\n",
      "           [ 4.0898e-02, -7.8993e-03, -1.7800e-02],\n",
      "           [ 3.4519e-03,  3.1761e-03, -2.2613e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 4.6729e-03, -5.4199e-02,  4.1255e-02],\n",
      "           [ 3.1624e-02,  5.4079e-03,  1.5518e-02],\n",
      "           [ 5.8848e-02,  8.6758e-02,  6.1181e-02]],\n",
      "\n",
      "          [[ 2.7015e-03,  1.6023e-02, -6.6774e-02],\n",
      "           [-1.8721e-02, -2.5293e-02, -4.1015e-02],\n",
      "           [-8.4762e-02,  1.6587e-02, -5.0825e-02]],\n",
      "\n",
      "          [[-3.8617e-02,  5.6402e-02, -1.6757e-01],\n",
      "           [-3.3389e-03, -3.5318e-02, -3.3754e-03],\n",
      "           [-6.1364e-02,  8.6590e-02,  4.2133e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.4680e-02, -3.1398e-02, -2.9738e-02],\n",
      "           [ 5.4434e-02, -8.6448e-03, -3.2395e-02],\n",
      "           [-6.1526e-02,  3.3640e-02,  1.4153e-02]],\n",
      "\n",
      "          [[-8.2209e-02, -7.7043e-04, -1.4052e-02],\n",
      "           [-3.9818e-02, -3.9137e-02, -2.6050e-02],\n",
      "           [-4.6221e-03, -2.3370e-03,  6.8346e-02]],\n",
      "\n",
      "          [[ 5.1028e-02,  6.1568e-03,  5.3547e-02],\n",
      "           [-1.5672e-02, -2.3343e-03,  1.3236e-02],\n",
      "           [-7.6212e-02, -5.9355e-03, -2.1275e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3624e-02, -6.8178e-03, -3.1984e-03],\n",
      "           [-7.0457e-02, -5.3996e-02, -3.6804e-02],\n",
      "           [ 4.9631e-02, -2.6301e-02,  4.1572e-02]],\n",
      "\n",
      "          [[ 7.4157e-03, -7.4193e-03,  5.8964e-02],\n",
      "           [-5.3925e-02, -4.8751e-02, -7.1233e-02],\n",
      "           [-6.0849e-03, -4.2463e-02, -8.5482e-02]],\n",
      "\n",
      "          [[-1.6693e-02, -8.0828e-02, -2.7872e-02],\n",
      "           [ 6.1571e-02,  5.4139e-02,  5.7270e-02],\n",
      "           [-3.6642e-02,  1.1147e-02,  5.6614e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-8.0387e-02,  2.2617e-02,  1.7894e-02],\n",
      "           [-3.8467e-02, -8.0534e-03, -3.4771e-02],\n",
      "           [-2.2804e-02, -7.8957e-02,  5.4797e-02]],\n",
      "\n",
      "          [[-2.2428e-02, -5.7935e-02,  5.6738e-02],\n",
      "           [ 1.0830e-01, -4.9157e-02, -1.6296e-02],\n",
      "           [-2.3020e-02, -1.1365e-02, -3.0173e-02]],\n",
      "\n",
      "          [[-8.8480e-03,  2.3965e-03,  2.1254e-02],\n",
      "           [ 1.3143e-02, -1.0254e-01, -8.7786e-02],\n",
      "           [-1.0697e-02, -3.8396e-02,  4.6314e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.1522e-02,  2.8167e-02,  6.4976e-02],\n",
      "           [ 4.2215e-02,  9.7952e-03, -8.1486e-03],\n",
      "           [-2.6861e-02, -5.7200e-03,  3.7922e-02]],\n",
      "\n",
      "          [[ 1.1495e-01,  3.2157e-02, -2.4775e-02],\n",
      "           [ 2.4431e-02,  5.6148e-02,  2.7485e-03],\n",
      "           [-6.8405e-02,  1.8298e-02, -9.8617e-02]],\n",
      "\n",
      "          [[ 6.3916e-03,  2.0277e-03, -1.3112e-02],\n",
      "           [ 6.5944e-02, -6.2557e-02, -5.3852e-02],\n",
      "           [-2.8630e-02, -1.1580e-02,  4.7563e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.5485e-02,  6.7363e-03,  7.8623e-03],\n",
      "           [-1.0965e-01,  6.3999e-02, -5.5187e-02],\n",
      "           [-8.7574e-02, -6.6280e-02,  6.2899e-02]],\n",
      "\n",
      "          [[ 1.4571e-02,  3.7985e-03,  2.8084e-03],\n",
      "           [ 9.1285e-02, -5.5270e-02, -3.6211e-02],\n",
      "           [ 3.7213e-02, -4.8489e-02, -5.3553e-02]],\n",
      "\n",
      "          [[ 4.1001e-02, -7.0882e-02, -5.2430e-02],\n",
      "           [-7.3252e-02,  3.6770e-02, -4.6975e-03],\n",
      "           [ 4.2369e-02, -4.0829e-03, -2.6881e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-6.7569e-02, -7.7690e-02, -4.9889e-02],\n",
      "           [ 7.6061e-02, -8.4241e-03, -1.9399e-02],\n",
      "           [-7.5310e-02,  9.4894e-02, -7.3183e-02]],\n",
      "\n",
      "          [[ 5.3966e-02,  3.7435e-03, -1.8014e-02],\n",
      "           [-1.4253e-02,  8.4439e-02, -4.0459e-02],\n",
      "           [-6.6378e-02, -1.2618e-01,  8.7733e-03]],\n",
      "\n",
      "          [[-5.6521e-02,  1.8439e-02, -6.9590e-02],\n",
      "           [-5.0879e-02,  1.4883e-02, -1.0353e-03],\n",
      "           [ 1.4335e-01,  1.9504e-02,  1.8117e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.5655e-02,  2.7015e-02, -1.0802e-02],\n",
      "           [ 2.3762e-04, -3.7078e-02,  4.2833e-02],\n",
      "           [-2.3799e-02,  4.6969e-02, -1.4041e-02]],\n",
      "\n",
      "          [[ 6.4689e-02,  7.0220e-03, -2.5832e-02],\n",
      "           [ 2.7455e-02, -6.3160e-04,  3.0100e-02],\n",
      "           [ 2.4941e-02,  3.2741e-02,  3.1127e-02]],\n",
      "\n",
      "          [[-2.4237e-02,  5.4968e-02,  9.0950e-03],\n",
      "           [ 2.9380e-02,  3.2943e-04, -6.4511e-02],\n",
      "           [-6.7757e-03, -3.1642e-02,  4.2757e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.6187e-02,  3.8618e-02,  1.3941e-02],\n",
      "           [ 1.9186e-02,  8.1408e-03, -2.0786e-02],\n",
      "           [ 1.3429e-02, -1.0537e-02,  4.4810e-02]],\n",
      "\n",
      "          [[ 1.6301e-02, -2.3210e-03, -3.4772e-02],\n",
      "           [ 3.0649e-02, -5.5913e-02,  1.8685e-02],\n",
      "           [ 3.0887e-02, -3.1399e-02,  5.6185e-02]],\n",
      "\n",
      "          [[ 8.6100e-02,  4.3845e-02, -1.0094e-01],\n",
      "           [ 2.2943e-02,  4.5463e-02, -2.0861e-03],\n",
      "           [ 3.0853e-02, -5.6409e-02,  1.4758e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.0987e-02,  1.7941e-03,  5.6762e-02],\n",
      "           [ 5.8862e-02,  4.5318e-02, -3.8504e-02],\n",
      "           [-1.2307e-02, -7.4279e-02,  1.8106e-02]],\n",
      "\n",
      "          [[-3.1027e-03, -8.1741e-02, -2.2763e-02],\n",
      "           [-4.3612e-02,  2.3068e-02,  2.0908e-02],\n",
      "           [ 3.1177e-03,  3.7252e-02, -6.5598e-02]],\n",
      "\n",
      "          [[-5.0069e-02,  3.2384e-02, -9.3273e-02],\n",
      "           [-2.3769e-02, -4.1067e-02, -6.7637e-02],\n",
      "           [ 7.9041e-02, -5.3089e-02, -8.3234e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.6013e-02, -1.2736e-02, -1.1249e-02],\n",
      "           [-8.2166e-02, -3.9851e-02, -7.1970e-02],\n",
      "           [-1.0668e-01,  4.7338e-02,  1.5144e-02]],\n",
      "\n",
      "          [[ 1.7597e-02, -5.6484e-02,  3.3091e-02],\n",
      "           [ 5.8436e-02,  7.5012e-02,  3.7531e-02],\n",
      "           [ 4.0958e-02,  1.4011e-02,  6.8762e-02]],\n",
      "\n",
      "          [[ 1.6316e-02,  1.6193e-02,  3.4824e-02],\n",
      "           [ 2.6744e-02,  3.6889e-02, -1.8555e-02],\n",
      "           [ 4.8109e-02, -8.1148e-02, -1.5002e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2239e-02,  2.3403e-02,  1.0266e-01],\n",
      "           [ 1.0733e-02,  5.4347e-02, -1.0927e-02],\n",
      "           [-2.6973e-02,  5.3981e-02, -2.2334e-02]],\n",
      "\n",
      "          [[-2.4059e-02, -5.0772e-03, -7.6884e-02],\n",
      "           [ 3.7638e-02, -5.3140e-02,  2.0783e-02],\n",
      "           [-1.8719e-02, -4.7300e-02,  2.9906e-02]],\n",
      "\n",
      "          [[-1.5559e-02, -2.2073e-02, -7.5619e-03],\n",
      "           [ 5.4869e-02, -1.6391e-02,  1.5334e-02],\n",
      "           [ 1.8934e-02,  6.4124e-02,  5.4748e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.5349e-02, -1.7139e-02, -8.9741e-02],\n",
      "           [ 3.1730e-03, -8.8853e-02,  2.0072e-02],\n",
      "           [-1.8110e-02, -7.2737e-03, -2.4843e-02]],\n",
      "\n",
      "          [[-4.1420e-02,  1.0231e-02,  2.4411e-02],\n",
      "           [-3.6809e-02, -2.7533e-02, -3.9025e-03],\n",
      "           [-5.6167e-02, -6.4168e-02, -1.8844e-04]],\n",
      "\n",
      "          [[-9.0992e-02, -2.4605e-02,  5.5594e-02],\n",
      "           [ 2.2498e-02, -1.3123e-03, -2.9419e-02],\n",
      "           [ 1.2333e-02,  2.6238e-02,  7.1199e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.7529e-02,  8.8057e-02,  6.2131e-02],\n",
      "           [-1.2857e-02,  5.9411e-02,  2.4165e-02],\n",
      "           [ 3.5588e-02,  2.5672e-02, -2.3972e-02]],\n",
      "\n",
      "          [[ 4.5456e-02, -4.0228e-02,  2.7966e-03],\n",
      "           [ 2.1726e-02,  3.8284e-03,  1.0614e-01],\n",
      "           [-2.3994e-02,  3.8956e-02,  4.7164e-03]],\n",
      "\n",
      "          [[-5.1081e-03, -1.2816e-01, -7.4853e-02],\n",
      "           [ 2.1011e-02, -2.9175e-02,  1.5342e-02],\n",
      "           [ 1.3581e-03, -3.4092e-02,  5.7845e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.9584e-02,  6.2683e-02, -3.8980e-02],\n",
      "           [ 5.5809e-02, -8.1506e-02,  2.1674e-02],\n",
      "           [-2.0107e-02,  2.2348e-02, -4.1992e-02]],\n",
      "\n",
      "          [[-2.8313e-02,  6.1280e-02, -1.1617e-01],\n",
      "           [ 3.4262e-02,  6.0397e-04,  3.1542e-02],\n",
      "           [ 4.5789e-02,  4.1181e-02,  2.7094e-02]],\n",
      "\n",
      "          [[-9.6383e-03, -5.2044e-02,  4.8781e-02],\n",
      "           [-5.1623e-02,  4.8113e-02, -4.2200e-03],\n",
      "           [ 6.4568e-02, -3.6475e-02,  2.2829e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.9780e-02, -8.1826e-04,  4.6141e-02],\n",
      "           [ 3.6040e-02,  6.0740e-02, -4.5451e-02],\n",
      "           [ 1.3261e-02,  6.3053e-03,  1.6755e-02]],\n",
      "\n",
      "          [[ 5.9922e-02,  3.7148e-02,  8.3458e-03],\n",
      "           [ 5.6642e-02, -3.2436e-02, -5.4136e-02],\n",
      "           [-1.7796e-02, -1.7969e-02, -8.5409e-03]],\n",
      "\n",
      "          [[-3.9240e-02,  3.2933e-02,  5.2093e-02],\n",
      "           [ 3.5402e-03, -3.7063e-02, -3.7980e-02],\n",
      "           [ 7.8610e-02,  1.0271e-02, -1.0747e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 7.4715e-02, -1.7221e-02,  4.0275e-02],\n",
      "           [-1.0309e-01, -2.5646e-02,  1.1053e-02],\n",
      "           [ 4.6440e-03, -1.6277e-02,  8.7603e-03]],\n",
      "\n",
      "          [[-5.5021e-03, -2.1029e-02,  2.8055e-02],\n",
      "           [-1.1942e-02, -4.7093e-02, -2.6334e-04],\n",
      "           [ 8.4843e-02, -4.2342e-02, -6.3920e-02]],\n",
      "\n",
      "          [[-1.0450e-03, -7.6058e-03,  3.0368e-02],\n",
      "           [ 5.4022e-02,  9.6100e-03, -1.0548e-02],\n",
      "           [-1.0929e-02, -3.4418e-02, -2.8851e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.7313e-04, -3.6581e-02, -1.6564e-03],\n",
      "           [-2.3265e-02, -2.7697e-02,  4.0893e-02],\n",
      "           [-1.0853e-01, -3.2389e-02,  5.9593e-02]],\n",
      "\n",
      "          [[-3.9323e-02, -3.5301e-02,  6.6249e-02],\n",
      "           [ 2.5391e-02,  6.4404e-02,  4.2132e-02],\n",
      "           [-8.1329e-03, -2.0914e-02, -4.7036e-04]],\n",
      "\n",
      "          [[-9.7650e-03,  3.5001e-02, -6.0109e-03],\n",
      "           [ 8.1669e-02, -4.0452e-02, -8.3417e-03],\n",
      "           [-3.8399e-03, -3.4535e-03,  6.6442e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 7.1710e-03, -9.5495e-02, -3.4250e-02],\n",
      "           [-3.8959e-03, -6.1275e-02, -4.9345e-02],\n",
      "           [ 3.5020e-02,  4.1038e-02,  3.7170e-02]],\n",
      "\n",
      "          [[-2.5188e-02,  2.8865e-02, -3.1790e-03],\n",
      "           [-1.0017e-01, -1.6799e-02, -1.9498e-02],\n",
      "           [-1.5278e-03,  3.2969e-02,  6.8800e-04]],\n",
      "\n",
      "          [[-8.3284e-02,  3.7594e-02, -3.7334e-03],\n",
      "           [-2.0658e-03,  3.0826e-02,  7.8746e-02],\n",
      "           [-1.6932e-02,  7.0268e-02, -4.0539e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.8023e-02,  5.8091e-03,  8.2868e-03],\n",
      "           [ 9.8251e-03,  7.6614e-04,  7.8822e-03],\n",
      "           [ 1.4622e-02,  2.2124e-02,  3.7937e-02]],\n",
      "\n",
      "          [[ 6.0656e-02, -6.4642e-02, -3.2171e-02],\n",
      "           [ 5.8623e-02, -6.2376e-02, -1.0879e-02],\n",
      "           [-4.4281e-03, -6.8742e-02, -4.4356e-02]],\n",
      "\n",
      "          [[ 8.7124e-02,  5.1331e-02,  2.3103e-02],\n",
      "           [-3.0203e-02, -5.1560e-02, -2.9309e-03],\n",
      "           [-1.0085e-02,  8.7990e-02,  5.0790e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.8675e-04, -1.8150e-02,  4.8586e-02],\n",
      "           [-2.0465e-02,  5.0325e-04,  6.2996e-02],\n",
      "           [-6.7614e-02,  4.3113e-02, -6.8804e-02]],\n",
      "\n",
      "          [[-3.7501e-02, -4.8477e-02,  4.3799e-02],\n",
      "           [-1.3517e-02, -4.9376e-02,  7.4742e-02],\n",
      "           [ 1.4138e-02, -3.1172e-02,  5.0506e-02]],\n",
      "\n",
      "          [[ 3.5591e-03, -3.5214e-02, -9.4064e-03],\n",
      "           [ 1.5903e-02,  2.3707e-03, -4.3121e-02],\n",
      "           [ 7.4954e-03, -6.6080e-02, -4.0424e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.2532e-03, -3.4926e-02, -4.0172e-02],\n",
      "           [-3.1583e-02,  2.6485e-02, -3.6579e-02],\n",
      "           [-3.6688e-02, -9.1918e-02,  7.0646e-02]],\n",
      "\n",
      "          [[-7.5749e-02, -3.5804e-02,  3.0787e-02],\n",
      "           [-2.3659e-02,  2.4011e-02, -1.7624e-02],\n",
      "           [-6.0658e-02, -2.5694e-02, -3.3332e-02]],\n",
      "\n",
      "          [[ 3.8389e-02,  7.1067e-02, -1.4496e-02],\n",
      "           [-9.0215e-02, -5.7936e-02,  1.8430e-03],\n",
      "           [ 2.5180e-02,  1.0300e-01,  9.5398e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 7.9855e-03, -8.8309e-02, -2.0984e-02],\n",
      "           [ 1.1299e-02, -7.2565e-02, -4.9823e-02],\n",
      "           [ 1.1936e-01, -2.2009e-03, -2.9668e-02]],\n",
      "\n",
      "          [[ 8.8340e-02, -2.0792e-02,  3.2081e-03],\n",
      "           [-6.3928e-02, -5.1971e-02,  3.7443e-02],\n",
      "           [-1.3195e-01, -2.0637e-02,  2.0684e-02]],\n",
      "\n",
      "          [[ 5.9375e-03, -4.0802e-02, -4.0470e-02],\n",
      "           [ 4.1132e-02,  4.6669e-02, -1.2282e-01],\n",
      "           [-2.4083e-02,  5.3324e-02, -6.7735e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.8983e-03, -8.7978e-04,  3.2992e-02],\n",
      "           [-2.7106e-02, -3.0384e-02,  3.1657e-03],\n",
      "           [ 2.1671e-02,  1.0327e-01,  5.6463e-03]],\n",
      "\n",
      "          [[-4.8262e-02, -3.5344e-02, -4.6876e-02],\n",
      "           [-6.3505e-02,  1.0713e-01,  4.5762e-02],\n",
      "           [ 8.9398e-02,  3.0908e-03, -3.3006e-02]],\n",
      "\n",
      "          [[-3.8082e-02, -4.8607e-02, -1.5573e-02],\n",
      "           [-3.8414e-02,  5.1235e-02, -8.3251e-02],\n",
      "           [ 1.0705e-02,  3.4347e-02,  6.4267e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.3048e-02, -1.5398e-02, -8.3816e-03],\n",
      "           [ 6.3015e-04,  7.8097e-02, -2.7254e-02],\n",
      "           [-4.4155e-02,  5.1527e-02, -5.1621e-02]],\n",
      "\n",
      "          [[ 3.9226e-02, -7.4601e-02,  3.0433e-02],\n",
      "           [-5.3180e-02,  1.0297e-01,  4.6498e-03],\n",
      "           [ 3.9831e-03, -5.4378e-02,  4.8524e-02]],\n",
      "\n",
      "          [[-5.7695e-02,  4.4715e-02,  5.9356e-02],\n",
      "           [ 2.5379e-02,  1.2021e-03,  2.0152e-02],\n",
      "           [ 6.8512e-02, -2.8979e-02, -1.4793e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7518e-02,  1.4575e-02,  3.7580e-02],\n",
      "           [ 3.9683e-02, -5.4234e-02, -7.2438e-02],\n",
      "           [-3.9158e-02,  4.1067e-02,  2.4680e-02]],\n",
      "\n",
      "          [[ 5.8274e-02, -5.8255e-02,  2.5553e-02],\n",
      "           [-5.0460e-03,  1.5947e-02, -4.0803e-02],\n",
      "           [-2.7509e-03,  6.8642e-02, -4.3150e-02]],\n",
      "\n",
      "          [[ 2.6496e-02, -4.1750e-02,  2.6872e-02],\n",
      "           [-1.1666e-02,  2.1334e-02, -4.7559e-03],\n",
      "           [-3.9768e-02,  1.3095e-03, -2.4529e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1321e-02, -6.5124e-03, -4.1789e-02],\n",
      "           [ 5.3117e-02,  9.1765e-02,  6.6758e-02],\n",
      "           [-7.9071e-02, -2.6022e-02,  1.2506e-01]],\n",
      "\n",
      "          [[ 4.6459e-02,  5.1902e-03, -1.5770e-04],\n",
      "           [ 6.7366e-02, -4.7722e-02, -4.9892e-03],\n",
      "           [ 6.4893e-03, -7.7018e-02, -5.9541e-02]],\n",
      "\n",
      "          [[-5.5375e-02, -1.8942e-02,  5.2840e-02],\n",
      "           [-2.5832e-02,  4.4366e-02, -1.7770e-02],\n",
      "           [-5.0883e-02, -8.6481e-03,  1.1679e-01]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[-5.1961e-02,  7.6623e-02,  4.4042e-02],\n",
      "           [-1.8824e-02,  5.5475e-03, -5.2505e-02],\n",
      "           [ 8.6166e-02,  6.5336e-02,  2.9025e-02]],\n",
      "\n",
      "          [[-1.9815e-02, -2.7538e-03,  3.1758e-02],\n",
      "           [-4.8390e-03, -4.3628e-02, -5.0954e-03],\n",
      "           [ 4.6821e-02, -1.4827e-02,  2.6751e-04]],\n",
      "\n",
      "          [[ 7.7930e-02,  3.7731e-02,  1.1017e-02],\n",
      "           [-2.7918e-02,  4.6489e-02,  4.3417e-02],\n",
      "           [ 1.6245e-02, -3.3521e-03, -2.5531e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3654e-02, -1.2877e-01,  3.1015e-02],\n",
      "           [ 3.8204e-02, -2.7186e-02,  1.3624e-02],\n",
      "           [ 2.8008e-02, -1.7499e-02,  4.8376e-02]],\n",
      "\n",
      "          [[-2.6971e-02, -7.5873e-02, -1.1492e-01],\n",
      "           [ 2.3896e-02, -4.7788e-02, -7.6284e-02],\n",
      "           [-2.7630e-02,  3.5289e-02,  2.4847e-02]],\n",
      "\n",
      "          [[ 3.3696e-02, -1.1353e-02, -1.3405e-02],\n",
      "           [-4.3532e-02,  6.9599e-03, -6.2577e-02],\n",
      "           [-7.4905e-02, -4.8961e-03,  6.6942e-02]]],\n",
      "\n",
      "\n",
      "         [[[-8.2724e-02, -2.3983e-02, -7.6480e-03],\n",
      "           [ 2.2151e-02,  9.1823e-03,  3.8024e-02],\n",
      "           [-1.5686e-02,  6.6251e-02, -2.7306e-02]],\n",
      "\n",
      "          [[ 7.6285e-02, -1.0160e-02,  6.0745e-02],\n",
      "           [-1.2809e-02,  6.9139e-02, -2.0926e-02],\n",
      "           [ 4.2115e-02, -1.8344e-02,  2.1727e-02]],\n",
      "\n",
      "          [[-1.0728e-01,  3.1814e-02, -1.6436e-02],\n",
      "           [-2.7308e-03, -7.5017e-02,  5.0872e-02],\n",
      "           [-2.1227e-02, -5.7568e-02, -1.8517e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.2597e-02, -1.6195e-02,  7.4786e-02],\n",
      "           [ 5.6254e-02,  4.2451e-02, -2.6094e-02],\n",
      "           [-4.5880e-02, -3.2873e-02, -1.8569e-02]],\n",
      "\n",
      "          [[-5.4410e-03, -2.6175e-02, -6.6247e-02],\n",
      "           [-8.1280e-02,  2.4654e-02,  1.2859e-02],\n",
      "           [-2.6956e-02,  2.7991e-02,  9.7287e-02]],\n",
      "\n",
      "          [[ 1.9339e-02,  5.4826e-02,  6.1512e-02],\n",
      "           [-3.4114e-02, -5.3252e-02, -7.2167e-03],\n",
      "           [ 2.9051e-02, -4.7765e-05,  3.1452e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.9840e-03, -3.3390e-02,  1.8998e-02],\n",
      "           [ 1.1030e-01, -7.5231e-02, -1.0710e-02],\n",
      "           [ 2.3144e-02, -4.1564e-02, -9.1697e-02]],\n",
      "\n",
      "          [[-4.8763e-02, -1.7594e-04,  5.3350e-02],\n",
      "           [ 4.5095e-02,  3.6405e-02, -4.2715e-02],\n",
      "           [-1.2350e-02,  4.2329e-02, -4.1256e-02]],\n",
      "\n",
      "          [[-7.3661e-02,  3.3948e-02, -1.8348e-02],\n",
      "           [ 7.6782e-02, -8.1932e-02,  5.3764e-02],\n",
      "           [-4.4283e-02, -2.4248e-02, -7.1140e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.8113e-03, -9.5058e-02,  2.6504e-02],\n",
      "           [ 6.5931e-03, -3.1745e-03,  5.9125e-02],\n",
      "           [-6.3447e-02,  3.3385e-02,  9.2143e-03]],\n",
      "\n",
      "          [[-7.3472e-02,  2.7128e-02, -3.2362e-02],\n",
      "           [-1.9521e-02,  1.5989e-02, -6.5605e-02],\n",
      "           [-5.3212e-02,  7.8347e-02,  4.9082e-02]],\n",
      "\n",
      "          [[-1.2030e-02,  5.9035e-02, -6.7620e-02],\n",
      "           [ 2.5683e-02, -1.1401e-02,  5.5270e-02],\n",
      "           [ 7.1178e-02, -4.3543e-02, -4.0036e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.6521e-02,  3.7554e-02,  3.0938e-02],\n",
      "           [ 5.9276e-02,  5.2632e-04,  3.9820e-02],\n",
      "           [ 8.9887e-03,  4.2880e-03,  8.7505e-02]],\n",
      "\n",
      "          [[-5.8068e-02, -1.3324e-01,  3.1551e-02],\n",
      "           [ 6.2462e-02, -3.2872e-02,  9.5623e-03],\n",
      "           [-3.0432e-03, -5.0957e-03,  2.0579e-02]],\n",
      "\n",
      "          [[-1.1040e-01,  3.0948e-02,  9.1315e-02],\n",
      "           [-7.1400e-02, -9.1760e-02,  3.8552e-02],\n",
      "           [-4.5241e-03,  8.6406e-02,  2.2367e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.1034e-02,  2.3727e-03,  1.1610e-02],\n",
      "           [-2.1077e-02,  4.8300e-02, -2.5179e-04],\n",
      "           [-3.6637e-02, -2.6701e-02, -4.0513e-02]],\n",
      "\n",
      "          [[-4.8710e-02, -6.0522e-02, -1.2640e-02],\n",
      "           [-3.2740e-02, -2.4381e-02,  3.4781e-02],\n",
      "           [-1.8489e-02,  5.7678e-02,  5.2035e-02]],\n",
      "\n",
      "          [[ 3.3875e-02,  4.2701e-02, -5.1139e-02],\n",
      "           [-3.0911e-03, -1.9072e-02, -1.0882e-03],\n",
      "           [-9.9636e-03,  9.6526e-04,  6.2591e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.5850e-02, -1.5663e-02,  3.6376e-02],\n",
      "           [-1.7780e-02,  7.6119e-03,  5.5035e-02],\n",
      "           [-7.3001e-02, -6.9614e-02, -2.8226e-03]],\n",
      "\n",
      "          [[-3.5851e-02,  3.0251e-02, -2.0089e-03],\n",
      "           [-1.8076e-02,  9.0989e-03,  2.9929e-02],\n",
      "           [ 9.6759e-03,  9.3092e-02,  3.7944e-02]],\n",
      "\n",
      "          [[-8.7156e-02, -6.4306e-02, -4.7763e-03],\n",
      "           [ 3.6136e-02,  4.2284e-02,  4.7934e-02],\n",
      "           [ 1.9780e-02, -3.9863e-02, -3.6009e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.3442e-03, -4.4712e-02, -4.2109e-02],\n",
      "           [-4.8586e-03, -5.5246e-03,  1.7206e-03],\n",
      "           [-1.7576e-02,  4.1900e-02,  8.4382e-02]],\n",
      "\n",
      "          [[ 8.1015e-03,  6.8298e-02,  2.2974e-02],\n",
      "           [ 8.6295e-04, -1.7489e-02,  5.4909e-02],\n",
      "           [-1.3049e-02, -3.9957e-02, -2.2584e-02]],\n",
      "\n",
      "          [[ 6.3868e-02, -2.6375e-02, -3.0317e-02],\n",
      "           [ 7.2693e-03, -4.5976e-02,  7.0981e-02],\n",
      "           [ 1.7499e-02,  1.0845e-02,  3.4996e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7598e-02,  9.9450e-03, -8.4331e-02],\n",
      "           [ 9.2142e-02,  5.3097e-02, -1.9430e-02],\n",
      "           [-8.8173e-02, -7.6944e-02, -4.8052e-02]],\n",
      "\n",
      "          [[-2.8518e-02, -2.3042e-02, -3.6872e-02],\n",
      "           [ 7.4480e-02, -4.2624e-02,  2.3623e-02],\n",
      "           [-7.1080e-02, -2.7106e-02,  6.3573e-02]],\n",
      "\n",
      "          [[ 1.6148e-02, -5.2353e-02, -5.1376e-02],\n",
      "           [ 5.2997e-02,  6.1240e-02,  6.9051e-02],\n",
      "           [ 3.1184e-02, -1.0095e-01,  2.2186e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.6717e-02,  6.1318e-04,  2.6817e-02],\n",
      "           [-1.9976e-02, -2.8132e-03,  3.7159e-02],\n",
      "           [-3.4221e-02,  3.3395e-02, -8.4126e-02]],\n",
      "\n",
      "          [[-2.3884e-02, -9.8652e-02,  1.1739e-02],\n",
      "           [-1.6608e-02, -7.2516e-04,  5.6593e-02],\n",
      "           [-1.5599e-02, -8.8906e-02,  2.9133e-02]],\n",
      "\n",
      "          [[-3.8316e-02, -5.4831e-03,  3.5379e-02],\n",
      "           [-2.7222e-02,  1.1847e-01, -9.3676e-03],\n",
      "           [-4.7774e-02, -6.6920e-02, -6.1490e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.9879e-02, -1.5380e-02,  1.2775e-02],\n",
      "           [ 2.4000e-03,  7.1605e-03, -1.2566e-02],\n",
      "           [-1.9170e-02,  7.8875e-02, -7.2312e-02]],\n",
      "\n",
      "          [[ 4.3364e-04, -4.3289e-02, -2.0011e-02],\n",
      "           [ 6.7264e-02,  6.9482e-02,  7.5616e-02],\n",
      "           [-2.0213e-02, -4.6460e-02, -4.3715e-02]],\n",
      "\n",
      "          [[-1.2669e-02, -7.3335e-04,  7.7555e-02],\n",
      "           [ 4.4127e-02, -3.4169e-02, -9.6755e-02],\n",
      "           [ 9.8905e-03, -4.3172e-02,  1.8371e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.2529e-02,  6.0908e-02,  2.8032e-02],\n",
      "           [-1.6664e-02,  1.4425e-03, -1.5228e-01],\n",
      "           [ 1.7988e-03, -8.4233e-02,  2.9070e-03]],\n",
      "\n",
      "          [[ 8.7842e-02, -3.4228e-02,  3.4881e-02],\n",
      "           [-9.7064e-02,  6.4468e-02, -3.3291e-03],\n",
      "           [ 2.6575e-02,  3.7022e-02, -6.9211e-02]],\n",
      "\n",
      "          [[-3.9709e-02, -8.2960e-03, -5.2119e-02],\n",
      "           [-7.0896e-02,  5.0489e-02,  6.0531e-02],\n",
      "           [-9.5679e-02,  3.4551e-02, -5.8534e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.2168e-02, -6.6996e-02, -8.9584e-02],\n",
      "           [ 4.0996e-02,  2.1718e-02,  6.0033e-02],\n",
      "           [ 3.5232e-02, -9.2097e-02,  1.2227e-02]],\n",
      "\n",
      "          [[-2.5571e-02, -1.0724e-02, -4.1129e-02],\n",
      "           [ 7.3126e-02, -1.1040e-01,  1.8114e-02],\n",
      "           [ 1.0265e-01,  1.9298e-02,  5.5245e-02]],\n",
      "\n",
      "          [[ 4.5681e-03, -6.3781e-02, -7.5578e-02],\n",
      "           [-3.7799e-03,  1.1549e-01, -5.7685e-02],\n",
      "           [ 1.5858e-03,  2.7877e-02, -1.9692e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.8924e-02,  5.2104e-02,  2.0017e-02],\n",
      "           [-3.2339e-02,  9.5816e-02,  7.7878e-02],\n",
      "           [-4.4661e-03,  4.2372e-02, -5.2091e-02]],\n",
      "\n",
      "          [[ 1.0546e-01, -2.1631e-02,  5.0703e-02],\n",
      "           [-7.2046e-02,  1.7196e-02,  2.8262e-02],\n",
      "           [-7.2118e-02,  7.6972e-03,  1.7993e-02]],\n",
      "\n",
      "          [[-7.3441e-03,  3.9209e-02,  3.3824e-02],\n",
      "           [-3.9897e-02,  8.8954e-03, -9.1482e-03],\n",
      "           [ 4.2830e-02, -4.4234e-02, -5.8787e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.9643e-02,  2.3518e-02, -1.8408e-02],\n",
      "           [-3.8283e-02, -3.4908e-02, -2.4129e-03],\n",
      "           [-1.5987e-02,  1.5578e-02, -2.1493e-02]],\n",
      "\n",
      "          [[-2.8540e-02,  1.8783e-02, -1.7483e-03],\n",
      "           [ 2.0990e-02,  9.8596e-02,  7.4825e-02],\n",
      "           [-3.9156e-02,  2.1186e-02, -2.2931e-02]],\n",
      "\n",
      "          [[-5.1231e-02, -8.4997e-02, -2.5576e-02],\n",
      "           [ 2.1186e-02, -6.0371e-02, -2.6253e-02],\n",
      "           [-1.1147e-02, -8.9277e-03,  1.2522e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.7238e-02,  5.1731e-02,  8.4436e-02],\n",
      "           [ 2.0574e-02,  2.7650e-02, -7.6917e-03],\n",
      "           [ 8.9629e-02,  5.2516e-02, -1.5948e-02]],\n",
      "\n",
      "          [[ 5.9528e-02,  1.4493e-02,  5.3408e-02],\n",
      "           [-7.7502e-03, -5.8756e-02,  2.0557e-03],\n",
      "           [ 3.1679e-02, -2.3629e-03, -6.7630e-02]],\n",
      "\n",
      "          [[-7.0936e-02,  6.6762e-02,  9.7521e-02],\n",
      "           [-4.6476e-02,  1.2002e-02,  1.0819e-03],\n",
      "           [ 5.5617e-02,  9.7754e-02, -1.3907e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.2865e-03,  7.8825e-03, -2.1655e-02],\n",
      "           [ 6.3027e-02, -7.5564e-02, -9.7279e-02],\n",
      "           [-4.7962e-02,  2.3793e-02, -3.6194e-02]],\n",
      "\n",
      "          [[ 3.0531e-03, -5.9518e-02,  3.5527e-02],\n",
      "           [ 4.0093e-02, -2.6436e-02, -5.5298e-02],\n",
      "           [ 1.3078e-02,  5.2509e-02, -3.5849e-02]],\n",
      "\n",
      "          [[-8.8309e-03, -2.1914e-02, -3.8477e-02],\n",
      "           [-5.3052e-02, -3.2508e-02, -3.4920e-02],\n",
      "           [ 5.8626e-03,  3.4240e-02,  1.0608e-01]]],\n",
      "\n",
      "\n",
      "         [[[-6.6590e-02,  1.1676e-01, -6.2863e-02],\n",
      "           [ 8.8227e-03,  4.4197e-02, -3.9182e-02],\n",
      "           [ 7.2580e-02,  2.0892e-02,  5.1699e-02]],\n",
      "\n",
      "          [[ 8.3917e-04,  4.5700e-02, -6.2195e-03],\n",
      "           [-5.0576e-04,  6.8892e-02, -3.3000e-02],\n",
      "           [-4.9146e-02, -5.2398e-02,  4.1959e-02]],\n",
      "\n",
      "          [[-6.3383e-02, -2.0681e-02, -1.6236e-02],\n",
      "           [ 3.8644e-02, -5.9509e-02, -5.3445e-03],\n",
      "           [-6.1556e-02,  3.4856e-02, -1.6451e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.7837e-02, -1.0920e-02,  4.6583e-02],\n",
      "           [-6.1399e-02,  6.2003e-02,  4.7013e-02],\n",
      "           [-2.7499e-02,  1.5208e-01, -6.8569e-02]],\n",
      "\n",
      "          [[ 1.1624e-02,  2.9764e-02, -4.0320e-02],\n",
      "           [ 2.1822e-02, -1.0226e-01,  1.4367e-02],\n",
      "           [-9.9319e-03, -1.2689e-02,  1.8974e-02]],\n",
      "\n",
      "          [[-6.2198e-02,  1.6543e-01,  6.7200e-02],\n",
      "           [ 3.1326e-02,  5.5245e-02, -1.0586e-01],\n",
      "           [-1.5895e-02, -2.3098e-02, -3.3164e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 8.2882e-03, -6.9951e-02,  2.9155e-02],\n",
      "           [-1.5128e-01, -8.0378e-02, -2.7975e-02],\n",
      "           [-4.8599e-02, -4.9589e-02, -1.3677e-02]],\n",
      "\n",
      "          [[ 4.2330e-02,  4.6056e-02, -6.4346e-02],\n",
      "           [ 5.0244e-03,  2.6184e-04,  1.5073e-02],\n",
      "           [ 1.0123e-02, -6.4680e-02,  8.9890e-03]],\n",
      "\n",
      "          [[-2.6911e-02, -5.0653e-02, -9.9809e-02],\n",
      "           [ 2.7028e-02,  1.0429e-01,  5.5920e-02],\n",
      "           [-2.8116e-02,  7.7598e-02,  5.7369e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.7404e-02,  9.9481e-03,  1.6627e-02],\n",
      "           [ 5.0159e-03, -2.3173e-02, -4.1823e-03],\n",
      "           [ 9.8344e-03, -6.4786e-02,  1.3816e-02]],\n",
      "\n",
      "          [[ 2.4101e-02, -3.9026e-02, -4.3779e-03],\n",
      "           [ 5.0616e-02, -2.8723e-02,  9.5928e-03],\n",
      "           [-1.1782e-02, -5.7468e-02, -2.8664e-02]],\n",
      "\n",
      "          [[-3.6893e-02,  1.0113e-01, -2.0491e-03],\n",
      "           [ 4.0331e-02,  2.3747e-02,  8.2638e-03],\n",
      "           [ 4.6510e-03,  1.4010e-02, -5.6805e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.1032e-02,  2.3389e-03, -2.1539e-02],\n",
      "           [ 3.8666e-02,  2.5818e-02, -1.7171e-02],\n",
      "           [ 5.3520e-02,  5.9079e-02, -1.3946e-02]],\n",
      "\n",
      "          [[ 1.5775e-03,  6.7543e-02, -9.6815e-03],\n",
      "           [ 5.0667e-02,  4.8246e-02,  1.5310e-02],\n",
      "           [-3.9397e-02, -6.7671e-02,  2.8759e-02]],\n",
      "\n",
      "          [[-8.7366e-03,  1.9251e-02, -8.7413e-02],\n",
      "           [-2.8293e-02,  1.3475e-02, -9.8690e-02],\n",
      "           [ 8.3820e-02, -8.9857e-02, -9.8816e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.0970e-02, -9.0889e-03,  2.5602e-02],\n",
      "           [-2.5282e-02, -6.2466e-03, -2.7312e-02],\n",
      "           [ 1.6099e-04,  5.7671e-02,  3.7760e-03]],\n",
      "\n",
      "          [[ 5.2440e-02, -8.0073e-02, -3.7252e-02],\n",
      "           [-8.5864e-02, -5.6980e-02,  2.2441e-02],\n",
      "           [-2.8369e-02,  5.6251e-02,  1.4712e-02]],\n",
      "\n",
      "          [[ 3.2819e-02,  6.0646e-03, -8.0922e-02],\n",
      "           [-2.7472e-02,  5.9008e-02, -5.5072e-02],\n",
      "           [ 4.9628e-02,  5.5350e-04, -4.0641e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.8910e-02,  1.4965e-02,  1.3142e-02],\n",
      "           [-1.1224e-02,  2.1836e-02, -1.4434e-02],\n",
      "           [ 4.5714e-02,  1.6048e-02, -2.6738e-02]],\n",
      "\n",
      "          [[-3.9262e-02, -2.9343e-02,  1.7474e-02],\n",
      "           [ 1.5319e-02,  1.1494e-01, -7.0278e-03],\n",
      "           [-2.0271e-02,  5.1448e-02,  3.5525e-04]],\n",
      "\n",
      "          [[-7.7924e-02, -9.1523e-02, -2.7383e-02],\n",
      "           [-3.8462e-02, -6.9318e-02,  5.7582e-03],\n",
      "           [-6.6699e-02, -1.9145e-02, -2.0514e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.4961e-02, -2.5238e-02,  2.9002e-02],\n",
      "           [-4.1247e-02, -3.5146e-02,  6.4447e-03],\n",
      "           [-4.6141e-02,  2.8511e-02,  4.0141e-02]],\n",
      "\n",
      "          [[-3.5573e-02, -4.4788e-02,  2.5839e-02],\n",
      "           [ 1.7517e-02,  1.0926e-01,  5.9387e-02],\n",
      "           [ 3.3019e-02, -3.5152e-02,  8.4674e-02]],\n",
      "\n",
      "          [[ 4.0708e-03,  5.4557e-02,  4.4481e-02],\n",
      "           [ 1.2288e-03,  7.0924e-02,  4.6960e-02],\n",
      "           [-1.2149e-01,  5.6675e-03,  3.3833e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-4.9763e-02,  3.9468e-02, -1.1843e-02],\n",
      "           [ 1.4242e-02, -6.7749e-02, -1.0540e-01],\n",
      "           [ 2.2649e-02, -1.9536e-02,  4.2822e-02]],\n",
      "\n",
      "          [[-1.8228e-02,  5.4001e-03,  2.1525e-02],\n",
      "           [ 6.7656e-02, -9.9454e-03, -3.1130e-02],\n",
      "           [-9.7965e-04, -4.8138e-02,  5.7455e-02]],\n",
      "\n",
      "          [[-2.6709e-02,  1.4320e-02, -6.2363e-02],\n",
      "           [ 1.9523e-02, -2.9578e-02,  2.3138e-02],\n",
      "           [-4.6717e-02,  7.7316e-03,  1.4825e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.5232e-02, -3.5603e-02,  1.6310e-02],\n",
      "           [ 7.8234e-04, -5.4795e-02, -7.1169e-02],\n",
      "           [ 4.0472e-02, -4.6686e-02, -1.5352e-02]],\n",
      "\n",
      "          [[ 4.2372e-02,  9.2162e-02, -5.9544e-02],\n",
      "           [-3.1278e-02, -2.8164e-02, -2.4618e-02],\n",
      "           [-1.9015e-02, -4.0494e-03,  1.7137e-02]],\n",
      "\n",
      "          [[-6.9457e-02, -7.3342e-02,  5.0318e-02],\n",
      "           [ 2.0195e-02,  1.8768e-02, -2.3657e-02],\n",
      "           [-4.6121e-02, -5.8373e-02, -2.7559e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.7274e-02,  1.7214e-02, -9.1549e-02],\n",
      "           [ 5.0713e-02,  1.0217e-01, -2.0563e-03],\n",
      "           [ 9.5020e-02, -3.9837e-02, -4.4120e-02]],\n",
      "\n",
      "          [[-1.6438e-03,  4.8625e-02,  2.0983e-02],\n",
      "           [ 2.2308e-02,  5.7718e-02, -9.3186e-02],\n",
      "           [-1.8677e-02, -4.9077e-02, -1.9279e-02]],\n",
      "\n",
      "          [[-9.5980e-02,  2.1094e-02, -1.0816e-02],\n",
      "           [ 6.0070e-02,  4.4499e-02,  3.2907e-02],\n",
      "           [ 2.7462e-02, -3.3177e-02,  1.6898e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.8119e-02,  7.4398e-03, -2.9181e-02],\n",
      "           [ 3.8943e-02,  4.5101e-02,  2.6783e-02],\n",
      "           [-1.1097e-02, -4.3217e-02, -6.2306e-02]],\n",
      "\n",
      "          [[-1.6919e-02,  1.9596e-02, -2.8357e-02],\n",
      "           [-1.7567e-02, -3.6124e-02, -5.6439e-02],\n",
      "           [-3.6473e-02, -2.0879e-02, -2.7899e-02]],\n",
      "\n",
      "          [[ 5.0173e-02, -2.4357e-02, -2.8119e-02],\n",
      "           [-1.3607e-02,  4.0728e-02, -1.4069e-02],\n",
      "           [-3.5404e-02, -8.8042e-03,  8.8073e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.8684e-03,  1.0553e-02, -8.7192e-03],\n",
      "           [-5.9121e-02, -7.2268e-02,  4.3016e-04],\n",
      "           [-6.0107e-03,  7.6486e-03, -1.4403e-02]],\n",
      "\n",
      "          [[ 2.3768e-04, -1.1103e-02,  2.7431e-02],\n",
      "           [ 3.3184e-02,  1.1028e-02,  7.3887e-02],\n",
      "           [ 1.1674e-02,  1.4568e-02,  3.3370e-02]],\n",
      "\n",
      "          [[ 3.2694e-02,  5.8463e-02,  4.5955e-02],\n",
      "           [ 1.1427e-03,  5.7246e-02, -3.2172e-02],\n",
      "           [ 3.6534e-02, -5.3829e-02,  8.4121e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 5.1056e-03, -7.4035e-03,  2.2420e-02],\n",
      "           [-1.7379e-02,  4.9841e-02,  3.1987e-02],\n",
      "           [-4.9134e-02, -4.5984e-02, -9.3494e-02]],\n",
      "\n",
      "          [[-2.0206e-02,  1.8034e-02, -3.0845e-02],\n",
      "           [ 1.3939e-02, -2.2814e-02,  4.1933e-02],\n",
      "           [-4.1468e-02, -2.0173e-03,  4.3864e-02]],\n",
      "\n",
      "          [[ 7.3926e-02, -4.1699e-03, -9.4190e-02],\n",
      "           [ 2.5107e-02, -8.2211e-02, -3.0748e-02],\n",
      "           [-3.8453e-02, -1.5981e-02, -8.7041e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0163e-02,  1.8468e-02, -8.4624e-02],\n",
      "           [-4.7517e-02, -2.1765e-02,  4.2940e-02],\n",
      "           [ 5.4060e-04, -2.7520e-02, -7.5235e-02]],\n",
      "\n",
      "          [[ 4.4833e-02, -1.0262e-03, -7.5515e-02],\n",
      "           [-4.8664e-03, -1.9848e-02,  4.6392e-02],\n",
      "           [-1.0552e-02, -1.1814e-02, -1.4855e-02]],\n",
      "\n",
      "          [[-7.1715e-02, -1.3834e-02, -5.8124e-02],\n",
      "           [ 6.8085e-02,  4.0202e-02, -1.5914e-02],\n",
      "           [ 8.2776e-02, -1.2883e-02,  7.5094e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.0146e-02, -7.2847e-02,  7.9900e-02],\n",
      "           [ 5.2727e-02,  6.0110e-02, -9.7537e-02],\n",
      "           [ 2.9664e-02,  3.8502e-02,  3.0876e-02]],\n",
      "\n",
      "          [[ 1.0790e-02, -1.0065e-01, -7.7581e-02],\n",
      "           [ 1.6232e-02, -1.2118e-02,  1.1121e-02],\n",
      "           [ 3.7298e-02,  1.4967e-04, -1.8393e-02]],\n",
      "\n",
      "          [[ 1.0008e-01, -1.8342e-02, -4.5871e-02],\n",
      "           [-4.7116e-03, -2.0570e-02, -1.3716e-02],\n",
      "           [-2.5938e-02, -5.0428e-03, -8.5684e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.4208e-02, -2.8109e-02, -5.1510e-02],\n",
      "           [ 4.0915e-02,  3.3678e-03,  1.8162e-02],\n",
      "           [ 2.1774e-03,  1.6066e-02,  6.9009e-02]],\n",
      "\n",
      "          [[ 1.2839e-02, -7.1426e-02,  3.8490e-02],\n",
      "           [ 1.9537e-02,  1.1984e-01, -3.3697e-02],\n",
      "           [ 7.9038e-02, -8.9931e-02, -3.7397e-02]],\n",
      "\n",
      "          [[-1.4987e-02,  6.9667e-02, -1.2394e-01],\n",
      "           [ 5.6693e-02,  7.6597e-02,  4.8597e-03],\n",
      "           [ 4.2109e-02, -1.2831e-01,  8.6646e-02]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[ 0.1235]]],\n",
      "\n",
      "\n",
      "         [[[-0.1122]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0035]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3034]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2547]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0062]]],\n",
      "\n",
      "\n",
      "         [[[-0.2079]]],\n",
      "\n",
      "\n",
      "         [[[-0.0313]]],\n",
      "\n",
      "\n",
      "         [[[ 0.7984]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0832]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1956]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0026]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4438]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3151]]],\n",
      "\n",
      "\n",
      "         [[[-0.2709]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4603]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.2127]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0224]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4729]]],\n",
      "\n",
      "\n",
      "         [[[-0.3527]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2214]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2510]]],\n",
      "\n",
      "\n",
      "         [[[-0.0175]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2804]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2220]]],\n",
      "\n",
      "\n",
      "         [[[-0.2902]]],\n",
      "\n",
      "\n",
      "         [[[-0.1619]]],\n",
      "\n",
      "\n",
      "         [[[-0.0783]]],\n",
      "\n",
      "\n",
      "         [[[-0.0390]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1384]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1378]]],\n",
      "\n",
      "\n",
      "         [[[-0.2149]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.1744]]],\n",
      "\n",
      "\n",
      "         [[[-0.0151]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0689]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0245]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1866]]],\n",
      "\n",
      "\n",
      "         [[[-0.3616]]],\n",
      "\n",
      "\n",
      "         [[[-0.2577]]],\n",
      "\n",
      "\n",
      "         [[[-0.0649]]],\n",
      "\n",
      "\n",
      "         [[[-0.4137]]],\n",
      "\n",
      "\n",
      "         [[[-0.1201]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0099]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2478]]],\n",
      "\n",
      "\n",
      "         [[[-0.5223]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1162]]],\n",
      "\n",
      "\n",
      "         [[[-0.2155]]],\n",
      "\n",
      "\n",
      "         [[[-0.1636]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.2248]]],\n",
      "\n",
      "\n",
      "         [[[-0.6343]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1877]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3449]]],\n",
      "\n",
      "\n",
      "         [[[-0.5306]]],\n",
      "\n",
      "\n",
      "         [[[-0.4820]]],\n",
      "\n",
      "\n",
      "         [[[-0.1129]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0731]]],\n",
      "\n",
      "\n",
      "         [[[-0.1449]]],\n",
      "\n",
      "\n",
      "         [[[-0.0775]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1769]]],\n",
      "\n",
      "\n",
      "         [[[-0.0291]]],\n",
      "\n",
      "\n",
      "         [[[-0.2023]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4441]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3941]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1493]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.2006]]],\n",
      "\n",
      "\n",
      "         [[[-0.0513]]],\n",
      "\n",
      "\n",
      "         [[[-0.2573]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0190]]],\n",
      "\n",
      "\n",
      "         [[[-0.5238]]],\n",
      "\n",
      "\n",
      "         [[[-0.0750]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0876]]],\n",
      "\n",
      "\n",
      "         [[[-0.3126]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1199]]],\n",
      "\n",
      "\n",
      "         [[[-0.2363]]],\n",
      "\n",
      "\n",
      "         [[[-0.0288]]],\n",
      "\n",
      "\n",
      "         [[[-0.3815]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0611]]],\n",
      "\n",
      "\n",
      "         [[[-0.1062]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2358]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0238]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.1236]]],\n",
      "\n",
      "\n",
      "         [[[-0.0469]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2177]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0986]]],\n",
      "\n",
      "\n",
      "         [[[-0.1852]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4776]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1447]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0110]]],\n",
      "\n",
      "\n",
      "         [[[-0.2388]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0615]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4999]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2144]]],\n",
      "\n",
      "\n",
      "         [[[-0.3739]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1959]]],\n",
      "\n",
      "\n",
      "         [[[-0.3397]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4739]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0730]]],\n",
      "\n",
      "\n",
      "         [[[-0.1334]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2026]]],\n",
      "\n",
      "\n",
      "         [[[-0.0734]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5766]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0227]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1883]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1199]]],\n",
      "\n",
      "\n",
      "         [[[-0.1816]]],\n",
      "\n",
      "\n",
      "         [[[-0.0562]]],\n",
      "\n",
      "\n",
      "         [[[-0.2114]]],\n",
      "\n",
      "\n",
      "         [[[-0.1900]]],\n",
      "\n",
      "\n",
      "         [[[-0.2174]]],\n",
      "\n",
      "\n",
      "         [[[-0.1018]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2436]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5404]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0714]]],\n",
      "\n",
      "\n",
      "         [[[-0.0589]]],\n",
      "\n",
      "\n",
      "         [[[-0.0391]]],\n",
      "\n",
      "\n",
      "         [[[-0.1628]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2308]]],\n",
      "\n",
      "\n",
      "         [[[-0.3971]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0326]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2125]]],\n",
      "\n",
      "\n",
      "         [[[-0.0185]]],\n",
      "\n",
      "\n",
      "         [[[-0.1542]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2917]]],\n",
      "\n",
      "\n",
      "         [[[-0.6043]]],\n",
      "\n",
      "\n",
      "         [[[-0.0075]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3376]]],\n",
      "\n",
      "\n",
      "         [[[-0.0421]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0616]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.5774]]],\n",
      "\n",
      "\n",
      "         [[[-0.4320]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1572]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0044]]],\n",
      "\n",
      "\n",
      "         [[[-0.0407]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0702]]],\n",
      "\n",
      "\n",
      "         [[[-0.1630]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2136]]],\n",
      "\n",
      "\n",
      "         [[[-0.1542]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0610]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1522]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4424]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0753]]],\n",
      "\n",
      "\n",
      "         [[[-0.0174]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0216]]],\n",
      "\n",
      "\n",
      "         [[[-0.2296]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0086]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2293]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0338]]],\n",
      "\n",
      "\n",
      "         [[[-0.1966]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2571]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2588]]],\n",
      "\n",
      "\n",
      "         [[[-0.2913]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1294]]],\n",
      "\n",
      "\n",
      "         [[[-0.0289]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0441]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2268]]],\n",
      "\n",
      "\n",
      "         [[[-0.3097]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0422]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4178]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1221]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3016]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.1096]]],\n",
      "\n",
      "\n",
      "         [[[-0.1702]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0765]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0297]]],\n",
      "\n",
      "\n",
      "         [[[-0.4340]]],\n",
      "\n",
      "\n",
      "         [[[-0.2243]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0808]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0548]]],\n",
      "\n",
      "\n",
      "         [[[-0.0356]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4246]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0942]]],\n",
      "\n",
      "\n",
      "         [[[-0.2366]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2385]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0971]]],\n",
      "\n",
      "\n",
      "         [[[-0.4387]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1087]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0455]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1665]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0339]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1006]]],\n",
      "\n",
      "\n",
      "         [[[-0.2427]]],\n",
      "\n",
      "\n",
      "         [[[-0.2890]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0359]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4043]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2738]]],\n",
      "\n",
      "\n",
      "         [[[-0.4422]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2481]]],\n",
      "\n",
      "\n",
      "         [[[-0.1152]]],\n",
      "\n",
      "\n",
      "         [[[-0.1150]]],\n",
      "\n",
      "\n",
      "         [[[-0.1122]]],\n",
      "\n",
      "\n",
      "         [[[-0.4264]]],\n",
      "\n",
      "\n",
      "         [[[-0.1478]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0078]]],\n",
      "\n",
      "\n",
      "         [[[-0.1874]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1667]]],\n",
      "\n",
      "\n",
      "         [[[-0.1455]]],\n",
      "\n",
      "\n",
      "         [[[-0.2409]]],\n",
      "\n",
      "\n",
      "         [[[-0.2781]]],\n",
      "\n",
      "\n",
      "         [[[-0.2107]]],\n",
      "\n",
      "\n",
      "         [[[-0.3099]]],\n",
      "\n",
      "\n",
      "         [[[-0.1886]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0068]]],\n",
      "\n",
      "\n",
      "         [[[-0.1961]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3837]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0825]]],\n",
      "\n",
      "\n",
      "         [[[-0.1177]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3059]]],\n",
      "\n",
      "\n",
      "         [[[-0.5614]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1452]]],\n",
      "\n",
      "\n",
      "         [[[-0.6589]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0262]]],\n",
      "\n",
      "\n",
      "         [[[-0.1948]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0976]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2229]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2467]]],\n",
      "\n",
      "\n",
      "         [[[-0.1168]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3674]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5016]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0302]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0420]]],\n",
      "\n",
      "\n",
      "         [[[-0.2114]]],\n",
      "\n",
      "\n",
      "         [[[-0.1561]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0192]]],\n",
      "\n",
      "\n",
      "         [[[-0.1190]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.1122]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3600]]],\n",
      "\n",
      "\n",
      "         [[[-0.3263]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0490]]],\n",
      "\n",
      "\n",
      "         [[[-0.3111]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0488]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1171]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1303]]],\n",
      "\n",
      "\n",
      "         [[[-0.0661]]],\n",
      "\n",
      "\n",
      "         [[[-0.2591]]],\n",
      "\n",
      "\n",
      "         [[[ 0.6831]]],\n",
      "\n",
      "\n",
      "         [[[-0.1358]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0402]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2083]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1076]]],\n",
      "\n",
      "\n",
      "         [[[-0.0980]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.7837]]],\n",
      "\n",
      "\n",
      "         [[[-0.0133]]],\n",
      "\n",
      "\n",
      "         [[[-0.0738]]],\n",
      "\n",
      "\n",
      "         [[[-0.1129]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1132]]],\n",
      "\n",
      "\n",
      "         [[[-0.4230]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0514]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0810]]],\n",
      "\n",
      "\n",
      "         [[[-0.3600]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2958]]],\n",
      "\n",
      "\n",
      "         [[[-0.0018]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0563]]],\n",
      "\n",
      "\n",
      "         [[[-0.1652]]],\n",
      "\n",
      "\n",
      "         [[[-0.3120]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1588]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1454]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0352]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0107]]],\n",
      "\n",
      "\n",
      "         [[[-0.1233]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1919]]],\n",
      "\n",
      "\n",
      "         [[[-0.3622]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1998]]],\n",
      "\n",
      "\n",
      "         [[[-0.0357]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1267]]],\n",
      "\n",
      "\n",
      "         [[[-0.1385]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0182]]],\n",
      "\n",
      "\n",
      "         [[[-0.1740]]],\n",
      "\n",
      "\n",
      "         [[[-0.1017]]],\n",
      "\n",
      "\n",
      "         [[[ 0.6009]]],\n",
      "\n",
      "\n",
      "         [[[-0.1605]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1008]]],\n",
      "\n",
      "\n",
      "         [[[-0.0352]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.2552]]],\n",
      "\n",
      "\n",
      "         [[[-0.2080]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2808]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1943]]],\n",
      "\n",
      "\n",
      "         [[[-0.2949]]],\n",
      "\n",
      "\n",
      "         [[[-0.1952]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3205]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4488]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1203]]],\n",
      "\n",
      "\n",
      "         [[[-0.2732]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0678]]],\n",
      "\n",
      "\n",
      "         [[[-0.1020]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3521]]],\n",
      "\n",
      "\n",
      "         [[[-0.0111]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0595]]],\n",
      "\n",
      "\n",
      "         [[[-0.0386]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.3775]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1847]]],\n",
      "\n",
      "\n",
      "         [[[-0.5345]]],\n",
      "\n",
      "\n",
      "         [[[-0.3013]]],\n",
      "\n",
      "\n",
      "         [[[-0.1342]]],\n",
      "\n",
      "\n",
      "         [[[-0.2103]]],\n",
      "\n",
      "\n",
      "         [[[-0.3174]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0588]]],\n",
      "\n",
      "\n",
      "         [[[-0.2099]]],\n",
      "\n",
      "\n",
      "         [[[-0.4759]]],\n",
      "\n",
      "\n",
      "         [[[-0.1808]]],\n",
      "\n",
      "\n",
      "         [[[-0.3012]]],\n",
      "\n",
      "\n",
      "         [[[-0.1016]]],\n",
      "\n",
      "\n",
      "         [[[-0.0413]]],\n",
      "\n",
      "\n",
      "         [[[-0.1127]]],\n",
      "\n",
      "\n",
      "         [[[-0.1098]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.4843]]],\n",
      "\n",
      "\n",
      "         [[[-0.0885]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2260]]],\n",
      "\n",
      "\n",
      "         [[[-0.1064]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4579]]],\n",
      "\n",
      "\n",
      "         [[[-0.2643]]],\n",
      "\n",
      "\n",
      "         [[[-0.4324]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1172]]],\n",
      "\n",
      "\n",
      "         [[[-0.2442]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1968]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0562]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3553]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2039]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0699]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2426]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2167]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1639]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1261]]],\n",
      "\n",
      "\n",
      "         [[[-0.1206]]],\n",
      "\n",
      "\n",
      "         [[[-0.3072]]],\n",
      "\n",
      "\n",
      "         [[[-0.0528]]],\n",
      "\n",
      "\n",
      "         [[[-0.0099]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2001]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4366]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0411]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2253]]],\n",
      "\n",
      "\n",
      "         [[[-0.0365]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5251]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3765]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3559]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1696]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0685]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0504]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0433]]],\n",
      "\n",
      "\n",
      "         [[[-0.3116]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4767]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1534]]],\n",
      "\n",
      "\n",
      "         [[[-0.1392]]],\n",
      "\n",
      "\n",
      "         [[[-0.2568]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0689]]],\n",
      "\n",
      "\n",
      "         [[[-0.0023]]],\n",
      "\n",
      "\n",
      "         [[[-0.0491]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1561]]],\n",
      "\n",
      "\n",
      "         [[[-0.1900]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4168]]],\n",
      "\n",
      "\n",
      "         [[[-0.2701]]],\n",
      "\n",
      "\n",
      "         [[[-0.1427]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1095]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1281]]],\n",
      "\n",
      "\n",
      "         [[[-0.1425]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0417]]],\n",
      "\n",
      "\n",
      "         [[[-0.2025]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5995]]],\n",
      "\n",
      "\n",
      "         [[[-0.3157]]],\n",
      "\n",
      "\n",
      "         [[[-0.3252]]],\n",
      "\n",
      "\n",
      "         [[[-0.2227]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2550]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2904]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1725]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0933]]],\n",
      "\n",
      "\n",
      "         [[[-0.1772]]],\n",
      "\n",
      "\n",
      "         [[[-0.2279]]],\n",
      "\n",
      "\n",
      "         [[[-0.0713]]],\n",
      "\n",
      "\n",
      "         [[[-0.4812]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0077]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3341]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0373]]],\n",
      "\n",
      "\n",
      "         [[[-0.3816]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2192]]],\n",
      "\n",
      "\n",
      "         [[[-0.2062]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4354]]],\n",
      "\n",
      "\n",
      "         [[[-0.4166]]],\n",
      "\n",
      "\n",
      "         [[[-0.0017]]],\n",
      "\n",
      "\n",
      "         [[[-0.3376]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3663]]],\n",
      "\n",
      "\n",
      "         [[[-0.0849]]],\n",
      "\n",
      "\n",
      "         [[[-0.2973]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0368]]],\n",
      "\n",
      "\n",
      "         [[[-0.3284]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3142]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.2878]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2372]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3101]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2829]]],\n",
      "\n",
      "\n",
      "         [[[-0.1088]]],\n",
      "\n",
      "\n",
      "         [[[-0.3130]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2167]]],\n",
      "\n",
      "\n",
      "         [[[-0.3129]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5257]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1290]]],\n",
      "\n",
      "\n",
      "         [[[-0.1188]]],\n",
      "\n",
      "\n",
      "         [[[-0.1169]]],\n",
      "\n",
      "\n",
      "         [[[-0.3312]]],\n",
      "\n",
      "\n",
      "         [[[-0.2529]]],\n",
      "\n",
      "\n",
      "         [[[-0.0035]]],\n",
      "\n",
      "\n",
      "         [[[-0.2135]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1743]]],\n",
      "\n",
      "\n",
      "         [[[-0.3996]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3063]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1376]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1418]]],\n",
      "\n",
      "\n",
      "         [[[-0.0649]]],\n",
      "\n",
      "\n",
      "         [[[ 0.6314]]],\n",
      "\n",
      "\n",
      "         [[[-0.5294]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1937]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0345]]],\n",
      "\n",
      "\n",
      "         [[[-0.5354]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1082]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0833]]],\n",
      "\n",
      "\n",
      "         [[[-0.3492]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1643]]],\n",
      "\n",
      "\n",
      "         [[[-0.2131]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0582]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2713]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1171]]],\n",
      "\n",
      "\n",
      "         [[[-0.4100]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3708]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1879]]],\n",
      "\n",
      "\n",
      "         [[[-0.0509]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2128]]],\n",
      "\n",
      "\n",
      "         [[[-0.1751]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0496]]],\n",
      "\n",
      "\n",
      "         [[[-0.2814]]],\n",
      "\n",
      "\n",
      "         [[[-0.2826]]],\n",
      "\n",
      "\n",
      "         [[[-0.1268]]],\n",
      "\n",
      "\n",
      "         [[[-0.3308]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1778]]],\n",
      "\n",
      "\n",
      "         [[[-0.1943]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0174]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3204]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0143]]],\n",
      "\n",
      "\n",
      "         [[[-0.0446]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2524]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1417]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0370]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1206]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4655]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1398]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2143]]],\n",
      "\n",
      "\n",
      "         [[[-0.4181]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1091]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0610]]],\n",
      "\n",
      "\n",
      "         [[[-0.2027]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0948]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.5554]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4729]]],\n",
      "\n",
      "\n",
      "         [[[-0.3754]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1854]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1326]]],\n",
      "\n",
      "\n",
      "         [[[-0.3927]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2273]]],\n",
      "\n",
      "\n",
      "         [[[-0.4040]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2213]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3406]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1566]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4282]]],\n",
      "\n",
      "\n",
      "         [[[-0.0268]]],\n",
      "\n",
      "\n",
      "         [[[-0.3499]]],\n",
      "\n",
      "\n",
      "         [[[-0.0181]]],\n",
      "\n",
      "\n",
      "         [[[-0.0141]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.3200]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0387]]],\n",
      "\n",
      "\n",
      "         [[[-0.0998]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1999]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1072]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1473]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5013]]],\n",
      "\n",
      "\n",
      "         [[[-0.2575]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2568]]],\n",
      "\n",
      "\n",
      "         [[[-0.0911]]],\n",
      "\n",
      "\n",
      "         [[[-0.1653]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0380]]],\n",
      "\n",
      "\n",
      "         [[[-0.0720]]],\n",
      "\n",
      "\n",
      "         [[[-0.0436]]],\n",
      "\n",
      "\n",
      "         [[[-0.0870]]],\n",
      "\n",
      "\n",
      "         [[[-0.0089]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1868]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4225]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2506]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2233]]],\n",
      "\n",
      "\n",
      "         [[[-0.3821]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0050]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2723]]],\n",
      "\n",
      "\n",
      "         [[[-0.2609]]],\n",
      "\n",
      "\n",
      "         [[[-0.1963]]],\n",
      "\n",
      "\n",
      "         [[[-0.2755]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2934]]],\n",
      "\n",
      "\n",
      "         [[[-0.2564]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5116]]],\n",
      "\n",
      "\n",
      "         [[[-0.1466]]],\n",
      "\n",
      "\n",
      "         [[[-0.0334]]],\n",
      "\n",
      "\n",
      "         [[[-0.1744]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.2145]]],\n",
      "\n",
      "\n",
      "         [[[-0.0675]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0276]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0415]]],\n",
      "\n",
      "\n",
      "         [[[-0.2299]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5851]]],\n",
      "\n",
      "\n",
      "         [[[-0.0902]]],\n",
      "\n",
      "\n",
      "         [[[-0.0638]]],\n",
      "\n",
      "\n",
      "         [[[-0.3208]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0735]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0956]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3641]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0625]]],\n",
      "\n",
      "\n",
      "         [[[-0.2758]]],\n",
      "\n",
      "\n",
      "         [[[-0.2615]]],\n",
      "\n",
      "\n",
      "         [[[-0.2349]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1925, -0.0881,  0.2406, -0.2120, -0.0860,  0.0627, -0.1703, -0.0183,\n",
      "         0.1831, -0.2112,  0.1725, -0.2255,  0.1833, -0.1767, -0.0085, -0.0739,\n",
      "         0.0896, -0.0758, -0.1042, -0.0726,  0.2393,  0.0690,  0.0603,  0.1023,\n",
      "        -0.0139, -0.1104, -0.2201,  0.1171,  0.0498,  0.0049, -0.1505, -0.0567],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[ 2.1118e-02,  1.4679e-03, -7.1606e-03],\n",
      "           [ 4.9850e-02,  6.8870e-04,  4.8192e-02],\n",
      "           [-4.1176e-02,  2.5666e-02,  2.4502e-02]],\n",
      "\n",
      "          [[ 2.6788e-02, -5.3438e-03, -1.0374e-02],\n",
      "           [ 5.1153e-02, -2.0724e-02, -6.1703e-02],\n",
      "           [ 3.1540e-02, -1.7789e-03,  3.8583e-02]],\n",
      "\n",
      "          [[ 4.6470e-03, -3.3258e-02,  9.8729e-03],\n",
      "           [-2.7809e-02,  1.3552e-02,  4.6241e-02],\n",
      "           [ 8.0144e-03, -2.4421e-02,  2.5701e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.0765e-03,  8.5778e-03,  5.0373e-02],\n",
      "           [ 3.0413e-02, -2.4683e-02, -9.1630e-03],\n",
      "           [ 2.1758e-02,  1.2399e-02, -2.3312e-02]],\n",
      "\n",
      "          [[-2.6944e-02,  1.6120e-03, -6.1364e-02],\n",
      "           [ 4.7660e-02, -5.8464e-03,  3.4695e-02],\n",
      "           [ 4.1774e-03,  3.7717e-02, -7.3502e-03]],\n",
      "\n",
      "          [[ 4.2475e-02,  2.0126e-02,  7.7574e-03],\n",
      "           [-1.7769e-02, -6.2213e-03,  5.7277e-02],\n",
      "           [-6.3863e-03, -2.1686e-02, -3.4199e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.4499e-02,  4.5498e-02,  2.0847e-02],\n",
      "           [ 3.5683e-02, -6.6513e-03,  4.9520e-03],\n",
      "           [ 1.5928e-02,  1.9144e-02,  1.7054e-03]],\n",
      "\n",
      "          [[-2.7892e-02,  3.7256e-02, -1.7300e-02],\n",
      "           [-1.8393e-02,  5.7697e-02, -5.2306e-02],\n",
      "           [ 2.1381e-02,  4.9776e-02, -2.2267e-02]],\n",
      "\n",
      "          [[ 2.7492e-02, -6.7338e-03, -5.8204e-02],\n",
      "           [-3.8025e-02,  3.7383e-03,  2.6107e-02],\n",
      "           [-1.0258e-02,  9.0175e-03,  1.8839e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.3835e-03,  1.8982e-02,  4.1201e-02],\n",
      "           [ 2.4917e-02, -2.3913e-02,  1.2813e-03],\n",
      "           [ 4.0438e-02, -5.3354e-02,  9.9320e-03]],\n",
      "\n",
      "          [[-1.2754e-02,  5.6900e-02, -2.4639e-02],\n",
      "           [ 2.8349e-03, -1.2322e-02,  4.6741e-03],\n",
      "           [ 4.4539e-02, -2.1356e-02,  2.5188e-02]],\n",
      "\n",
      "          [[ 1.7655e-02,  2.2781e-02,  2.2714e-02],\n",
      "           [-4.8814e-02,  2.5844e-02,  3.3634e-02],\n",
      "           [-3.2710e-02, -3.5054e-02,  2.6166e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.5367e-02,  3.7649e-03, -7.2982e-03],\n",
      "           [ 2.5974e-02,  2.9219e-02, -8.7219e-03],\n",
      "           [-2.0616e-02,  5.6614e-02,  6.5495e-02]],\n",
      "\n",
      "          [[-1.7351e-02,  6.1144e-03,  4.1742e-02],\n",
      "           [ 5.1359e-03, -1.9868e-02,  1.0272e-02],\n",
      "           [ 1.2411e-03, -8.6443e-03,  3.6601e-02]],\n",
      "\n",
      "          [[ 2.8556e-02, -2.5285e-02, -2.6908e-03],\n",
      "           [-3.8982e-02,  4.4958e-03,  6.1552e-03],\n",
      "           [ 5.8168e-03,  2.7246e-02,  2.5267e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.1834e-02, -4.4536e-03, -2.2267e-02],\n",
      "           [ 2.1635e-02, -3.7842e-02, -2.3011e-02],\n",
      "           [ 6.6475e-02,  1.7608e-02, -6.2841e-02]],\n",
      "\n",
      "          [[-1.0786e-02,  7.5179e-03, -2.9033e-03],\n",
      "           [ 1.3607e-02,  2.5139e-03,  1.9646e-02],\n",
      "           [-1.9664e-02, -1.4090e-02, -3.4139e-04]],\n",
      "\n",
      "          [[-3.2305e-02,  1.2319e-02,  2.0095e-02],\n",
      "           [ 3.2555e-02, -1.7334e-02,  8.2504e-02],\n",
      "           [-1.3651e-02,  3.1679e-02, -7.3149e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.6337e-02, -4.3170e-03,  2.7875e-02],\n",
      "           [-5.3038e-02,  5.5486e-02, -5.7875e-02],\n",
      "           [ 8.4583e-03, -3.5648e-02, -3.9513e-02]],\n",
      "\n",
      "          [[-4.7787e-02,  7.6140e-03,  5.4140e-03],\n",
      "           [ 2.7655e-02,  2.2327e-02,  1.7244e-02],\n",
      "           [-1.3318e-03, -1.0017e-02,  5.4714e-02]],\n",
      "\n",
      "          [[-5.5817e-02, -1.8985e-02, -4.5251e-02],\n",
      "           [ 2.2302e-02, -6.9032e-02, -7.5850e-03],\n",
      "           [ 2.9494e-02, -2.4520e-02, -4.1746e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.6424e-02, -6.5762e-03,  3.3390e-02],\n",
      "           [ 1.9811e-03, -3.9656e-02, -3.9084e-02],\n",
      "           [ 3.6838e-02,  2.7830e-02,  1.3377e-02]],\n",
      "\n",
      "          [[ 6.5231e-02,  1.2212e-02, -1.0711e-02],\n",
      "           [-2.2491e-02,  1.8429e-02, -5.7308e-02],\n",
      "           [ 3.3106e-02, -2.1885e-02, -2.0762e-02]],\n",
      "\n",
      "          [[-2.1488e-02,  6.7568e-03,  1.6118e-02],\n",
      "           [ 7.5807e-03,  2.4430e-02,  1.0070e-02],\n",
      "           [ 1.7639e-02,  5.7444e-02, -3.4858e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 4.3596e-03,  4.6945e-02,  3.6475e-02],\n",
      "           [-4.4347e-02, -4.8492e-02,  4.2878e-02],\n",
      "           [ 3.3328e-02,  2.3338e-02,  2.4111e-02]],\n",
      "\n",
      "          [[ 7.4363e-02, -1.7895e-02,  4.3444e-02],\n",
      "           [ 1.0758e-02, -3.4921e-02,  1.8728e-02],\n",
      "           [ 2.2613e-02, -1.2731e-02,  2.8440e-02]],\n",
      "\n",
      "          [[-2.3374e-02,  5.7368e-03,  4.6518e-02],\n",
      "           [ 8.0219e-03, -3.9279e-03,  6.7145e-02],\n",
      "           [-3.6934e-02, -4.9305e-02,  1.2750e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0332e-02,  4.1860e-02, -2.9469e-02],\n",
      "           [ 2.7214e-02,  1.7953e-02, -1.2428e-02],\n",
      "           [ 1.4657e-02, -1.7611e-02, -1.1720e-02]],\n",
      "\n",
      "          [[ 3.4032e-02,  3.8326e-03, -3.2081e-03],\n",
      "           [ 5.7671e-03, -3.8288e-02,  5.5064e-02],\n",
      "           [-4.7677e-02,  1.2372e-02, -3.2068e-02]],\n",
      "\n",
      "          [[-2.9763e-02,  1.3920e-02,  1.1753e-03],\n",
      "           [ 6.8178e-03,  3.0289e-03,  5.8208e-02],\n",
      "           [ 2.5533e-02, -8.7936e-03, -7.0510e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.0212e-02, -4.8921e-04, -1.4063e-02],\n",
      "           [ 2.8506e-02, -1.3354e-03, -2.9353e-02],\n",
      "           [ 3.3958e-03, -1.9952e-02, -3.0670e-02]],\n",
      "\n",
      "          [[-3.8744e-02, -4.0808e-02,  6.9465e-04],\n",
      "           [-1.8233e-02, -2.6298e-02, -2.3918e-02],\n",
      "           [ 5.9233e-02, -5.3696e-02,  2.3287e-02]],\n",
      "\n",
      "          [[ 1.8780e-02, -2.1481e-02,  5.9966e-02],\n",
      "           [-1.4965e-02,  1.2866e-02, -2.6058e-04],\n",
      "           [ 8.7260e-03, -6.8050e-03,  1.9465e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1417e-02,  3.6098e-03, -1.1496e-02],\n",
      "           [-9.3712e-03,  2.0813e-02,  7.5363e-03],\n",
      "           [-6.7039e-03,  1.5010e-02,  2.9192e-02]],\n",
      "\n",
      "          [[-3.9334e-02,  2.7704e-02,  3.1531e-04],\n",
      "           [ 1.6019e-02, -6.7409e-03,  7.6802e-02],\n",
      "           [ 4.7036e-02,  1.4863e-02,  3.9357e-02]],\n",
      "\n",
      "          [[ 6.3773e-02, -7.0337e-03, -1.8620e-02],\n",
      "           [ 2.3893e-02,  8.2043e-03, -3.7622e-02],\n",
      "           [ 4.1247e-02,  1.9405e-02,  3.6754e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.0971e-02,  1.2419e-02,  8.7817e-02],\n",
      "           [ 1.8565e-02, -4.9056e-02,  4.9747e-02],\n",
      "           [-2.8580e-02,  2.3186e-02, -3.4578e-02]],\n",
      "\n",
      "          [[-3.9647e-03,  6.4592e-02, -4.9713e-03],\n",
      "           [-6.4904e-03,  1.5710e-02, -2.4093e-02],\n",
      "           [-7.7288e-03, -3.1090e-02,  2.5456e-03]],\n",
      "\n",
      "          [[ 8.4210e-03,  1.0241e-02, -1.5496e-02],\n",
      "           [ 5.0854e-02, -2.2737e-02, -5.8326e-03],\n",
      "           [-2.6006e-02, -7.5145e-02, -3.5004e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.8508e-03, -1.8394e-02,  1.4532e-02],\n",
      "           [ 1.1342e-02,  4.2312e-02,  7.4743e-02],\n",
      "           [ 1.9427e-02, -5.9717e-02,  6.3661e-02]],\n",
      "\n",
      "          [[-7.1244e-02, -3.9951e-02, -1.2063e-02],\n",
      "           [-5.1388e-02, -3.4811e-02,  4.2061e-02],\n",
      "           [ 1.8935e-02,  2.8583e-02, -1.2640e-02]],\n",
      "\n",
      "          [[-3.0624e-02, -3.0175e-03,  1.6953e-03],\n",
      "           [-1.7634e-02, -5.4440e-02,  5.8202e-02],\n",
      "           [ 1.5820e-02, -3.2023e-02,  1.4054e-02]]],\n",
      "\n",
      "\n",
      "         [[[-6.1997e-02,  1.3262e-02,  2.4225e-02],\n",
      "           [-2.8500e-02, -2.6241e-02,  2.0995e-02],\n",
      "           [-7.1376e-02,  1.7625e-02, -2.6418e-02]],\n",
      "\n",
      "          [[ 2.7629e-02, -1.2544e-02, -6.2476e-02],\n",
      "           [-5.6521e-03,  5.1747e-03,  7.6397e-03],\n",
      "           [-1.7195e-02,  9.1458e-03, -4.5502e-04]],\n",
      "\n",
      "          [[ 4.2116e-03,  2.6790e-02,  1.6956e-02],\n",
      "           [-5.1597e-02, -4.0698e-02, -6.4863e-03],\n",
      "           [ 7.5088e-03, -9.5415e-04, -4.1777e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.7690e-02,  2.0834e-02,  6.1117e-03],\n",
      "           [-1.6090e-03,  4.1856e-02,  5.0214e-02],\n",
      "           [-1.3866e-02,  7.8684e-02,  8.6792e-03]],\n",
      "\n",
      "          [[-2.4444e-02, -1.4476e-02, -1.4721e-02],\n",
      "           [-6.2515e-02, -4.3850e-02, -5.7374e-03],\n",
      "           [-4.7171e-02,  4.1132e-02,  2.8341e-02]],\n",
      "\n",
      "          [[ 3.5354e-02, -6.6134e-02, -6.5356e-03],\n",
      "           [ 4.6953e-02, -1.5266e-02, -1.0081e-02],\n",
      "           [ 4.2078e-02, -5.4931e-03,  1.6557e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.6526e-02,  7.0576e-02, -4.6835e-02],\n",
      "           [ 7.8105e-03, -3.1196e-04, -1.0672e-02],\n",
      "           [ 9.8030e-05, -5.7931e-02, -2.0663e-02]],\n",
      "\n",
      "          [[ 1.0858e-02,  1.7158e-02, -2.5130e-02],\n",
      "           [ 5.8274e-02, -3.1896e-02, -4.1456e-02],\n",
      "           [-3.5541e-03,  9.0567e-03,  1.9382e-03]],\n",
      "\n",
      "          [[-1.8236e-03, -3.0388e-02, -2.1448e-02],\n",
      "           [ 5.8906e-02,  8.4929e-02, -2.1777e-02],\n",
      "           [ 8.4453e-03,  8.6703e-03,  1.4825e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.8811e-02,  3.2267e-02,  2.2602e-02],\n",
      "           [-1.5575e-02, -2.1461e-02, -2.9285e-03],\n",
      "           [-4.1476e-02,  3.9013e-02, -1.4771e-02]],\n",
      "\n",
      "          [[ 1.9547e-02,  5.3076e-03, -2.4886e-02],\n",
      "           [ 1.9702e-03, -3.6050e-02, -5.2401e-02],\n",
      "           [-3.0982e-02, -3.8882e-02, -4.8439e-02]],\n",
      "\n",
      "          [[-3.7349e-02, -2.3988e-02, -4.3796e-02],\n",
      "           [-3.7892e-02,  1.1214e-02,  2.9541e-02],\n",
      "           [-3.0235e-02, -8.1593e-03,  3.8673e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.1262e-02, -2.1343e-02,  9.2085e-03],\n",
      "           [ 3.5266e-03,  6.4220e-03, -6.3510e-03],\n",
      "           [ 5.3321e-03, -1.3298e-02,  5.2202e-02]],\n",
      "\n",
      "          [[-1.0914e-02, -1.3628e-02,  3.9024e-02],\n",
      "           [-8.3234e-03,  2.6966e-03, -3.2566e-02],\n",
      "           [-1.3937e-03,  2.4801e-02,  7.9204e-04]],\n",
      "\n",
      "          [[-5.9879e-02,  4.2705e-02, -2.0427e-02],\n",
      "           [ 1.0883e-02, -5.1598e-02, -2.6125e-02],\n",
      "           [-1.1380e-02,  4.2749e-02,  2.3290e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2790e-02,  5.0272e-02,  4.9197e-02],\n",
      "           [ 9.2876e-03, -2.4543e-03, -1.9552e-02],\n",
      "           [-3.3064e-02,  6.0611e-02,  4.4606e-04]],\n",
      "\n",
      "          [[-2.8676e-03, -2.3476e-02,  3.9410e-02],\n",
      "           [-5.4050e-02,  2.3477e-02, -1.5986e-02],\n",
      "           [-1.3276e-02,  2.2023e-02, -1.4143e-02]],\n",
      "\n",
      "          [[-2.0932e-02, -3.9224e-02, -2.4086e-02],\n",
      "           [-2.0500e-02, -9.7739e-03,  6.4060e-03],\n",
      "           [ 1.0423e-02,  7.1290e-03, -4.8017e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.4627e-02,  4.1700e-02,  3.1178e-02],\n",
      "           [-3.2237e-02, -6.0472e-02,  6.0867e-02],\n",
      "           [ 1.6438e-02, -4.6775e-02, -5.7909e-02]],\n",
      "\n",
      "          [[-1.3092e-02, -1.9242e-02, -1.2173e-02],\n",
      "           [-1.5548e-02,  2.9192e-02, -1.8139e-02],\n",
      "           [ 2.5612e-03,  4.1835e-02,  4.8069e-02]],\n",
      "\n",
      "          [[ 1.5066e-02, -7.0286e-03,  3.0455e-02],\n",
      "           [-3.8266e-02,  3.8120e-02, -2.1546e-02],\n",
      "           [-2.4783e-03, -3.8364e-02,  3.6180e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-6.7820e-04, -4.8070e-03,  2.4984e-02],\n",
      "           [-2.1780e-02,  3.3129e-02,  7.4518e-02],\n",
      "           [ 2.0205e-02, -5.4645e-02, -5.7532e-02]],\n",
      "\n",
      "          [[ 1.4214e-02,  1.0237e-02,  1.0348e-02],\n",
      "           [ 1.1852e-02, -8.6014e-03,  1.2943e-02],\n",
      "           [ 5.4970e-03, -1.4004e-02,  1.2431e-02]],\n",
      "\n",
      "          [[ 5.3337e-02, -2.1104e-02, -3.7030e-03],\n",
      "           [ 1.9890e-02, -2.5880e-02, -1.2321e-02],\n",
      "           [-1.1209e-02, -1.4207e-02,  9.2242e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2618e-02,  3.4204e-03,  2.1444e-02],\n",
      "           [-4.0043e-02, -2.3620e-02, -1.1883e-02],\n",
      "           [ 1.8132e-02, -2.0708e-02,  5.0797e-03]],\n",
      "\n",
      "          [[-5.9142e-03,  5.5612e-02, -3.3191e-02],\n",
      "           [ 3.7755e-02, -3.4248e-02, -1.0182e-02],\n",
      "           [-3.3507e-02,  6.0707e-02, -3.7215e-02]],\n",
      "\n",
      "          [[-5.9774e-02, -3.6776e-02,  8.9652e-03],\n",
      "           [ 4.7320e-03,  6.9537e-02, -4.3004e-02],\n",
      "           [ 3.2177e-02, -1.0243e-01, -1.3599e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.4921e-02, -4.8655e-02,  4.6848e-02],\n",
      "           [-1.0073e-02,  3.8340e-03, -1.3549e-02],\n",
      "           [-3.8621e-02, -3.6703e-02, -4.9195e-02]],\n",
      "\n",
      "          [[ 4.3659e-02, -9.4990e-03,  9.4720e-03],\n",
      "           [ 6.7772e-02, -1.1230e-02,  9.0294e-02],\n",
      "           [ 1.8555e-02, -7.5421e-03, -5.0532e-02]],\n",
      "\n",
      "          [[ 3.3082e-03,  2.9293e-02, -1.1112e-02],\n",
      "           [ 2.8303e-02, -4.2152e-02,  2.1265e-02],\n",
      "           [ 6.2817e-03, -3.7660e-02, -3.3278e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 5.5832e-03,  1.3822e-02, -4.0132e-02],\n",
      "           [ 2.2546e-02,  5.4969e-02,  3.4102e-02],\n",
      "           [-1.3888e-02, -4.3479e-03, -1.6663e-02]],\n",
      "\n",
      "          [[ 4.3271e-02,  3.7304e-02, -1.1972e-02],\n",
      "           [ 4.1374e-03, -2.6662e-02,  4.5815e-02],\n",
      "           [-5.2566e-02, -4.5028e-02, -1.4163e-02]],\n",
      "\n",
      "          [[-1.6713e-03,  6.2727e-02,  1.7594e-02],\n",
      "           [-2.5193e-02,  2.4405e-02,  4.0238e-02],\n",
      "           [-2.1034e-03,  1.9188e-02,  1.9217e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.9964e-02,  3.3465e-02, -6.5515e-03],\n",
      "           [-5.9968e-03,  1.0882e-03,  1.8984e-02],\n",
      "           [ 1.2067e-02,  9.5311e-03, -2.6139e-02]],\n",
      "\n",
      "          [[ 1.3834e-02,  6.0054e-03, -4.1351e-02],\n",
      "           [-4.6623e-02, -3.9536e-02,  5.6773e-03],\n",
      "           [-8.6580e-03,  3.9961e-02,  2.3491e-02]],\n",
      "\n",
      "          [[-2.1815e-02,  2.0899e-02, -6.8186e-03],\n",
      "           [-3.1510e-02,  5.1490e-02,  2.8207e-02],\n",
      "           [-2.2814e-02, -9.0325e-03, -1.4667e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.2306e-02,  2.4474e-02,  3.4690e-02],\n",
      "           [-1.6869e-02, -1.7376e-02,  3.0383e-03],\n",
      "           [-1.7131e-02, -8.2159e-02,  3.5142e-02]],\n",
      "\n",
      "          [[ 5.0243e-02, -4.1096e-02,  8.5735e-03],\n",
      "           [-3.1277e-02,  3.6242e-02, -1.8756e-02],\n",
      "           [-5.2217e-02, -2.5536e-02, -2.9289e-02]],\n",
      "\n",
      "          [[ 3.4798e-02,  1.0192e-02, -2.2929e-02],\n",
      "           [-3.7770e-02, -6.8107e-02, -3.0692e-02],\n",
      "           [ 2.4471e-02, -6.0226e-03,  2.6529e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.2970e-02,  4.4570e-02,  9.6902e-03],\n",
      "           [ 3.5980e-02, -1.1438e-02,  3.4327e-02],\n",
      "           [ 5.8600e-02, -1.7313e-02,  3.2568e-02]],\n",
      "\n",
      "          [[ 5.7184e-02, -5.5962e-02,  2.8611e-02],\n",
      "           [-2.8818e-03, -2.2910e-02, -6.7798e-02],\n",
      "           [ 1.7856e-02, -5.1618e-02,  2.1647e-02]],\n",
      "\n",
      "          [[-5.6317e-02,  3.1398e-02, -7.2113e-03],\n",
      "           [ 1.8966e-02,  1.0250e-02, -3.3479e-02],\n",
      "           [-2.8238e-02, -1.7570e-02, -2.3515e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.4364e-02,  4.0286e-02,  5.1674e-02],\n",
      "           [ 2.8990e-02, -4.9914e-02, -3.8751e-03],\n",
      "           [-4.6907e-02,  1.1816e-02, -3.3077e-02]],\n",
      "\n",
      "          [[ 1.4438e-02,  1.5935e-02,  4.6521e-02],\n",
      "           [ 3.4322e-02,  1.3959e-02,  3.7071e-02],\n",
      "           [ 2.7891e-02, -1.4612e-02, -3.3466e-02]],\n",
      "\n",
      "          [[ 3.0717e-03, -2.4530e-02,  8.0474e-02],\n",
      "           [-2.0049e-02,  6.7745e-02, -2.0836e-02],\n",
      "           [ 5.5815e-03, -2.1973e-02,  7.5016e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1810e-02,  8.7965e-03, -5.3080e-03],\n",
      "           [ 3.3143e-02,  1.8613e-02, -3.0562e-03],\n",
      "           [-2.5937e-02,  4.3460e-02,  2.7328e-02]],\n",
      "\n",
      "          [[-2.7415e-02, -1.8038e-02, -3.3047e-02],\n",
      "           [-3.5741e-02, -1.3416e-02,  9.7825e-03],\n",
      "           [-2.4301e-02,  9.1468e-03,  3.3694e-02]],\n",
      "\n",
      "          [[ 2.6495e-02,  1.4057e-02, -3.6818e-02],\n",
      "           [ 1.6831e-02,  2.7784e-02,  3.4566e-02],\n",
      "           [ 7.3536e-03, -9.3520e-02,  6.4400e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-9.1604e-02, -5.1099e-02, -1.0441e-03],\n",
      "           [ 2.7163e-02,  9.2868e-03,  5.0264e-03],\n",
      "           [ 3.7290e-02, -9.9230e-03, -2.4126e-02]],\n",
      "\n",
      "          [[ 3.4324e-02, -5.3951e-02, -5.3297e-02],\n",
      "           [-4.3861e-03,  7.6598e-03,  1.3827e-02],\n",
      "           [-2.9582e-02, -5.2209e-02,  2.4423e-02]],\n",
      "\n",
      "          [[ 1.0369e-01, -1.9094e-02,  2.8608e-02],\n",
      "           [ 1.6793e-02, -9.2972e-03,  4.9572e-02],\n",
      "           [ 4.7902e-03, -3.5602e-02,  4.0957e-03]]],\n",
      "\n",
      "\n",
      "         [[[-6.2903e-02, -8.9697e-03,  1.1335e-02],\n",
      "           [-1.8710e-02,  7.0069e-02,  1.6013e-03],\n",
      "           [ 3.9510e-02, -1.4159e-02, -2.2875e-02]],\n",
      "\n",
      "          [[-1.9430e-02,  1.9357e-02, -4.2637e-02],\n",
      "           [-3.0049e-02,  2.4419e-02, -1.8813e-02],\n",
      "           [ 5.5078e-03,  4.5225e-02,  3.0264e-02]],\n",
      "\n",
      "          [[ 2.6107e-02,  1.6605e-03, -2.6876e-02],\n",
      "           [-4.8433e-02, -4.0354e-02,  1.2544e-02],\n",
      "           [ 2.6730e-02,  5.1720e-02, -3.1618e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.6263e-02, -1.7015e-02, -1.0691e-02],\n",
      "           [ 1.7564e-02,  1.2031e-01,  2.8950e-02],\n",
      "           [-7.0548e-02,  5.6685e-02, -1.3434e-02]],\n",
      "\n",
      "          [[-3.1919e-02, -3.7986e-02, -1.6829e-02],\n",
      "           [-2.4554e-02, -3.6163e-02,  3.6400e-02],\n",
      "           [-7.6901e-03, -5.9494e-02,  7.7990e-03]],\n",
      "\n",
      "          [[ 1.7103e-02,  2.0671e-02, -2.2730e-02],\n",
      "           [ 1.8584e-02, -2.4425e-02, -7.0964e-02],\n",
      "           [-2.1871e-02, -2.4060e-02,  4.0363e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 8.4863e-02,  6.1196e-02,  1.6294e-02],\n",
      "           [-2.6495e-02,  1.2101e-02, -2.6523e-02],\n",
      "           [ 2.9679e-02, -6.2499e-03,  3.3879e-02]],\n",
      "\n",
      "          [[-4.1928e-02, -1.1172e-02,  2.1245e-02],\n",
      "           [-5.3521e-03, -9.1663e-03,  3.8131e-02],\n",
      "           [-1.5196e-02,  2.9355e-02,  6.6893e-02]],\n",
      "\n",
      "          [[ 4.3742e-02,  1.4158e-02,  6.1585e-03],\n",
      "           [ 3.1190e-02,  6.8037e-04, -2.2773e-02],\n",
      "           [-3.4009e-02,  1.9414e-02, -2.2864e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.4219e-02, -2.8047e-03, -4.8883e-02],\n",
      "           [-5.8121e-02, -2.8044e-02, -2.3831e-02],\n",
      "           [-1.5039e-02,  1.6370e-02,  3.5200e-02]],\n",
      "\n",
      "          [[-1.8062e-02,  1.0471e-02,  3.1790e-02],\n",
      "           [-6.4515e-02, -7.9322e-03,  2.1757e-02],\n",
      "           [ 3.7077e-02, -3.8618e-03,  6.3656e-02]],\n",
      "\n",
      "          [[ 2.1605e-03, -1.5405e-02,  7.0342e-03],\n",
      "           [-2.0762e-02, -9.4096e-03, -1.5222e-02],\n",
      "           [ 6.3150e-03,  1.0551e-02, -9.9751e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.8569e-02,  4.6437e-02,  4.1781e-02],\n",
      "           [-2.6447e-02,  3.2844e-02, -2.9854e-02],\n",
      "           [ 4.3198e-02, -2.0375e-03, -8.8212e-03]],\n",
      "\n",
      "          [[ 1.6638e-02, -5.5523e-03, -2.3273e-03],\n",
      "           [ 2.4306e-03, -3.9939e-02,  1.8567e-02],\n",
      "           [-4.1325e-02,  6.5781e-02, -2.3532e-02]],\n",
      "\n",
      "          [[ 1.9776e-02, -8.1995e-03,  3.3422e-02],\n",
      "           [-4.1466e-02, -3.1301e-02, -2.9535e-02],\n",
      "           [ 3.9288e-02,  3.8181e-03, -1.8469e-02]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[ 0.0437,  0.0995,  0.0077],\n",
      "           [-0.0193,  0.0383, -0.0160],\n",
      "           [-0.0089, -0.0022, -0.0524]],\n",
      "\n",
      "          [[ 0.0196,  0.0538, -0.0310],\n",
      "           [-0.0146,  0.0289,  0.0112],\n",
      "           [ 0.0202, -0.0054,  0.0047]],\n",
      "\n",
      "          [[ 0.0525,  0.0538,  0.0590],\n",
      "           [-0.0383, -0.0167, -0.0264],\n",
      "           [-0.0436,  0.0438, -0.0190]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0782,  0.0264, -0.0110],\n",
      "           [-0.0042,  0.0202, -0.0381],\n",
      "           [-0.0402, -0.0188,  0.0150]],\n",
      "\n",
      "          [[-0.0125,  0.0424, -0.0016],\n",
      "           [-0.0001,  0.0358, -0.0060],\n",
      "           [ 0.0398, -0.0070, -0.0181]],\n",
      "\n",
      "          [[-0.0093, -0.0380,  0.0951],\n",
      "           [ 0.0142, -0.0147, -0.0371],\n",
      "           [ 0.0177, -0.0207,  0.0034]]],\n",
      "\n",
      "\n",
      "         [[[-0.0610,  0.0225, -0.0263],\n",
      "           [ 0.0159, -0.0143,  0.0281],\n",
      "           [-0.0289, -0.0499, -0.0203]],\n",
      "\n",
      "          [[ 0.0574,  0.0003,  0.0187],\n",
      "           [ 0.0215, -0.0630, -0.0177],\n",
      "           [-0.0040, -0.0059,  0.0283]],\n",
      "\n",
      "          [[-0.0258, -0.0113, -0.0009],\n",
      "           [-0.0167,  0.0353, -0.0325],\n",
      "           [ 0.0211, -0.0714,  0.0576]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0076, -0.0120,  0.0317],\n",
      "           [ 0.0181,  0.0547, -0.0211],\n",
      "           [-0.0431,  0.0596, -0.0418]],\n",
      "\n",
      "          [[ 0.0191, -0.0348, -0.0325],\n",
      "           [ 0.0650, -0.0259,  0.0365],\n",
      "           [-0.0258, -0.0152, -0.0136]],\n",
      "\n",
      "          [[ 0.0269, -0.0016, -0.0397],\n",
      "           [ 0.0535,  0.0552, -0.0273],\n",
      "           [ 0.0050,  0.0028, -0.0443]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0044, -0.0498, -0.0436],\n",
      "           [ 0.0020,  0.0511,  0.0436],\n",
      "           [-0.0112, -0.0671, -0.0361]],\n",
      "\n",
      "          [[-0.0156, -0.0403,  0.0724],\n",
      "           [ 0.0207,  0.0678, -0.0231],\n",
      "           [-0.0115,  0.0293, -0.0467]],\n",
      "\n",
      "          [[-0.0364, -0.0191,  0.0534],\n",
      "           [ 0.0259, -0.0146, -0.0348],\n",
      "           [-0.0811,  0.0138,  0.0238]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0351,  0.0359, -0.0478],\n",
      "           [ 0.0419,  0.0396,  0.0762],\n",
      "           [ 0.0234, -0.0316,  0.0305]],\n",
      "\n",
      "          [[ 0.0336, -0.0596,  0.0422],\n",
      "           [-0.0013, -0.0565,  0.0211],\n",
      "           [-0.0411,  0.0407, -0.0469]],\n",
      "\n",
      "          [[-0.0246, -0.0242,  0.0215],\n",
      "           [ 0.0386,  0.0095,  0.0418],\n",
      "           [ 0.0669, -0.0406, -0.0166]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0053, -0.0418, -0.0242],\n",
      "           [-0.0121, -0.0047,  0.0003],\n",
      "           [-0.0111,  0.0072,  0.0283]],\n",
      "\n",
      "          [[-0.0030,  0.0418, -0.0068],\n",
      "           [ 0.0284, -0.0920,  0.0175],\n",
      "           [-0.0268, -0.0705,  0.0175]],\n",
      "\n",
      "          [[ 0.0090, -0.0062,  0.0070],\n",
      "           [-0.0369,  0.0020, -0.0115],\n",
      "           [ 0.0455, -0.0029,  0.0017]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0019, -0.0186, -0.0442],\n",
      "           [ 0.0077,  0.0167,  0.0308],\n",
      "           [-0.0070,  0.0584,  0.0175]],\n",
      "\n",
      "          [[-0.0171,  0.0084, -0.0052],\n",
      "           [-0.0655,  0.0131,  0.0131],\n",
      "           [ 0.0028,  0.0099, -0.0060]],\n",
      "\n",
      "          [[ 0.0571,  0.0117,  0.0681],\n",
      "           [-0.0728,  0.0092, -0.0514],\n",
      "           [-0.0285,  0.0436, -0.0142]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0231,  0.0095, -0.0003],\n",
      "           [ 0.0293, -0.0182,  0.0347],\n",
      "           [ 0.0111,  0.0094, -0.0042]],\n",
      "\n",
      "          [[-0.0018, -0.0387,  0.0193],\n",
      "           [-0.0027, -0.0392, -0.0108],\n",
      "           [ 0.0412, -0.0504,  0.0100]],\n",
      "\n",
      "          [[ 0.0190, -0.0472,  0.0031],\n",
      "           [ 0.0597, -0.0032, -0.0201],\n",
      "           [-0.0284,  0.0015,  0.0151]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0108, -0.0421, -0.0019],\n",
      "           [-0.0056,  0.0240, -0.0014],\n",
      "           [ 0.0017,  0.0803,  0.0041]],\n",
      "\n",
      "          [[-0.0121, -0.0007,  0.0678],\n",
      "           [ 0.0041,  0.0426,  0.0234],\n",
      "           [ 0.0006,  0.0335,  0.0253]],\n",
      "\n",
      "          [[ 0.0039,  0.0167, -0.0133],\n",
      "           [-0.0083, -0.0602,  0.0110],\n",
      "           [ 0.0337,  0.0753,  0.0562]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0268,  0.0471, -0.0416],\n",
      "           [-0.0559,  0.0017,  0.0403],\n",
      "           [-0.0415,  0.0342, -0.0732]],\n",
      "\n",
      "          [[-0.0047, -0.0188, -0.0197],\n",
      "           [-0.0537, -0.0625,  0.0207],\n",
      "           [-0.0213,  0.0060, -0.0239]],\n",
      "\n",
      "          [[ 0.0345,  0.0089,  0.0197],\n",
      "           [-0.0052, -0.0256,  0.0204],\n",
      "           [-0.0013, -0.0221, -0.0009]]],\n",
      "\n",
      "\n",
      "         [[[-0.0281,  0.0275,  0.0026],\n",
      "           [ 0.0324,  0.0421,  0.0203],\n",
      "           [-0.0140,  0.0139, -0.0908]],\n",
      "\n",
      "          [[-0.0313, -0.0458, -0.0027],\n",
      "           [ 0.0076, -0.0434, -0.0483],\n",
      "           [-0.0402, -0.0058,  0.0032]],\n",
      "\n",
      "          [[-0.0438,  0.0745, -0.0306],\n",
      "           [ 0.0560, -0.0157, -0.0152],\n",
      "           [ 0.0327, -0.0019,  0.0441]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0002, -0.0265,  0.0055],\n",
      "           [-0.0063,  0.0347, -0.0273],\n",
      "           [-0.0035,  0.0323, -0.0209]],\n",
      "\n",
      "          [[-0.0055,  0.0240,  0.0124],\n",
      "           [-0.0144, -0.0101,  0.0040],\n",
      "           [-0.0326, -0.0027,  0.0027]],\n",
      "\n",
      "          [[-0.0206, -0.0069, -0.0258],\n",
      "           [ 0.0678,  0.0127, -0.0430],\n",
      "           [-0.0388, -0.0665, -0.0125]]],\n",
      "\n",
      "\n",
      "         [[[-0.0014, -0.0004, -0.0609],\n",
      "           [-0.0442,  0.0242, -0.0392],\n",
      "           [ 0.0216, -0.0119, -0.0221]],\n",
      "\n",
      "          [[-0.0556, -0.0449,  0.0131],\n",
      "           [-0.0018,  0.0469, -0.0194],\n",
      "           [ 0.0004, -0.0206, -0.0021]],\n",
      "\n",
      "          [[ 0.0400, -0.0123,  0.0776],\n",
      "           [-0.0505, -0.0188, -0.0294],\n",
      "           [-0.0113,  0.0025, -0.0408]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0307,  0.0005,  0.0122],\n",
      "           [ 0.0176, -0.0543, -0.0005],\n",
      "           [ 0.0603, -0.0162, -0.0052]],\n",
      "\n",
      "          [[-0.0218,  0.0395,  0.0556],\n",
      "           [ 0.0089, -0.1011,  0.0334],\n",
      "           [-0.0396, -0.0363,  0.0467]],\n",
      "\n",
      "          [[ 0.0206,  0.0401, -0.0158],\n",
      "           [ 0.0334,  0.0056, -0.0181],\n",
      "           [-0.0218, -0.0162,  0.0479]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0087, -0.0097, -0.0380],\n",
      "           [ 0.0478, -0.0666,  0.0342],\n",
      "           [ 0.0180, -0.0485, -0.0003]],\n",
      "\n",
      "          [[-0.0235,  0.0062,  0.0131],\n",
      "           [-0.0005, -0.0408,  0.0226],\n",
      "           [ 0.0267, -0.0125, -0.0162]],\n",
      "\n",
      "          [[-0.0155,  0.0349,  0.0065],\n",
      "           [-0.0581, -0.0556, -0.0257],\n",
      "           [-0.0663, -0.0542,  0.0325]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0060,  0.0138, -0.0133],\n",
      "           [ 0.0512,  0.0009, -0.0711],\n",
      "           [ 0.0222,  0.0074, -0.0084]],\n",
      "\n",
      "          [[ 0.0626, -0.0238,  0.0225],\n",
      "           [ 0.0100, -0.0010,  0.0263],\n",
      "           [ 0.0277, -0.0113, -0.0118]],\n",
      "\n",
      "          [[-0.0607, -0.0539, -0.0236],\n",
      "           [-0.0013, -0.0397, -0.0078],\n",
      "           [-0.0513,  0.0427, -0.0177]]],\n",
      "\n",
      "\n",
      "         [[[-0.0302,  0.0312,  0.0527],\n",
      "           [ 0.0452,  0.0033,  0.0784],\n",
      "           [-0.0457,  0.0200,  0.0316]],\n",
      "\n",
      "          [[ 0.0088, -0.0089, -0.0125],\n",
      "           [ 0.0348, -0.0225,  0.0138],\n",
      "           [ 0.0340, -0.0313, -0.0090]],\n",
      "\n",
      "          [[ 0.0109, -0.0521,  0.0077],\n",
      "           [ 0.0444,  0.0007, -0.0250],\n",
      "           [ 0.0103,  0.0700,  0.0408]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0137,  0.0069,  0.0004],\n",
      "           [ 0.0399,  0.0220, -0.0236],\n",
      "           [ 0.0500,  0.0347, -0.0159]],\n",
      "\n",
      "          [[ 0.0292,  0.0082,  0.0187],\n",
      "           [ 0.0223, -0.0043,  0.0569],\n",
      "           [ 0.0360,  0.0367, -0.0237]],\n",
      "\n",
      "          [[ 0.0135,  0.0246, -0.0595],\n",
      "           [ 0.0299,  0.0461, -0.0426],\n",
      "           [-0.0249,  0.0072, -0.0758]]],\n",
      "\n",
      "\n",
      "         [[[-0.0046,  0.0037,  0.0039],\n",
      "           [ 0.0435,  0.0017, -0.0145],\n",
      "           [-0.0164,  0.0069, -0.0244]],\n",
      "\n",
      "          [[ 0.0219, -0.0298,  0.0128],\n",
      "           [-0.0153, -0.0229, -0.0265],\n",
      "           [ 0.0420, -0.0161, -0.0327]],\n",
      "\n",
      "          [[-0.0270, -0.0232, -0.0292],\n",
      "           [ 0.0371, -0.0107,  0.0362],\n",
      "           [-0.0059,  0.0464, -0.0170]]],\n",
      "\n",
      "\n",
      "         [[[-0.0153,  0.0003, -0.0501],\n",
      "           [ 0.0126, -0.0653, -0.0103],\n",
      "           [ 0.0138,  0.0193,  0.0593]],\n",
      "\n",
      "          [[-0.0376, -0.0295, -0.0386],\n",
      "           [ 0.0393, -0.0275, -0.0023],\n",
      "           [ 0.0007,  0.0296,  0.0058]],\n",
      "\n",
      "          [[ 0.0121,  0.0064, -0.0132],\n",
      "           [ 0.0304, -0.0010,  0.0143],\n",
      "           [ 0.0276, -0.0510, -0.0056]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0248,  0.0339,  0.0119],\n",
      "           [-0.0241,  0.0278, -0.0040],\n",
      "           [ 0.0014, -0.0363,  0.0734]],\n",
      "\n",
      "          [[ 0.0865, -0.0284, -0.0141],\n",
      "           [ 0.0096, -0.0246,  0.0190],\n",
      "           [-0.0051, -0.0471, -0.0126]],\n",
      "\n",
      "          [[-0.0190,  0.0640,  0.0193],\n",
      "           [ 0.0801,  0.0116, -0.0322],\n",
      "           [-0.0238, -0.0363,  0.0192]]],\n",
      "\n",
      "\n",
      "         [[[-0.0352, -0.0081,  0.0366],\n",
      "           [ 0.0693,  0.0288,  0.0006],\n",
      "           [-0.0273,  0.0429,  0.0016]],\n",
      "\n",
      "          [[-0.0072, -0.0518, -0.0584],\n",
      "           [ 0.0723,  0.0049,  0.0022],\n",
      "           [-0.0200,  0.0356,  0.0277]],\n",
      "\n",
      "          [[-0.0044,  0.0068,  0.0331],\n",
      "           [ 0.0517, -0.0529, -0.0063],\n",
      "           [-0.0083, -0.0247,  0.0271]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0097,  0.0130, -0.0053],\n",
      "           [-0.0588, -0.0040,  0.0012],\n",
      "           [ 0.0348, -0.0165, -0.0186]],\n",
      "\n",
      "          [[-0.0100, -0.0172, -0.0091],\n",
      "           [ 0.0238, -0.0037, -0.0538],\n",
      "           [-0.0178,  0.1061,  0.0198]],\n",
      "\n",
      "          [[ 0.0064,  0.0057,  0.0040],\n",
      "           [-0.0241, -0.0227, -0.0148],\n",
      "           [-0.0323,  0.0198,  0.0059]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0385,  0.0224,  0.0368],\n",
      "           [-0.0105,  0.0159, -0.0003],\n",
      "           [ 0.0443,  0.0780, -0.0299]],\n",
      "\n",
      "          [[-0.0381,  0.0545, -0.0014],\n",
      "           [-0.0009, -0.0064,  0.0332],\n",
      "           [ 0.0108,  0.0249,  0.0006]],\n",
      "\n",
      "          [[ 0.0303,  0.0548,  0.0440],\n",
      "           [ 0.0020, -0.0050, -0.0033],\n",
      "           [ 0.0301, -0.0722,  0.0246]]],\n",
      "\n",
      "\n",
      "         [[[-0.0173, -0.0291, -0.0314],\n",
      "           [ 0.0086,  0.0223, -0.0346],\n",
      "           [ 0.0029,  0.0060,  0.0472]],\n",
      "\n",
      "          [[-0.0423, -0.0494, -0.0562],\n",
      "           [ 0.0835,  0.0173, -0.0202],\n",
      "           [ 0.0087, -0.0054,  0.0320]],\n",
      "\n",
      "          [[-0.0275,  0.0334,  0.0020],\n",
      "           [ 0.0177, -0.0594,  0.0183],\n",
      "           [-0.0324,  0.0043,  0.0018]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0006, -0.0282,  0.0027],\n",
      "           [-0.0055, -0.0130,  0.0112],\n",
      "           [ 0.0297, -0.0171,  0.0582]],\n",
      "\n",
      "          [[ 0.0175,  0.0207,  0.0304],\n",
      "           [-0.0144, -0.0032, -0.0361],\n",
      "           [ 0.0008,  0.0063,  0.0214]],\n",
      "\n",
      "          [[ 0.0598,  0.0867, -0.0298],\n",
      "           [ 0.0542, -0.0193,  0.0004],\n",
      "           [-0.0157, -0.0129,  0.0171]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0104, -0.0270, -0.0071],\n",
      "           [-0.0208,  0.0289, -0.0296],\n",
      "           [ 0.0113, -0.0524, -0.0441]],\n",
      "\n",
      "          [[-0.0065,  0.0184,  0.0042],\n",
      "           [-0.0066, -0.0116,  0.0123],\n",
      "           [-0.0204,  0.0059,  0.0062]],\n",
      "\n",
      "          [[ 0.0181, -0.0197,  0.0024],\n",
      "           [-0.0272,  0.0187,  0.0798],\n",
      "           [-0.0171,  0.0354,  0.0443]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0226, -0.0491,  0.0189],\n",
      "           [ 0.0377,  0.0262,  0.0321],\n",
      "           [ 0.0240,  0.0345,  0.0128]],\n",
      "\n",
      "          [[ 0.0189,  0.0383, -0.0376],\n",
      "           [ 0.0177,  0.0083,  0.0099],\n",
      "           [-0.0263,  0.0035,  0.0696]],\n",
      "\n",
      "          [[-0.0189,  0.0491, -0.0046],\n",
      "           [-0.0268,  0.0561,  0.0062],\n",
      "           [-0.0044,  0.0045, -0.0057]]],\n",
      "\n",
      "\n",
      "         [[[-0.0181, -0.0026,  0.0055],\n",
      "           [ 0.0035,  0.0109, -0.0571],\n",
      "           [-0.0052, -0.0043,  0.0196]],\n",
      "\n",
      "          [[-0.0478,  0.0013,  0.0312],\n",
      "           [-0.0236, -0.0142,  0.0820],\n",
      "           [-0.0132, -0.0169,  0.0425]],\n",
      "\n",
      "          [[ 0.0341, -0.0106, -0.0211],\n",
      "           [-0.0002, -0.0211, -0.0428],\n",
      "           [ 0.0114,  0.0051,  0.0491]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0722, -0.0135, -0.0103],\n",
      "           [ 0.0045, -0.0648,  0.0266],\n",
      "           [ 0.0535,  0.0149, -0.0471]],\n",
      "\n",
      "          [[-0.0431, -0.0149,  0.0076],\n",
      "           [ 0.0228, -0.0693, -0.0040],\n",
      "           [ 0.0421, -0.0371, -0.0027]],\n",
      "\n",
      "          [[-0.0143,  0.0227, -0.0305],\n",
      "           [ 0.0756,  0.0020, -0.1064],\n",
      "           [-0.0418, -0.0052, -0.0190]]],\n",
      "\n",
      "\n",
      "         [[[-0.0370,  0.0116,  0.0923],\n",
      "           [ 0.0205,  0.0834,  0.0570],\n",
      "           [ 0.0434, -0.0110,  0.0325]],\n",
      "\n",
      "          [[ 0.0218,  0.0542,  0.0426],\n",
      "           [-0.0403,  0.0169,  0.0057],\n",
      "           [-0.0113, -0.0262,  0.0369]],\n",
      "\n",
      "          [[-0.0165,  0.0388,  0.0176],\n",
      "           [ 0.0080,  0.0333, -0.0189],\n",
      "           [-0.0566,  0.0480, -0.0496]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0010, -0.0050,  0.0205],\n",
      "           [ 0.0234, -0.0255, -0.0081],\n",
      "           [ 0.0143,  0.0403,  0.0852]],\n",
      "\n",
      "          [[-0.0263,  0.0091, -0.0027],\n",
      "           [ 0.0303,  0.0564, -0.0172],\n",
      "           [ 0.0041,  0.0138, -0.0238]],\n",
      "\n",
      "          [[ 0.0307, -0.0069, -0.0275],\n",
      "           [-0.0102,  0.0155,  0.0184],\n",
      "           [ 0.0170,  0.0419,  0.0563]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0408, -0.0526,  0.0093],\n",
      "           [-0.0393,  0.0050,  0.0130],\n",
      "           [ 0.0153, -0.0101,  0.0125]],\n",
      "\n",
      "          [[ 0.0056, -0.0293, -0.0095],\n",
      "           [-0.0222,  0.0145, -0.0148],\n",
      "           [-0.0283, -0.1255,  0.0209]],\n",
      "\n",
      "          [[-0.0295, -0.0486,  0.0069],\n",
      "           [-0.0203,  0.0070,  0.0459],\n",
      "           [ 0.0385, -0.0539,  0.0714]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0015, -0.0355,  0.0453],\n",
      "           [-0.0087, -0.0141,  0.0513],\n",
      "           [-0.0437,  0.0029, -0.0249]],\n",
      "\n",
      "          [[-0.0596, -0.0273, -0.0068],\n",
      "           [-0.0102, -0.0154, -0.0042],\n",
      "           [ 0.0122,  0.0786, -0.0266]],\n",
      "\n",
      "          [[ 0.0064,  0.0334, -0.0246],\n",
      "           [-0.0540, -0.0144, -0.0289],\n",
      "           [ 0.0305, -0.0128, -0.0080]]],\n",
      "\n",
      "\n",
      "         [[[-0.0030, -0.0286,  0.0338],\n",
      "           [ 0.0607,  0.0301,  0.0466],\n",
      "           [ 0.0173,  0.0526,  0.0260]],\n",
      "\n",
      "          [[-0.0600, -0.0238,  0.0231],\n",
      "           [-0.0157, -0.0039, -0.0112],\n",
      "           [ 0.0501,  0.0492, -0.0203]],\n",
      "\n",
      "          [[-0.0102, -0.0197, -0.0519],\n",
      "           [-0.0073,  0.0103,  0.0076],\n",
      "           [-0.0190,  0.1156,  0.0046]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[-0.0361]]],\n",
      "\n",
      "\n",
      "         [[[-0.0094]]],\n",
      "\n",
      "\n",
      "         [[[-0.0903]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0916]]],\n",
      "\n",
      "\n",
      "         [[[-0.1085]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3780]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.2407]]],\n",
      "\n",
      "\n",
      "         [[[-0.0597]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1311]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.1693]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1172]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2707]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.2656]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2667]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2490]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.1896]]],\n",
      "\n",
      "\n",
      "         [[[-0.0258]]],\n",
      "\n",
      "\n",
      "         [[[-0.2183]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.2132]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0613]]],\n",
      "\n",
      "\n",
      "         [[[-0.1053]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0957]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2127]]],\n",
      "\n",
      "\n",
      "         [[[-0.3204]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0527]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2195]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0025]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.2380]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0400]]],\n",
      "\n",
      "\n",
      "         [[[-0.2207]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1687]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0020]]],\n",
      "\n",
      "\n",
      "         [[[ 0.3078]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.2608]]],\n",
      "\n",
      "\n",
      "         [[[-0.0722]]],\n",
      "\n",
      "\n",
      "         [[[-0.0240]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0129,  0.1574, -0.0614, -0.1759,  0.0459,  0.1522, -0.0424,  0.1181,\n",
      "         0.0564,  0.0269, -0.1034, -0.1760, -0.0823,  0.1371, -0.1204,  0.0565,\n",
      "        -0.1415, -0.0388, -0.1393, -0.1288, -0.1370, -0.1434, -0.0497,  0.1109,\n",
      "        -0.1202, -0.0333, -0.1683,  0.0574, -0.0738,  0.0980, -0.0048, -0.0650,\n",
      "         0.0795, -0.0016,  0.1584,  0.1599, -0.1589, -0.0128, -0.0474,  0.0054,\n",
      "        -0.0759, -0.1314,  0.0027,  0.0901,  0.0327,  0.1538,  0.0386,  0.1757,\n",
      "        -0.0493,  0.0572, -0.0662, -0.0516,  0.0688, -0.1230, -0.0397, -0.0399,\n",
      "         0.0718,  0.0372, -0.0181, -0.1468, -0.1062,  0.0880, -0.0188,  0.0927],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[ 8.9435e-03,  1.4671e-03,  1.1538e-02],\n",
      "           [ 3.9164e-02, -2.7632e-04, -3.7929e-03],\n",
      "           [ 1.1739e-02, -6.3960e-03, -6.9668e-03]],\n",
      "\n",
      "          [[ 2.1080e-02,  1.7662e-02, -3.0134e-03],\n",
      "           [ 2.0850e-02, -1.1205e-02, -2.1450e-02],\n",
      "           [ 5.6784e-02,  9.9110e-03,  3.8225e-02]],\n",
      "\n",
      "          [[-1.5712e-02, -3.1243e-02,  9.7979e-03],\n",
      "           [-2.8196e-03,  1.5772e-02,  1.0300e-02],\n",
      "           [ 2.3322e-02,  2.8987e-02,  2.8599e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.2029e-03,  9.0768e-03,  1.3445e-02],\n",
      "           [-1.1488e-03,  1.7480e-02,  2.6684e-02],\n",
      "           [-3.3256e-02,  1.2424e-02, -1.4659e-02]],\n",
      "\n",
      "          [[ 2.6743e-02, -8.6861e-03, -5.7582e-03],\n",
      "           [-9.3872e-03, -1.9833e-02,  2.0884e-02],\n",
      "           [-2.2697e-02, -4.0440e-02, -1.7985e-02]],\n",
      "\n",
      "          [[ 1.8459e-02, -3.1540e-03, -1.2762e-02],\n",
      "           [-1.1150e-02,  2.0053e-02, -1.2395e-02],\n",
      "           [ 4.0969e-02,  2.9159e-02,  5.2891e-04]]],\n",
      "\n",
      "\n",
      "         [[[-5.9614e-03, -1.8758e-03, -2.1446e-02],\n",
      "           [ 8.4420e-03,  5.9129e-03, -1.3165e-02],\n",
      "           [-2.1774e-03,  2.6257e-02,  1.6748e-03]],\n",
      "\n",
      "          [[-2.5636e-03,  2.7918e-02,  4.9005e-02],\n",
      "           [ 1.8889e-02,  1.7830e-02,  1.4144e-02],\n",
      "           [ 4.3672e-02, -2.7156e-02, -5.7481e-04]],\n",
      "\n",
      "          [[-6.4836e-03, -5.9151e-03,  1.0138e-02],\n",
      "           [-2.5034e-02,  9.6245e-03,  4.6307e-02],\n",
      "           [-9.9677e-03, -3.7101e-02, -2.6429e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.8801e-03, -2.2497e-02, -4.9196e-02],\n",
      "           [-5.8381e-02,  3.1621e-02, -9.1887e-03],\n",
      "           [-2.0951e-02, -1.0003e-02, -1.9623e-02]],\n",
      "\n",
      "          [[ 2.1414e-02, -1.5826e-02,  1.5585e-02],\n",
      "           [-2.0925e-02,  2.4715e-02,  3.1135e-02],\n",
      "           [-1.8204e-02, -7.0841e-03, -2.3435e-02]],\n",
      "\n",
      "          [[-1.1965e-02, -4.5716e-02,  8.4466e-03],\n",
      "           [ 7.3735e-03,  5.9418e-03, -4.1337e-02],\n",
      "           [-1.2777e-02,  2.8684e-02,  1.2667e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.0138e-02,  3.7850e-03,  4.5639e-02],\n",
      "           [-2.8292e-02,  1.3956e-03, -2.7757e-02],\n",
      "           [-3.9106e-02,  2.0346e-02, -1.3268e-04]],\n",
      "\n",
      "          [[ 1.4695e-02,  2.4505e-02,  3.2208e-03],\n",
      "           [-2.4581e-02,  3.7576e-02, -3.2545e-02],\n",
      "           [-2.6328e-02,  1.0653e-02,  4.3752e-02]],\n",
      "\n",
      "          [[-7.9640e-03, -5.1965e-03,  7.4057e-05],\n",
      "           [ 7.6101e-03,  2.6098e-03, -2.7118e-02],\n",
      "           [ 3.7280e-03,  1.4206e-02, -2.6223e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2156e-02,  9.2047e-03, -2.2854e-03],\n",
      "           [ 1.3228e-02,  1.2076e-02, -1.7945e-02],\n",
      "           [-1.5978e-02,  4.3576e-02,  2.6974e-02]],\n",
      "\n",
      "          [[-2.8501e-02,  1.3406e-02,  3.8940e-02],\n",
      "           [-1.8730e-02, -2.3356e-02, -2.2464e-02],\n",
      "           [ 9.4713e-03,  4.5349e-02,  4.7750e-02]],\n",
      "\n",
      "          [[-1.6164e-02,  7.9189e-03, -5.1808e-02],\n",
      "           [-3.3475e-02, -4.2922e-02,  1.0266e-02],\n",
      "           [ 1.0483e-02,  1.2567e-02,  4.7959e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.7857e-03, -2.8317e-02, -4.8832e-02],\n",
      "           [ 2.7498e-02, -1.3318e-02, -9.2099e-03],\n",
      "           [ 6.4180e-03, -3.2831e-02,  3.1080e-02]],\n",
      "\n",
      "          [[ 2.1425e-02,  1.9826e-02, -3.7879e-02],\n",
      "           [ 3.4578e-02, -2.2885e-02, -4.3783e-02],\n",
      "           [ 3.1741e-02,  4.0437e-02, -3.5636e-02]],\n",
      "\n",
      "          [[ 2.3948e-02, -1.0895e-02, -2.5463e-02],\n",
      "           [-2.6944e-02, -7.5070e-03, -3.4315e-02],\n",
      "           [-1.3412e-03, -1.9741e-02, -1.7953e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.2491e-02,  5.7908e-02,  6.2048e-03],\n",
      "           [-1.2649e-02,  8.2945e-04, -2.4403e-03],\n",
      "           [ 2.9406e-02, -1.6135e-02, -9.4145e-03]],\n",
      "\n",
      "          [[-1.3766e-02, -6.8335e-03, -8.6079e-03],\n",
      "           [-2.0203e-02, -1.9864e-02, -2.0479e-02],\n",
      "           [ 1.1849e-02,  2.7742e-04,  8.8184e-03]],\n",
      "\n",
      "          [[ 2.2667e-03, -1.6930e-02, -9.3015e-03],\n",
      "           [ 1.3283e-02,  4.9241e-03,  2.9723e-02],\n",
      "           [ 2.7280e-03, -7.0923e-02, -2.1567e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.3060e-02, -2.1894e-03, -3.3986e-03],\n",
      "           [ 1.3452e-02, -6.6197e-03,  3.3683e-02],\n",
      "           [ 3.7421e-02, -8.4912e-03, -2.1269e-02]],\n",
      "\n",
      "          [[-2.0343e-02, -7.4163e-04, -1.6971e-02],\n",
      "           [ 5.4894e-03,  2.1098e-02, -1.0324e-02],\n",
      "           [-1.9408e-02,  4.0291e-02, -2.6399e-02]],\n",
      "\n",
      "          [[-7.5731e-03,  2.1249e-02,  2.0721e-02],\n",
      "           [-3.4879e-02,  6.6968e-02, -2.3355e-03],\n",
      "           [ 3.0286e-02, -3.9937e-02, -5.2263e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.5111e-03, -1.3959e-02, -7.9921e-03],\n",
      "           [ 3.7066e-02, -2.9641e-02, -3.2808e-02],\n",
      "           [-2.5802e-03,  4.5838e-03,  1.0089e-02]],\n",
      "\n",
      "          [[-1.0610e-02,  1.4370e-02,  9.8457e-04],\n",
      "           [ 1.5997e-02,  5.9455e-02, -4.1519e-04],\n",
      "           [-1.5188e-02, -1.4863e-02,  1.9535e-02]],\n",
      "\n",
      "          [[-2.3294e-02,  1.3469e-02, -3.2665e-02],\n",
      "           [ 2.7724e-02, -1.1318e-02,  3.8267e-02],\n",
      "           [ 2.6586e-02, -1.6677e-03, -7.5656e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.9657e-02,  1.7004e-02, -1.5948e-02],\n",
      "           [ 2.2289e-02,  5.4761e-02, -4.8875e-03],\n",
      "           [-4.7086e-02,  4.3976e-02,  3.0344e-03]],\n",
      "\n",
      "          [[-1.4368e-02, -9.1937e-03, -2.0376e-02],\n",
      "           [-8.8314e-03, -3.4500e-02,  1.9654e-02],\n",
      "           [ 2.6875e-02, -3.8701e-02,  2.3682e-02]],\n",
      "\n",
      "          [[ 5.5834e-02,  3.6703e-02,  2.9851e-02],\n",
      "           [-1.2393e-02, -8.8954e-02,  3.0622e-02],\n",
      "           [ 6.1333e-03, -9.2975e-03,  9.6495e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 4.3443e-03, -9.5456e-03,  2.1288e-02],\n",
      "           [-9.8175e-03,  2.6050e-02, -2.7823e-03],\n",
      "           [ 2.5073e-02, -4.7108e-03, -3.0600e-02]],\n",
      "\n",
      "          [[-4.2801e-03, -2.1524e-02, -2.2514e-02],\n",
      "           [ 8.4834e-03, -1.6004e-02,  1.5285e-02],\n",
      "           [-2.9147e-03,  1.8896e-02, -9.6882e-04]],\n",
      "\n",
      "          [[-5.0341e-02,  4.1399e-02, -2.9862e-02],\n",
      "           [ 5.3388e-03, -4.4940e-03, -4.9687e-03],\n",
      "           [-3.6392e-03, -4.0107e-02, -3.1536e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.3711e-02,  2.3627e-02, -1.6007e-02],\n",
      "           [-1.7416e-02, -4.0206e-02,  2.2138e-02],\n",
      "           [-3.1839e-02,  4.2987e-02,  3.3075e-02]],\n",
      "\n",
      "          [[-3.1623e-02,  2.0677e-02,  2.0258e-02],\n",
      "           [-5.2678e-03,  3.7787e-02, -6.8791e-03],\n",
      "           [ 1.8790e-02, -2.8314e-02,  2.8806e-03]],\n",
      "\n",
      "          [[-3.7847e-02, -1.3366e-02, -1.0196e-02],\n",
      "           [ 1.4155e-02, -1.6986e-02,  6.9117e-03],\n",
      "           [-8.3451e-03, -2.7184e-02, -1.8419e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.4872e-02,  2.2568e-03, -1.2864e-02],\n",
      "           [-9.0720e-03, -1.3163e-02,  3.9932e-02],\n",
      "           [-1.4713e-03,  2.2368e-04, -2.5713e-02]],\n",
      "\n",
      "          [[-3.9650e-03, -1.6724e-02, -3.7337e-02],\n",
      "           [-1.7739e-03, -2.9811e-03,  7.9159e-03],\n",
      "           [ 4.3117e-02, -2.1468e-02, -2.4525e-02]],\n",
      "\n",
      "          [[ 2.6018e-02,  5.0961e-04,  3.0013e-02],\n",
      "           [ 3.7184e-03, -2.1762e-02, -1.9045e-02],\n",
      "           [-7.9155e-03, -2.1237e-02, -4.0451e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.8161e-03,  9.7442e-04, -1.0035e-02],\n",
      "           [ 1.0549e-02,  3.1990e-02,  3.2615e-02],\n",
      "           [ 3.0398e-02,  1.2349e-02,  1.1573e-03]],\n",
      "\n",
      "          [[-2.8705e-03,  4.5902e-03,  9.8388e-03],\n",
      "           [-8.3021e-04,  5.1997e-04,  2.3534e-02],\n",
      "           [ 2.6058e-02, -1.4699e-03,  3.9523e-02]],\n",
      "\n",
      "          [[ 1.4500e-02, -1.2379e-02, -8.8387e-03],\n",
      "           [-5.8340e-03, -1.1147e-02, -4.9710e-02],\n",
      "           [ 4.1885e-03,  4.3597e-03, -1.8435e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.9694e-03, -2.6447e-02,  2.9829e-02],\n",
      "           [-3.4555e-02, -8.4523e-03,  1.4985e-02],\n",
      "           [ 1.4565e-02, -2.1210e-02,  1.3167e-02]],\n",
      "\n",
      "          [[ 2.8336e-02,  2.3390e-02,  5.6194e-03],\n",
      "           [ 1.0074e-02,  3.4557e-02, -1.2185e-02],\n",
      "           [-1.4913e-02,  2.2962e-02, -3.1938e-02]],\n",
      "\n",
      "          [[ 4.0068e-02,  1.4637e-03,  3.4187e-02],\n",
      "           [ 2.4860e-02,  1.1524e-03, -2.9365e-02],\n",
      "           [-7.9208e-03,  6.7055e-03, -6.4677e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1315e-02,  1.5635e-02,  3.3156e-03],\n",
      "           [-1.5689e-03,  7.2893e-03, -4.8570e-02],\n",
      "           [ 1.0236e-03, -1.1421e-02, -1.7448e-02]],\n",
      "\n",
      "          [[-5.3925e-02,  2.5864e-02,  2.8037e-04],\n",
      "           [ 6.0092e-03,  1.1096e-02,  2.8792e-02],\n",
      "           [ 2.8349e-02, -1.3667e-02, -1.4961e-02]],\n",
      "\n",
      "          [[-1.4009e-02,  3.0046e-02,  4.4439e-02],\n",
      "           [ 2.6537e-03, -2.2561e-02, -1.7965e-02],\n",
      "           [ 7.9333e-03, -5.7346e-03,  2.1700e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.5813e-02, -3.7431e-03,  8.4633e-03],\n",
      "           [ 1.5629e-02,  2.0464e-02, -2.0643e-02],\n",
      "           [-3.6250e-02,  6.0550e-03,  3.8102e-02]],\n",
      "\n",
      "          [[ 2.6774e-02, -3.7551e-03,  3.9259e-02],\n",
      "           [-2.6749e-02, -1.7964e-02, -4.9986e-03],\n",
      "           [-1.8709e-02,  1.6254e-03, -8.5749e-03]],\n",
      "\n",
      "          [[ 2.7928e-02, -1.2970e-02,  1.4454e-02],\n",
      "           [-2.3566e-02, -1.5975e-02,  2.0948e-02],\n",
      "           [ 1.5281e-02,  3.8991e-02,  2.0750e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.6289e-03, -2.8366e-02,  2.8014e-02],\n",
      "           [ 3.4735e-03, -1.3091e-02,  4.3245e-03],\n",
      "           [-8.2974e-03,  6.4652e-02,  1.1931e-02]],\n",
      "\n",
      "          [[-4.4692e-02,  4.4976e-03,  6.9256e-02],\n",
      "           [-1.8302e-03,  5.3150e-03, -4.3348e-03],\n",
      "           [-4.6801e-02,  4.7511e-02,  1.3361e-02]],\n",
      "\n",
      "          [[ 1.4122e-02, -1.4121e-02,  2.1499e-02],\n",
      "           [ 6.8339e-03,  2.4363e-03,  4.2090e-03],\n",
      "           [-5.0866e-02, -1.5008e-02,  6.8354e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.5836e-02, -2.2343e-02,  9.4628e-03],\n",
      "           [ 1.2613e-02, -3.4061e-02, -2.7656e-02],\n",
      "           [-1.1604e-02, -4.0725e-02,  2.8705e-02]],\n",
      "\n",
      "          [[-1.5722e-03, -3.4110e-03,  7.1355e-03],\n",
      "           [ 2.3358e-02,  1.5526e-03,  1.7689e-02],\n",
      "           [-3.0330e-02,  2.6162e-03,  5.4882e-03]],\n",
      "\n",
      "          [[-3.1221e-02, -1.2258e-02,  2.8824e-02],\n",
      "           [ 2.1789e-02, -3.9841e-02,  4.1109e-02],\n",
      "           [-1.9675e-02, -2.5207e-02, -2.2715e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.5153e-02, -3.1267e-02,  2.5051e-02],\n",
      "           [-1.4905e-02, -2.5111e-02, -1.6869e-02],\n",
      "           [-1.4029e-02,  6.1668e-03,  2.0476e-02]],\n",
      "\n",
      "          [[ 1.1363e-03, -1.8915e-02,  4.9984e-03],\n",
      "           [-1.7952e-02, -5.7691e-04,  2.7211e-02],\n",
      "           [ 6.2122e-02, -1.4837e-03,  9.9542e-04]],\n",
      "\n",
      "          [[ 4.1204e-02, -4.1227e-02, -1.1879e-02],\n",
      "           [-1.7476e-02, -9.2220e-03, -2.3561e-02],\n",
      "           [ 1.7221e-02,  3.3412e-03,  8.3161e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.4263e-02,  4.0800e-02,  4.0881e-04],\n",
      "           [ 3.0006e-02, -6.5194e-03,  9.8688e-03],\n",
      "           [ 2.9142e-03, -1.8515e-02,  2.3048e-02]],\n",
      "\n",
      "          [[-4.5084e-02, -1.5809e-02,  3.4000e-03],\n",
      "           [ 1.1577e-02, -2.7849e-02, -6.3875e-03],\n",
      "           [ 1.5867e-02, -2.3209e-02, -2.8869e-02]],\n",
      "\n",
      "          [[ 8.3867e-03, -3.4320e-02, -7.5045e-03],\n",
      "           [-1.5836e-03,  1.4805e-02, -1.4763e-03],\n",
      "           [ 2.5832e-02, -1.6388e-03, -2.7337e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.0706e-02, -1.7895e-02,  2.6714e-02],\n",
      "           [-7.5842e-03, -3.3690e-02, -7.4842e-03],\n",
      "           [-2.2977e-02,  2.0374e-02,  8.4872e-03]],\n",
      "\n",
      "          [[ 1.0942e-02, -1.2076e-02, -3.3226e-02],\n",
      "           [-1.3671e-02, -4.9437e-03, -1.7337e-02],\n",
      "           [ 8.6753e-03, -5.1727e-03,  8.0709e-03]],\n",
      "\n",
      "          [[-1.4797e-02,  1.5038e-02, -3.2693e-02],\n",
      "           [-1.0510e-02, -5.2370e-03,  1.0856e-02],\n",
      "           [-8.2274e-03, -7.2280e-03, -2.2291e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.8072e-02, -1.6153e-02, -2.6142e-02],\n",
      "           [-2.5730e-02, -2.2811e-02,  8.6710e-02],\n",
      "           [ 3.8562e-03, -5.3583e-02, -7.8194e-03]],\n",
      "\n",
      "          [[ 2.2861e-02,  9.1608e-03,  2.8295e-02],\n",
      "           [-2.1376e-03,  1.2986e-02, -7.2966e-03],\n",
      "           [ 5.2873e-02, -3.5555e-03,  2.1512e-02]],\n",
      "\n",
      "          [[ 1.0307e-02,  1.0140e-02,  5.9067e-03],\n",
      "           [ 5.9666e-03,  2.4623e-02, -7.2403e-03],\n",
      "           [ 3.4241e-02,  3.7302e-02, -1.4657e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.9076e-02, -2.1333e-03, -1.8164e-02],\n",
      "           [ 5.4264e-03,  1.8097e-02, -8.9645e-03],\n",
      "           [ 9.7238e-03,  1.5889e-02, -8.5427e-03]],\n",
      "\n",
      "          [[ 1.4412e-02,  1.5595e-02,  2.1098e-02],\n",
      "           [ 1.2897e-02,  3.3717e-03, -6.3308e-05],\n",
      "           [-1.1360e-02,  4.7903e-02, -5.9293e-03]],\n",
      "\n",
      "          [[-2.7969e-03,  1.0871e-02, -3.0315e-02],\n",
      "           [-4.0548e-02,  3.0761e-02, -1.6506e-02],\n",
      "           [-4.8191e-03, -1.5762e-02, -1.6117e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.4724e-03, -4.3358e-02,  1.2009e-02],\n",
      "           [-5.2313e-03,  2.0833e-02, -1.7916e-02],\n",
      "           [-2.0046e-02,  5.1226e-04, -2.9050e-02]],\n",
      "\n",
      "          [[-3.1207e-02, -1.6790e-03,  1.6966e-02],\n",
      "           [-6.1797e-02,  2.4619e-02, -1.9192e-02],\n",
      "           [-1.1508e-02,  1.0870e-02, -5.1498e-02]],\n",
      "\n",
      "          [[-2.4264e-02,  3.5506e-03,  1.2014e-03],\n",
      "           [-8.9255e-03,  2.5522e-02, -4.1994e-02],\n",
      "           [ 3.1618e-02,  8.8938e-03,  9.9048e-03]]],\n",
      "\n",
      "\n",
      "         [[[-6.4698e-02,  5.1310e-03, -1.2560e-02],\n",
      "           [-4.5878e-02, -3.7325e-02, -4.5573e-03],\n",
      "           [-2.4711e-02,  2.1890e-02, -8.9528e-03]],\n",
      "\n",
      "          [[-1.2591e-02,  1.3878e-02,  2.9903e-02],\n",
      "           [ 1.9682e-02, -1.0727e-02,  3.7444e-02],\n",
      "           [-2.4688e-02,  1.7002e-02, -1.5074e-02]],\n",
      "\n",
      "          [[-4.3049e-03,  1.6293e-02, -4.4464e-03],\n",
      "           [-1.5671e-02, -1.2307e-02, -1.7649e-02],\n",
      "           [ 7.0740e-03,  8.9774e-03,  3.0582e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-4.3812e-02,  3.5666e-02, -8.9708e-03],\n",
      "           [ 3.1051e-02,  1.9745e-02, -2.4317e-03],\n",
      "           [-3.3909e-03, -1.8631e-02, -1.1845e-02]],\n",
      "\n",
      "          [[-2.5569e-02, -4.3930e-02,  2.0343e-02],\n",
      "           [-8.1253e-03, -3.3159e-02, -2.1363e-03],\n",
      "           [-3.8578e-03, -5.9408e-03, -1.4084e-02]],\n",
      "\n",
      "          [[ 3.2780e-02,  2.8731e-02,  2.8432e-02],\n",
      "           [ 1.3268e-02,  4.3788e-02, -5.2650e-03],\n",
      "           [-2.0315e-02,  2.1931e-02, -3.8706e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1272e-02, -3.9033e-02,  6.3787e-03],\n",
      "           [-1.6188e-02,  9.7233e-03, -5.4577e-02],\n",
      "           [-2.2169e-02, -1.7781e-02, -4.5489e-02]],\n",
      "\n",
      "          [[ 5.4071e-02,  8.9489e-03, -1.0537e-02],\n",
      "           [-4.6541e-02, -1.4786e-02,  4.6438e-03],\n",
      "           [ 5.5076e-02, -3.3125e-02, -4.0280e-03]],\n",
      "\n",
      "          [[ 4.1175e-03,  1.4646e-02, -2.9332e-03],\n",
      "           [ 4.0436e-03,  1.3209e-02,  2.4454e-02],\n",
      "           [ 1.2983e-02, -4.5830e-02,  4.2744e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.0448e-02, -2.0613e-02,  6.4171e-04],\n",
      "           [ 1.6884e-02, -1.9047e-02, -2.0395e-02],\n",
      "           [-4.7003e-02,  2.3404e-02,  2.6660e-02]],\n",
      "\n",
      "          [[ 9.5671e-03,  2.5615e-02, -6.2728e-02],\n",
      "           [ 2.4117e-02, -1.8465e-03, -3.7058e-02],\n",
      "           [ 4.4124e-02, -1.3093e-03, -4.1961e-03]],\n",
      "\n",
      "          [[-2.8470e-02,  3.1085e-02, -1.6837e-02],\n",
      "           [-4.5930e-03, -1.1869e-02,  5.3803e-02],\n",
      "           [ 4.9224e-02,  2.7131e-02, -1.5154e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.7546e-02,  6.8017e-04, -3.9568e-02],\n",
      "           [-3.2248e-03,  4.3624e-02, -1.8514e-02],\n",
      "           [ 3.5464e-02,  6.2906e-03, -1.8214e-02]],\n",
      "\n",
      "          [[ 1.6140e-02,  4.2867e-02, -5.5884e-03],\n",
      "           [-2.7507e-02, -2.0336e-02,  1.2234e-02],\n",
      "           [-3.8253e-02,  3.1879e-02, -1.4534e-02]],\n",
      "\n",
      "          [[-6.8780e-03, -3.0434e-02,  2.5140e-02],\n",
      "           [ 1.4725e-02, -5.9293e-04, -1.0166e-02],\n",
      "           [ 6.5806e-02,  2.3001e-02,  1.7867e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.9530e-03, -6.3254e-02,  2.9687e-02],\n",
      "           [-3.4417e-02,  2.2324e-02,  1.1608e-03],\n",
      "           [ 5.1751e-03,  1.2561e-03,  5.1780e-03]],\n",
      "\n",
      "          [[-3.1139e-02,  2.3538e-02,  3.6311e-02],\n",
      "           [-1.8581e-02,  1.0270e-02, -1.4395e-02],\n",
      "           [ 4.4931e-02, -1.7608e-02,  1.3851e-02]],\n",
      "\n",
      "          [[ 2.4236e-02,  4.3564e-03, -2.2205e-02],\n",
      "           [-3.4359e-02,  1.6921e-02,  1.9504e-02],\n",
      "           [-2.3046e-02, -2.3557e-02,  5.7789e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5838e-02,  2.1138e-02, -2.0978e-03],\n",
      "           [-5.5077e-03, -4.1669e-02,  6.9041e-03],\n",
      "           [-2.2426e-02,  2.7744e-03,  2.4948e-03]],\n",
      "\n",
      "          [[ 4.4724e-03, -3.7631e-03, -1.6479e-02],\n",
      "           [ 1.9081e-02, -2.0872e-02, -8.8176e-03],\n",
      "           [-3.0500e-02, -1.3574e-02, -2.5185e-02]],\n",
      "\n",
      "          [[ 2.1557e-02,  6.1445e-02, -3.1471e-02],\n",
      "           [ 4.6021e-02, -1.4222e-02, -4.9097e-03],\n",
      "           [-1.2448e-02,  3.5027e-03, -1.9982e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0501e-02,  1.5817e-02,  2.0026e-03],\n",
      "           [-8.3065e-03,  1.7026e-02,  5.5525e-04],\n",
      "           [-3.2377e-02, -2.3453e-02,  9.5889e-03]],\n",
      "\n",
      "          [[ 3.6476e-02, -2.5303e-02, -1.6891e-02],\n",
      "           [ 2.7784e-02,  1.7922e-02, -6.6201e-03],\n",
      "           [ 2.4549e-03,  2.2967e-02, -8.7863e-03]],\n",
      "\n",
      "          [[ 4.2761e-03, -3.7437e-03, -2.6996e-02],\n",
      "           [ 2.0120e-02,  8.7425e-03,  2.2853e-02],\n",
      "           [ 2.9202e-03, -5.0715e-02,  2.1707e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.1711e-03,  1.8447e-02, -3.5510e-02],\n",
      "           [-1.8218e-02, -6.2240e-04, -3.6402e-02],\n",
      "           [ 1.7185e-03, -2.7428e-02,  2.9077e-02]],\n",
      "\n",
      "          [[ 4.1291e-02,  2.3805e-02, -4.0167e-02],\n",
      "           [-2.4040e-02, -3.4742e-02,  5.7471e-02],\n",
      "           [ 4.4624e-03,  1.8959e-02, -2.7163e-02]],\n",
      "\n",
      "          [[ 5.8956e-03, -2.8986e-03,  2.6180e-02],\n",
      "           [ 5.1483e-03, -2.8072e-02,  1.0608e-02],\n",
      "           [ 1.0359e-02, -1.8317e-02,  2.1746e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2335e-04,  1.2653e-02, -5.1661e-03],\n",
      "           [-2.4239e-02, -3.1961e-03, -1.7990e-02],\n",
      "           [ 2.3051e-02,  1.7750e-02,  1.8283e-02]],\n",
      "\n",
      "          [[ 1.4211e-03, -1.4229e-02,  2.0394e-02],\n",
      "           [-3.1998e-02, -3.6235e-02,  5.4671e-03],\n",
      "           [-2.5102e-02,  2.4118e-02,  3.1836e-02]],\n",
      "\n",
      "          [[-2.3251e-02, -1.9319e-02, -1.3938e-02],\n",
      "           [ 7.4532e-03, -1.1884e-02, -1.2818e-02],\n",
      "           [ 2.4010e-02,  1.5178e-02,  1.3669e-03]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[ 2.7928e-03,  2.2522e-02, -3.9708e-02],\n",
      "           [ 3.4427e-02,  7.4609e-03, -3.4785e-02],\n",
      "           [-6.0091e-03, -2.5305e-03,  9.4726e-03]],\n",
      "\n",
      "          [[ 3.7583e-02, -1.3157e-02, -3.9002e-03],\n",
      "           [ 5.2786e-02,  5.4568e-03, -8.3690e-03],\n",
      "           [-1.1338e-02,  3.8647e-02,  3.5400e-03]],\n",
      "\n",
      "          [[ 9.5648e-03,  7.3650e-03, -2.3283e-02],\n",
      "           [ 5.7295e-03, -2.0706e-02,  1.9742e-02],\n",
      "           [-2.5704e-02,  8.9659e-03, -1.7921e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.4161e-02,  2.9499e-02, -1.8890e-03],\n",
      "           [ 3.0890e-03,  1.9117e-02, -2.6344e-02],\n",
      "           [ 2.3270e-02,  8.4049e-03, -3.2972e-02]],\n",
      "\n",
      "          [[-3.5385e-02,  7.8244e-03,  2.5308e-02],\n",
      "           [-4.7999e-02, -9.3519e-04, -3.2535e-02],\n",
      "           [-8.6501e-03,  1.8910e-02, -2.1443e-02]],\n",
      "\n",
      "          [[-2.6541e-02,  1.8934e-02,  5.8015e-03],\n",
      "           [-4.4852e-03, -2.8674e-02, -1.3668e-02],\n",
      "           [-2.5228e-02,  2.1228e-02,  5.0554e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.7350e-02,  8.8100e-03,  9.7268e-03],\n",
      "           [ 2.5371e-02,  1.3127e-02, -2.9318e-02],\n",
      "           [-9.3476e-03, -7.2785e-03, -2.5018e-02]],\n",
      "\n",
      "          [[-6.7807e-03, -7.1536e-03, -2.8025e-03],\n",
      "           [-1.9850e-02,  2.7472e-02,  1.0169e-02],\n",
      "           [ 2.0272e-02,  2.0570e-02,  8.0542e-03]],\n",
      "\n",
      "          [[-2.5911e-02, -3.1426e-02, -1.7441e-02],\n",
      "           [-8.6375e-03,  3.6914e-02,  7.7337e-03],\n",
      "           [-3.5469e-02,  4.1200e-03, -2.9283e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.6318e-03, -5.7498e-03,  2.6981e-02],\n",
      "           [ 1.2546e-02, -2.9789e-02, -1.2387e-03],\n",
      "           [ 1.2886e-02, -4.7860e-02, -1.3502e-02]],\n",
      "\n",
      "          [[-7.0516e-03,  2.6150e-02, -3.4648e-02],\n",
      "           [-1.7817e-02,  5.2542e-02,  2.4820e-02],\n",
      "           [ 1.5499e-03,  1.8457e-02,  1.5060e-04]],\n",
      "\n",
      "          [[-2.8465e-02, -2.9614e-03, -6.0057e-02],\n",
      "           [ 2.4973e-02,  1.9285e-02, -1.4262e-02],\n",
      "           [-7.9807e-03, -1.8727e-02,  8.5080e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2683e-02, -1.9671e-02, -2.7991e-02],\n",
      "           [-5.5005e-03,  9.7745e-03,  6.2107e-02],\n",
      "           [ 1.1642e-02, -9.4437e-03,  2.1780e-04]],\n",
      "\n",
      "          [[ 9.8821e-03, -1.5999e-02,  7.7706e-03],\n",
      "           [-3.8782e-02,  8.5066e-03, -3.6908e-02],\n",
      "           [ 2.7042e-02, -3.0300e-02, -2.6441e-02]],\n",
      "\n",
      "          [[ 4.3872e-02,  7.8095e-03, -2.6182e-02],\n",
      "           [ 8.4259e-04, -3.2556e-03, -1.1766e-02],\n",
      "           [-2.2251e-02, -9.5830e-03,  4.3930e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.2179e-03, -1.7308e-02, -3.3574e-03],\n",
      "           [-4.8510e-03, -1.5570e-02,  3.1365e-03],\n",
      "           [ 1.9598e-03,  7.9595e-03,  2.6508e-02]],\n",
      "\n",
      "          [[ 1.6729e-02,  1.5902e-02,  2.1866e-02],\n",
      "           [-1.5566e-02,  1.7033e-02, -1.4271e-02],\n",
      "           [-1.8323e-02, -5.7526e-03, -3.4958e-02]],\n",
      "\n",
      "          [[-3.3292e-02, -2.0539e-02,  4.5307e-02],\n",
      "           [ 3.7218e-02, -5.4822e-02,  3.6782e-02],\n",
      "           [ 2.5939e-02, -2.9610e-02, -1.8894e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.5880e-02, -1.6855e-02, -2.1625e-02],\n",
      "           [ 3.2736e-02, -3.7131e-02, -2.2461e-02],\n",
      "           [-2.0140e-02,  9.6168e-03, -2.4390e-03]],\n",
      "\n",
      "          [[-1.3292e-02, -1.8150e-02,  1.2634e-02],\n",
      "           [-1.2236e-03,  9.3362e-03, -6.6363e-03],\n",
      "           [ 2.8923e-03,  1.7979e-02, -6.1937e-05]],\n",
      "\n",
      "          [[ 3.0405e-02,  3.1841e-02,  1.4480e-03],\n",
      "           [ 2.9165e-02,  1.0681e-03, -8.9469e-03],\n",
      "           [ 8.7189e-03,  1.6594e-03, -4.1677e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.3043e-02, -2.2932e-02,  3.1636e-02],\n",
      "           [-3.6545e-02,  1.6371e-02,  3.6397e-02],\n",
      "           [-4.2495e-03, -2.4525e-03,  2.4480e-02]],\n",
      "\n",
      "          [[-2.1571e-02,  2.6570e-02,  1.0809e-02],\n",
      "           [-5.3739e-03, -3.7520e-02, -4.5338e-04],\n",
      "           [ 6.5237e-03,  1.6988e-02, -5.7371e-04]],\n",
      "\n",
      "          [[-3.0688e-02, -4.8214e-03,  6.3010e-03],\n",
      "           [-2.9014e-03,  1.2486e-02,  1.0582e-02],\n",
      "           [ 1.7360e-02,  2.3964e-02, -3.0016e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2955e-02,  1.6962e-02,  1.1856e-02],\n",
      "           [ 7.5810e-03,  4.2109e-02,  1.4235e-02],\n",
      "           [ 3.0700e-02, -1.9566e-02,  2.8204e-02]],\n",
      "\n",
      "          [[-1.7043e-02,  1.9691e-02, -3.8383e-03],\n",
      "           [ 3.7200e-03,  1.1719e-03,  6.8374e-03],\n",
      "           [ 1.5248e-02, -1.8933e-02, -6.3405e-02]],\n",
      "\n",
      "          [[-1.0915e-03,  2.4453e-02, -3.7154e-02],\n",
      "           [ 3.5440e-02, -4.2584e-02,  2.6611e-02],\n",
      "           [ 4.0819e-02,  4.5693e-02,  1.7994e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.4314e-02, -7.4323e-03, -7.2184e-03],\n",
      "           [-2.9759e-03,  2.0550e-02, -1.4450e-02],\n",
      "           [ 4.0935e-03,  3.9844e-02, -1.0284e-02]],\n",
      "\n",
      "          [[ 1.7244e-02,  3.4716e-02,  6.5167e-03],\n",
      "           [-6.6342e-03, -1.5023e-02,  3.6839e-03],\n",
      "           [-2.2958e-02, -5.4418e-03, -6.5882e-03]],\n",
      "\n",
      "          [[-4.4233e-02, -8.5418e-03,  8.5556e-03],\n",
      "           [-4.8174e-02, -2.3831e-02,  2.6641e-03],\n",
      "           [ 9.5891e-03, -1.9379e-02,  2.5498e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3306e-02,  1.2460e-02, -2.3581e-02],\n",
      "           [-1.3443e-02, -2.8423e-02, -1.0329e-02],\n",
      "           [ 1.8117e-02,  2.1478e-03,  2.5994e-03]],\n",
      "\n",
      "          [[-3.5306e-02, -2.0228e-02,  2.8187e-02],\n",
      "           [-4.6330e-04, -1.8792e-03,  2.5264e-02],\n",
      "           [-8.5381e-03,  2.1471e-02, -1.0343e-02]],\n",
      "\n",
      "          [[-4.3854e-02,  2.7669e-02, -8.2991e-03],\n",
      "           [ 6.3124e-03, -1.6739e-02,  1.1695e-02],\n",
      "           [-5.1286e-03, -1.6788e-02, -2.2339e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.2417e-03,  8.1466e-03,  1.9395e-02],\n",
      "           [ 5.3267e-03, -3.0380e-02, -8.6758e-03],\n",
      "           [-3.2409e-02,  3.4474e-03,  2.5470e-02]],\n",
      "\n",
      "          [[-6.2229e-03, -8.4182e-04, -3.2300e-02],\n",
      "           [-2.0275e-02, -3.6069e-02,  1.4953e-02],\n",
      "           [ 5.2205e-02, -8.1219e-03,  2.8069e-02]],\n",
      "\n",
      "          [[-2.6910e-03, -2.7339e-02,  3.1754e-02],\n",
      "           [-5.5111e-02, -2.2682e-03, -2.1616e-02],\n",
      "           [ 1.2173e-04,  2.6756e-02, -6.9132e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.7782e-02,  1.0945e-02, -1.7783e-02],\n",
      "           [-1.5572e-02,  1.1993e-02,  2.1087e-02],\n",
      "           [ 3.4340e-02,  6.7464e-03, -2.6570e-02]],\n",
      "\n",
      "          [[-4.7858e-02, -6.6862e-03, -5.8735e-03],\n",
      "           [-5.5695e-03, -1.6844e-02, -2.7914e-02],\n",
      "           [-2.3590e-03,  2.0814e-02, -8.9439e-04]],\n",
      "\n",
      "          [[-9.8357e-03, -2.3851e-02,  5.3886e-02],\n",
      "           [ 7.9584e-04,  3.2683e-02, -4.6963e-02],\n",
      "           [ 1.6965e-02,  1.8848e-03,  3.4608e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.9581e-02,  1.9529e-02, -1.6006e-02],\n",
      "           [ 1.1908e-02,  1.0447e-02,  2.3497e-02],\n",
      "           [ 2.5269e-03,  1.0239e-02,  1.2586e-03]],\n",
      "\n",
      "          [[ 3.6463e-02, -3.6066e-03,  2.4030e-02],\n",
      "           [ 4.0147e-04,  2.2145e-02, -2.7198e-02],\n",
      "           [ 3.7821e-02, -5.1735e-03,  3.8201e-02]],\n",
      "\n",
      "          [[-2.8162e-02, -3.4251e-02,  2.8488e-02],\n",
      "           [ 2.6637e-02,  2.4650e-03,  2.7702e-03],\n",
      "           [ 2.3219e-03,  6.0558e-03,  1.5750e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.8844e-02,  5.6250e-04, -3.9281e-03],\n",
      "           [-3.0759e-02, -6.2306e-04, -1.2563e-05],\n",
      "           [-2.1677e-02,  1.1263e-02,  8.0109e-03]],\n",
      "\n",
      "          [[-7.3976e-03, -4.2160e-02, -8.9768e-03],\n",
      "           [ 2.7148e-03,  2.4243e-02,  4.0025e-02],\n",
      "           [ 2.2321e-02, -2.7336e-03,  2.4640e-02]],\n",
      "\n",
      "          [[ 3.8397e-02,  3.1887e-02,  3.6516e-03],\n",
      "           [ 2.7457e-02,  2.6181e-02, -7.1694e-02],\n",
      "           [ 2.2817e-02,  5.6623e-03,  6.3059e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.6606e-02, -3.5014e-02,  4.3999e-03],\n",
      "           [ 1.0311e-02,  3.1180e-02, -3.2104e-02],\n",
      "           [ 8.6237e-03, -1.2053e-03, -9.8201e-03]],\n",
      "\n",
      "          [[-4.2039e-02,  1.7448e-02, -8.5059e-03],\n",
      "           [ 2.2602e-03,  3.4574e-02,  1.8597e-02],\n",
      "           [ 3.1487e-02, -2.4296e-04,  2.4869e-02]],\n",
      "\n",
      "          [[-1.6112e-02, -2.9965e-02,  6.7953e-02],\n",
      "           [ 1.3600e-02,  7.0546e-03, -2.1911e-02],\n",
      "           [ 5.0830e-03,  1.5775e-02, -2.2184e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8458e-02, -3.0744e-02,  1.7931e-02],\n",
      "           [ 1.3835e-02, -1.1028e-02,  3.4594e-02],\n",
      "           [ 1.3264e-03, -2.9342e-02, -8.7330e-03]],\n",
      "\n",
      "          [[ 2.5265e-02, -1.3390e-03, -1.9396e-02],\n",
      "           [ 2.0280e-02, -1.2383e-02, -7.7990e-03],\n",
      "           [ 3.3517e-02,  2.3933e-02, -1.7956e-02]],\n",
      "\n",
      "          [[-1.9000e-02,  2.0814e-02, -1.2729e-02],\n",
      "           [ 1.9959e-02, -2.7179e-02, -3.5799e-02],\n",
      "           [-8.8679e-03, -2.0770e-02,  1.7742e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1276e-02, -1.0296e-02,  2.1795e-02],\n",
      "           [ 3.7330e-02, -2.8020e-02, -2.3194e-03],\n",
      "           [-6.8229e-03, -5.3791e-02,  1.3564e-03]],\n",
      "\n",
      "          [[ 1.3004e-02,  2.0473e-02,  1.9155e-02],\n",
      "           [-2.2443e-02,  8.9096e-03,  3.6663e-03],\n",
      "           [ 2.6479e-02,  1.1600e-02, -7.4707e-02]],\n",
      "\n",
      "          [[ 2.2792e-02, -6.6978e-03, -1.1008e-02],\n",
      "           [-1.7948e-02,  2.1041e-02,  4.0254e-02],\n",
      "           [ 1.2286e-02, -1.7648e-02, -4.0083e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.4703e-03, -2.9597e-02,  5.7544e-02],\n",
      "           [ 2.7098e-02, -1.8656e-02,  3.7009e-02],\n",
      "           [ 1.2582e-02, -3.5361e-03, -1.5283e-03]],\n",
      "\n",
      "          [[ 1.3443e-02,  2.0170e-03,  3.7285e-02],\n",
      "           [ 3.1228e-02, -4.6954e-02,  2.8808e-02],\n",
      "           [-4.6685e-02,  3.6699e-03,  1.8590e-04]],\n",
      "\n",
      "          [[-2.7000e-02, -2.2111e-02, -1.6108e-02],\n",
      "           [ 1.4800e-02,  7.5157e-03,  2.6369e-02],\n",
      "           [ 2.3474e-02, -1.5681e-02, -3.2924e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6453e-02,  8.6548e-03, -3.8617e-02],\n",
      "           [-1.2197e-02, -4.7651e-02, -6.0122e-03],\n",
      "           [ 1.7245e-02, -2.7245e-02,  1.8745e-02]],\n",
      "\n",
      "          [[-6.3637e-03,  6.7409e-03,  9.4026e-03],\n",
      "           [-4.6175e-03,  5.1671e-03, -8.3778e-04],\n",
      "           [ 5.1739e-03, -6.8695e-03, -5.9434e-03]],\n",
      "\n",
      "          [[ 1.7575e-02,  1.4712e-02, -2.1884e-02],\n",
      "           [-3.3414e-03,  1.5828e-03,  8.4741e-03],\n",
      "           [-8.5902e-03, -2.6723e-02,  5.6241e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.6654e-03,  2.1941e-02, -1.6241e-02],\n",
      "           [-4.5985e-02, -4.2488e-02,  5.5685e-04],\n",
      "           [-2.9811e-02, -2.9591e-02,  1.4120e-02]],\n",
      "\n",
      "          [[-1.9580e-02, -8.3299e-03,  4.2209e-02],\n",
      "           [-2.7685e-02,  2.6757e-02,  3.6400e-02],\n",
      "           [-8.5889e-03,  3.6733e-02, -2.9325e-04]],\n",
      "\n",
      "          [[ 2.0749e-03,  4.5609e-03,  6.5416e-02],\n",
      "           [ 1.9627e-02, -3.6743e-02,  8.8514e-03],\n",
      "           [ 1.0742e-02,  6.4872e-03, -1.5153e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.0858e-02, -5.0756e-02,  1.2638e-02],\n",
      "           [ 2.5374e-02,  3.2925e-02,  2.0421e-02],\n",
      "           [ 5.2407e-02, -2.3499e-02,  4.3118e-02]],\n",
      "\n",
      "          [[-2.2972e-02, -6.8599e-03,  1.9344e-02],\n",
      "           [-5.0529e-03, -5.0829e-02,  1.2451e-04],\n",
      "           [-8.7184e-02,  3.4378e-03, -2.3911e-02]],\n",
      "\n",
      "          [[ 4.4896e-03, -2.5530e-02, -1.2813e-02],\n",
      "           [-3.7996e-02,  4.4890e-03,  2.7753e-02],\n",
      "           [-6.3371e-03,  7.9049e-03, -1.7672e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7435e-02, -2.6834e-02,  8.1148e-03],\n",
      "           [-4.2201e-02, -5.0935e-03, -3.9180e-02],\n",
      "           [-2.8560e-02, -1.8553e-03,  2.1154e-02]],\n",
      "\n",
      "          [[-1.4497e-02,  2.0515e-02,  7.8584e-03],\n",
      "           [-1.1382e-02,  6.3842e-04, -2.6016e-02],\n",
      "           [-2.0830e-02, -1.7550e-02,  2.1880e-02]],\n",
      "\n",
      "          [[ 4.8681e-02, -2.0846e-02,  1.4117e-02],\n",
      "           [ 4.4925e-02,  3.5888e-02,  1.8856e-03],\n",
      "           [ 5.5824e-03,  5.2343e-02,  1.5962e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.0136e-03, -5.8454e-04,  5.8800e-02],\n",
      "           [-2.0600e-02, -4.2652e-02,  4.4218e-03],\n",
      "           [-1.0841e-02,  7.7447e-03,  9.0916e-03]],\n",
      "\n",
      "          [[-2.2522e-02,  4.7479e-03,  1.0573e-02],\n",
      "           [ 3.8468e-02, -1.9258e-02, -4.7211e-02],\n",
      "           [-5.7402e-03, -1.5113e-02, -8.9800e-04]],\n",
      "\n",
      "          [[-2.3991e-02, -4.6114e-03,  3.1782e-02],\n",
      "           [-1.4022e-02, -4.0601e-03,  2.9115e-02],\n",
      "           [-1.5350e-02, -1.7778e-02,  1.9477e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.0787e-04, -6.0490e-03, -3.0913e-02],\n",
      "           [-9.4168e-03,  4.0354e-03, -4.6075e-02],\n",
      "           [ 2.1125e-02,  2.2101e-02,  1.0825e-03]],\n",
      "\n",
      "          [[ 5.9904e-03,  6.9934e-03,  1.3435e-02],\n",
      "           [ 1.1919e-02, -6.3372e-03, -1.9967e-02],\n",
      "           [-1.6939e-02,  2.6473e-03,  1.3056e-03]],\n",
      "\n",
      "          [[ 1.1014e-02,  2.5755e-02,  1.5770e-02],\n",
      "           [ 1.4634e-02,  1.4679e-03, -1.3056e-02],\n",
      "           [ 2.7531e-02, -1.4370e-02,  8.8555e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.6642e-02, -3.0661e-02,  1.0577e-02],\n",
      "           [ 1.5525e-02,  2.7033e-02,  2.6179e-02],\n",
      "           [ 9.5292e-03, -3.6318e-02, -3.5078e-02]],\n",
      "\n",
      "          [[ 9.5537e-03, -3.8500e-02, -1.0265e-02],\n",
      "           [-4.4477e-02,  2.4230e-02,  2.6921e-02],\n",
      "           [-2.8446e-02, -2.0311e-02,  2.3657e-02]],\n",
      "\n",
      "          [[-1.3164e-02,  5.7086e-02,  3.0532e-02],\n",
      "           [-2.3750e-02,  2.1415e-02,  3.8545e-02],\n",
      "           [ 3.3053e-02,  2.4918e-03,  3.0070e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7936e-02,  1.1033e-02, -1.2607e-02],\n",
      "           [ 2.6446e-02,  3.2656e-03,  5.2379e-02],\n",
      "           [ 2.4340e-02,  3.9055e-02,  2.0469e-02]],\n",
      "\n",
      "          [[-2.6836e-02, -2.8678e-02, -1.8013e-02],\n",
      "           [-2.0911e-02,  1.3712e-02,  1.0104e-02],\n",
      "           [ 1.8966e-02,  2.5130e-02, -5.1840e-02]],\n",
      "\n",
      "          [[-3.4164e-03, -2.6059e-02,  3.0846e-02],\n",
      "           [ 3.3782e-02, -6.4489e-03, -9.5141e-03],\n",
      "           [ 4.5314e-02,  4.1268e-02, -1.9836e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.6420e-02,  1.9250e-02,  8.0847e-03],\n",
      "           [ 1.0345e-02,  8.5916e-03,  1.0021e-02],\n",
      "           [ 5.7693e-03,  2.0806e-02,  2.0767e-02]],\n",
      "\n",
      "          [[-8.6367e-03,  1.5448e-02,  1.1353e-02],\n",
      "           [ 1.1904e-02, -1.0285e-02, -1.3059e-03],\n",
      "           [ 1.4341e-02, -3.5200e-03,  3.0468e-02]],\n",
      "\n",
      "          [[ 2.8129e-02,  2.5999e-02,  2.4633e-02],\n",
      "           [ 1.0913e-03, -2.8498e-02, -6.5240e-04],\n",
      "           [-4.4144e-02, -3.6033e-02, -5.8040e-02]]],\n",
      "\n",
      "\n",
      "         [[[-8.4966e-04, -1.6139e-02, -5.3088e-03],\n",
      "           [ 1.0282e-02,  7.6586e-03, -1.7582e-02],\n",
      "           [-5.2292e-02,  1.0910e-02, -1.5958e-02]],\n",
      "\n",
      "          [[-2.3973e-03,  3.8213e-02, -1.2072e-02],\n",
      "           [ 1.7799e-02, -4.5843e-02,  8.2688e-03],\n",
      "           [ 9.9529e-03,  4.1562e-02, -2.5498e-02]],\n",
      "\n",
      "          [[-1.0094e-02,  2.8286e-02, -8.9168e-03],\n",
      "           [-1.2320e-02, -2.8788e-02,  1.0962e-02],\n",
      "           [ 8.7901e-04,  7.3121e-03, -5.8841e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5809e-02,  5.5892e-03, -4.2715e-02],\n",
      "           [-2.0595e-02,  2.8793e-03, -1.1299e-02],\n",
      "           [ 1.7610e-02, -1.6768e-02, -6.8868e-03]],\n",
      "\n",
      "          [[ 4.8875e-02, -1.4699e-02,  6.0155e-03],\n",
      "           [-4.3140e-03, -1.0825e-02,  1.2946e-03],\n",
      "           [ 4.6107e-02, -1.6702e-02,  1.5862e-02]],\n",
      "\n",
      "          [[ 5.2843e-02, -8.8952e-04, -2.6304e-02],\n",
      "           [-2.7854e-02, -4.4556e-03,  1.1257e-02],\n",
      "           [ 3.1604e-02,  1.2743e-02,  3.5242e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.9013e-02, -9.1983e-03,  4.6170e-02],\n",
      "           [-1.6853e-02, -4.6025e-04,  1.7592e-02],\n",
      "           [ 1.9301e-02, -8.3665e-04, -3.0473e-02]],\n",
      "\n",
      "          [[ 3.7778e-02, -2.1014e-02, -2.4970e-02],\n",
      "           [-4.2616e-02,  5.3247e-03, -4.2049e-04],\n",
      "           [ 3.8502e-03, -9.5946e-03, -1.3045e-02]],\n",
      "\n",
      "          [[ 2.5867e-02,  3.4782e-02, -3.2924e-02],\n",
      "           [ 7.5411e-03, -2.3406e-02, -2.8290e-02],\n",
      "           [-1.2119e-02, -2.8561e-02,  1.6723e-04]]],\n",
      "\n",
      "\n",
      "         [[[-1.5330e-02, -4.1505e-03, -1.1861e-02],\n",
      "           [-1.4425e-02, -1.0275e-02,  3.0984e-02],\n",
      "           [ 9.5316e-04, -2.6266e-02, -7.8955e-03]],\n",
      "\n",
      "          [[-2.6136e-02, -2.2964e-02,  2.2816e-03],\n",
      "           [-2.9885e-03,  3.2124e-03, -1.2784e-02],\n",
      "           [-3.6840e-03, -2.3463e-04,  2.9782e-02]],\n",
      "\n",
      "          [[-1.6388e-02,  3.4699e-02, -3.9954e-02],\n",
      "           [-2.8584e-03, -3.3283e-03, -2.7160e-02],\n",
      "           [ 1.5683e-02,  3.0323e-02,  1.8023e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.4393e-03,  3.8232e-02,  5.4261e-03],\n",
      "           [ 1.5829e-03,  2.4970e-02,  1.6094e-02],\n",
      "           [ 1.1503e-02, -1.5445e-02,  4.1056e-02]],\n",
      "\n",
      "          [[-4.8029e-02,  3.4419e-02, -1.2265e-02],\n",
      "           [ 1.5449e-02, -1.8443e-02, -1.7379e-02],\n",
      "           [ 5.9756e-03, -2.3617e-02,  3.5154e-02]],\n",
      "\n",
      "          [[-2.0351e-02, -3.0530e-02,  1.9759e-02],\n",
      "           [ 1.3227e-02,  1.2993e-02,  1.8331e-03],\n",
      "           [-3.1366e-02,  2.4180e-02,  9.1818e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 9.6130e-03, -2.5553e-03, -1.5204e-02],\n",
      "           [-6.3704e-03, -2.6133e-02,  5.6494e-02],\n",
      "           [ 1.3517e-02,  7.3349e-03,  4.2259e-03]],\n",
      "\n",
      "          [[ 3.2601e-03, -1.4165e-02, -3.2445e-02],\n",
      "           [ 8.0991e-02, -2.9479e-03, -1.9513e-02],\n",
      "           [-1.6521e-02, -1.3095e-02, -3.5508e-02]],\n",
      "\n",
      "          [[-6.0378e-03,  4.0645e-02,  5.8367e-02],\n",
      "           [-2.0437e-02, -2.2365e-03,  1.8784e-02],\n",
      "           [-1.8807e-02, -1.4580e-02, -3.7022e-02]]],\n",
      "\n",
      "\n",
      "         [[[-9.1563e-03,  9.6410e-03, -2.8178e-02],\n",
      "           [-2.1790e-02,  5.0892e-03,  2.6178e-02],\n",
      "           [-4.8763e-02,  1.6444e-02, -4.4649e-02]],\n",
      "\n",
      "          [[-8.1537e-03,  2.3187e-02,  1.6562e-02],\n",
      "           [-3.5468e-02, -1.3163e-02,  3.0858e-03],\n",
      "           [ 1.9882e-02, -7.2715e-04,  1.3732e-02]],\n",
      "\n",
      "          [[ 5.6389e-02,  3.3652e-02, -1.4248e-02],\n",
      "           [-2.7238e-02,  9.4119e-03, -5.2589e-03],\n",
      "           [-1.3538e-03,  2.9328e-02,  3.7577e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2965e-02,  1.6391e-02,  8.5324e-03],\n",
      "           [-9.0587e-04,  1.7464e-02, -1.7861e-02],\n",
      "           [ 2.8476e-02,  1.2840e-02,  4.0287e-03]],\n",
      "\n",
      "          [[ 2.5343e-02, -5.5599e-02,  1.9767e-03],\n",
      "           [ 2.3054e-02,  2.5465e-03,  2.0130e-02],\n",
      "           [ 1.9374e-02,  1.9363e-02, -1.8760e-02]],\n",
      "\n",
      "          [[-4.6164e-03,  1.6796e-02, -2.1489e-02],\n",
      "           [-2.2601e-02, -1.0134e-02,  9.4279e-03],\n",
      "           [-3.5826e-02,  2.3028e-02,  7.9441e-03]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[-0.2368]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1804]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2429]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.1530]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2223]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0412]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1150]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0279]]],\n",
      "\n",
      "\n",
      "         [[[-0.1561]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0893]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0699]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0269]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0707]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0966]]],\n",
      "\n",
      "\n",
      "         [[[-0.0697]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.1485]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1214]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2679]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0539]]],\n",
      "\n",
      "\n",
      "         [[[-0.0844]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1434]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.1092]]],\n",
      "\n",
      "\n",
      "         [[[-0.0483]]],\n",
      "\n",
      "\n",
      "         [[[-0.0467]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0195]]],\n",
      "\n",
      "\n",
      "         [[[-0.2177]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0266]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0868]]],\n",
      "\n",
      "\n",
      "         [[[-0.0075]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1845]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0677]]],\n",
      "\n",
      "\n",
      "         [[[-0.1309]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0383]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.1616]]],\n",
      "\n",
      "\n",
      "         [[[-0.0574]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1468]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.1647e-01,  9.7009e-02, -4.4074e-02,  7.6474e-02, -5.5278e-02,\n",
      "        -4.4303e-02,  1.1380e-01,  7.5517e-02, -4.0688e-02,  7.0678e-02,\n",
      "        -6.7348e-02,  4.3592e-02,  5.9780e-02, -1.1564e-01,  4.7081e-02,\n",
      "        -1.2575e-04,  9.4032e-02,  5.8911e-03,  8.8678e-02, -6.3993e-03,\n",
      "        -3.9884e-02, -1.8880e-02, -5.7309e-02, -6.3236e-02, -7.4015e-02,\n",
      "        -1.1380e-01, -6.5575e-02, -1.0158e-01,  6.2171e-02, -4.8371e-02,\n",
      "        -1.0397e-01,  5.6400e-03,  6.7858e-02,  9.4548e-02, -7.9025e-02,\n",
      "         1.2268e-01, -3.8443e-02, -3.3367e-02, -8.6771e-02,  4.2482e-02,\n",
      "        -4.2079e-02,  1.1264e-01, -1.0996e-01, -3.4113e-02, -2.3826e-02,\n",
      "         8.6117e-02, -3.5192e-02, -9.7530e-02,  2.8423e-02,  3.9129e-02,\n",
      "         5.1738e-02,  6.3401e-02,  5.8617e-02,  3.3638e-02,  7.6162e-03,\n",
      "         5.2478e-02,  2.3232e-02, -5.5519e-02, -4.4250e-02,  8.8939e-02,\n",
      "         6.3292e-02,  9.9756e-02, -1.3679e-02,  2.0270e-02, -1.1078e-04,\n",
      "         5.3575e-03, -5.7867e-02,  6.2454e-02, -7.8598e-02,  6.8173e-02,\n",
      "         1.1388e-01, -9.4744e-02, -9.1964e-02, -1.0814e-01, -8.7176e-03,\n",
      "        -5.9401e-02,  1.1089e-02,  5.3026e-02,  1.0122e-01,  9.4538e-03,\n",
      "        -1.0193e-01,  3.4813e-02,  1.5974e-02, -4.1476e-02, -3.8915e-02,\n",
      "        -1.7105e-02,  1.1203e-01,  1.7748e-02, -1.2073e-01, -6.5328e-04,\n",
      "        -5.6585e-02, -9.4303e-02, -3.4745e-02, -7.4337e-02, -7.0164e-02,\n",
      "         5.5841e-02,  6.9000e-02,  3.8601e-02,  1.0596e-01, -2.7918e-02,\n",
      "        -1.5736e-02, -3.0116e-02, -3.1028e-03, -3.6966e-02,  2.5462e-02,\n",
      "         6.2518e-02,  5.6533e-03, -2.5405e-03,  8.1192e-02,  5.3680e-02,\n",
      "         2.2761e-02,  4.4135e-02, -6.4928e-02, -7.8997e-02, -1.4956e-02,\n",
      "         2.2486e-02,  4.6201e-02,  3.1986e-02,  7.4765e-02,  8.5710e-02,\n",
      "        -8.0203e-02,  1.2909e-02,  1.1740e-01, -1.4354e-02,  4.1353e-02,\n",
      "        -3.3103e-02,  7.4604e-03, -7.3294e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0614,  0.0659, -0.0478,  ..., -0.0235,  0.0259,  0.0356],\n",
      "        [ 0.0173,  0.0055, -0.0220,  ..., -0.0883, -0.0485,  0.0515],\n",
      "        [ 0.0787,  0.0489,  0.0026,  ...,  0.0073, -0.0809,  0.0638],\n",
      "        ...,\n",
      "        [-0.0448,  0.0643, -0.0260,  ..., -0.0631,  0.0697, -0.0468],\n",
      "        [-0.0102,  0.0607,  0.0033,  ...,  0.0772,  0.0549,  0.0570],\n",
      "        [-0.0028, -0.0130,  0.0307,  ..., -0.0773, -0.0452, -0.0241]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 32, 64, 128] shit\n",
      "666666666666\n",
      "[ResNetBlock(\n",
      "  (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "  (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "  (bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")] this is layers\n",
      "666666666666\n",
      "[ResNetBlock(\n",
      "  (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "  (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "  (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")] this is layers\n",
      "666666666666\n",
      "[ResNetBlock(\n",
      "  (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "  (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")] this is layers\n",
      "666666666666\n",
      "[ResNetBlock(\n",
      "  (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "  (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "  (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")] this is layers\n"
     ]
    }
   ],
   "source": [
    "max_pool_test = torch.rand((1,1,30,256,256,))\n",
    "model = ResNet(ResNetBlock, [1, 1, 1, 1],get_inplanes(),spatial_dims=3,n_input_channels=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 30, 256, 256])\n",
      "torch.Size([1, 16, 30, 256, 256])\n",
      "run layer1\n",
      "None before downsample! torch.Size([1, 16, 15, 128, 128])\n",
      "after layer1 torch.Size([1, 16, 15, 128, 128])\n",
      "Sequential(\n",
      "  (0): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 32, 8, 64, 64])\n",
      "downsample!\n",
      "torch.Size([1, 32, 8, 64, 64]) after downsample!\n",
      "after layer2 torch.Size([1, 32, 8, 64, 64])\n",
      "Sequential(\n",
      "  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 64, 4, 32, 32])\n",
      "downsample!\n",
      "torch.Size([1, 64, 4, 32, 32]) after downsample!\n",
      "after layer3 torch.Size([1, 64, 4, 32, 32])\n",
      "Sequential(\n",
      "  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 128, 2, 16, 16])\n",
      "downsample!\n",
      "torch.Size([1, 128, 2, 16, 16]) after downsample!\n",
      "torch.Size([1, 128, 2, 16, 16]) this is x shape\n",
      "use SA block!\n",
      "this is v_x shape torch.Size([1, 128, 2, 16, 16])\n",
      "torch.Size([1, 128, 16, 2, 16]) this is Patt shape\n",
      "torch.Size([1, 128, 2, 16, 1, 16]) this is k_x_flatten shape\n",
      "torch.Size([1, 128, 2, 16, 16, 1]) this is q_x_flatten shape\n",
      "torch.Size([1, 128, 2, 16, 16, 16]) this is sigma_x shape\n",
      "torch.Size([1, 128, 16, 2, 16]) this is Patt shape torch.Size([1, 128, 16, 2, 16]) this is Datt shape\n",
      "after layer4 torch.Size([1, 128, 2, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9765e-01, -1.4284e-01,  1.5993e-02,  2.6331e-01,  2.8392e-01,\n",
       "          4.2128e-01, -2.7784e-01, -2.2856e-01, -3.4562e-01, -2.1264e-02,\n",
       "         -4.2272e-01,  3.2272e-01, -1.0220e-01,  3.7331e-01,  1.7065e-02,\n",
       "          4.9441e-02,  1.3540e-01,  2.4895e-01,  5.7697e-02, -1.6516e-01,\n",
       "         -2.4780e-02,  2.4781e-01,  3.0479e-01,  8.5140e-01, -2.7400e-01,\n",
       "         -5.4281e-01,  1.6444e-01, -2.8587e-01,  2.8384e-01,  9.4023e-02,\n",
       "          1.2418e-01, -7.7897e-02,  4.1452e-01,  2.3462e-01,  2.1504e-02,\n",
       "          3.5271e-01, -6.3891e-01,  6.0549e-01, -3.2324e-01, -6.2279e-01,\n",
       "          3.0696e-01,  1.0150e-01,  5.9606e-02, -2.7748e-01, -3.6840e-01,\n",
       "         -4.8625e-01, -3.5784e-01, -2.4102e-02,  2.5915e-01, -2.3036e-02,\n",
       "          4.0832e-01,  1.4282e-02, -5.3106e-02, -9.4535e-02, -2.4352e-01,\n",
       "         -2.2722e-02, -3.3510e-01, -3.4543e-02,  1.4460e-01,  7.4946e-02,\n",
       "          3.1900e-01, -4.6348e-02, -4.9639e-01, -2.0566e-01,  8.6543e-02,\n",
       "         -1.2756e-01,  3.6770e-01,  1.3560e-01,  1.5805e-02,  3.1191e-01,\n",
       "         -2.7328e-01,  1.5430e-02, -1.5317e-01,  2.0969e-01, -5.6331e-01,\n",
       "         -1.1731e-01,  2.2707e-01,  7.3777e-02,  2.9382e-01, -2.0073e-01,\n",
       "         -1.8894e-01,  3.4356e-01, -1.6531e-01, -6.2088e-01, -4.0929e-02,\n",
       "         -8.3983e-02, -4.3846e-01,  2.9246e-01, -5.9441e-01, -5.1955e-01,\n",
       "         -1.3507e-02,  4.3322e-01,  5.9649e-01, -4.7670e-01,  1.3477e-01,\n",
       "          6.5448e-01, -1.9651e-01,  3.8475e-01, -3.0563e-01, -5.6787e-02,\n",
       "         -1.1079e-01,  5.2686e-01,  5.6552e-01,  4.8352e-02,  7.9147e-02,\n",
       "         -3.0073e-01,  2.2050e-02,  1.8339e-02, -1.7022e-01,  4.1708e-01,\n",
       "         -6.1528e-02,  6.6097e-02,  2.7083e-01,  3.5691e-01, -5.7088e-02,\n",
       "         -3.3202e-01, -5.5269e-02, -1.8250e-02, -5.3538e-01,  4.3817e-01,\n",
       "          2.5752e-01,  1.6989e-01, -2.3641e-02,  2.5039e-01,  5.9753e-01,\n",
       "         -6.6396e-02,  3.4899e-01,  1.3941e-01,  2.7953e-01,  6.1154e-01,\n",
       "         -3.8812e-01,  1.9860e-01, -3.7093e-02, -3.1915e-01, -2.6347e-01,\n",
       "         -2.1077e-01, -3.3880e-01,  8.2928e-01, -1.8218e-01, -1.0391e-01,\n",
       "          3.2509e-01,  3.5178e-01,  1.4481e-01, -6.3129e-01, -5.0082e-01,\n",
       "          2.8200e-02,  4.6684e-01,  3.8014e-01, -8.9307e-02,  4.8423e-01,\n",
       "          5.4635e-01,  4.8423e-01, -6.3877e-01, -1.3399e-01,  1.2647e-01,\n",
       "          6.5666e-01,  2.1811e-01,  5.4129e-01, -4.2244e-01,  1.9549e-02,\n",
       "          2.7369e-02, -2.2075e-01,  4.5568e-01, -8.0300e-01,  2.1219e-01,\n",
       "         -2.2803e-01,  1.5778e-01,  4.7922e-01,  1.1822e-02,  1.1536e-01,\n",
       "         -1.7192e-01, -2.0987e-01,  3.8861e-02, -3.7598e-01, -4.6906e-01,\n",
       "         -1.7233e-02, -6.3219e-01,  8.9974e-02,  8.7165e-02, -3.0405e-01,\n",
       "         -1.1033e-01, -3.9437e-02,  2.3838e-01, -5.7887e-01, -1.6629e-01,\n",
       "         -8.6021e-02,  1.1605e-01,  6.5737e-02, -3.6617e-01,  3.9360e-02,\n",
       "          2.1343e-01,  2.9082e-01,  3.1732e-01,  3.9626e-03, -4.3865e-01,\n",
       "          4.7228e-01, -2.0684e-01, -1.8949e-01, -1.3485e-01, -6.9648e-01,\n",
       "         -3.2860e-01, -1.9906e-01, -2.9988e-01, -3.6897e-01,  9.3578e-02,\n",
       "          5.3226e-02, -4.5714e-01,  1.9029e-01,  5.9163e-02,  1.2596e-01,\n",
       "          8.6981e-02,  2.1928e-01, -1.1265e-01,  1.2333e-01,  2.0604e-01,\n",
       "          2.3327e-01,  9.0705e-01, -3.2487e-01,  1.0718e-01, -7.8688e-01,\n",
       "          3.1005e-02,  5.8687e-02, -3.5977e-01, -4.0591e-01, -2.3799e-01,\n",
       "          6.1516e-02, -6.2525e-01, -3.2003e-03,  6.7397e-02,  2.2348e-01,\n",
       "         -2.5635e-01,  2.3368e-01,  1.5675e-01,  2.8867e-01, -6.0880e-01,\n",
       "         -4.0423e-01,  6.8448e-01,  1.6050e-01,  2.4080e-01, -2.9655e-01,\n",
       "          2.8045e-02,  4.4683e-01,  2.7140e-01,  1.5887e-01,  6.2583e-01,\n",
       "         -3.5118e-01, -2.8830e-01,  4.3831e-01,  9.5282e-01,  4.0192e-01,\n",
       "         -8.3439e-02,  2.0003e-01,  2.1715e-01, -1.9863e-01,  4.8988e-02,\n",
       "          1.2507e-01, -2.3198e-01,  4.0111e-01, -2.5551e-01,  6.2407e-01,\n",
       "         -4.3198e-01,  3.6823e-01,  6.9193e-01, -1.2633e-01, -2.3423e-01,\n",
       "          5.0362e-01,  7.3557e-02,  3.9479e-01,  4.9473e-01, -2.4783e-01,\n",
       "         -2.2398e-02,  1.2524e-01, -2.4125e-01,  1.3454e-01, -7.8082e-02,\n",
       "          2.8851e-01, -5.2783e-01, -5.1770e-01, -5.8220e-01, -5.8859e-01,\n",
       "         -2.0070e-01, -2.1855e-01,  4.9724e-01, -4.3717e-01,  3.2264e-01,\n",
       "         -2.6004e-01,  1.1693e-01,  5.5743e-01, -2.4343e-01, -3.7419e-01,\n",
       "         -3.2850e-01,  2.5576e-01, -1.5454e-02,  2.6546e-01, -1.1895e-01,\n",
       "         -1.1677e-01, -2.4200e-01, -1.5842e-01, -2.2251e-01, -2.8349e-01,\n",
       "          3.3945e-01, -1.4029e-01,  6.0654e-01,  2.4324e-02,  6.3590e-02,\n",
       "         -2.1753e-01, -1.7170e-03,  1.7548e-01,  3.8831e-01, -9.7240e-02,\n",
       "          1.8029e-01,  3.7479e-01, -4.5300e-02,  2.9895e-01, -6.5925e-01,\n",
       "          1.0455e-02, -1.4958e-01,  2.1529e-01, -5.8442e-05,  1.0553e-01,\n",
       "          2.1492e-01, -2.8749e-01,  3.9510e-01, -2.0190e-01,  5.0261e-02,\n",
       "          9.0918e-02,  3.6462e-01, -4.9022e-01,  5.2175e-02,  3.0765e-01,\n",
       "          1.7804e-01, -2.7831e-01, -4.5758e-01,  5.5298e-01,  3.4157e-01,\n",
       "         -1.5394e-01, -4.8369e-01, -3.5509e-02,  1.8635e-02, -1.0071e-01,\n",
       "         -2.3691e-01, -1.9762e-01, -5.4166e-01, -7.7294e-01, -3.3017e-02,\n",
       "         -1.9189e-01,  1.0460e-01,  4.1291e-01,  1.2986e-01, -1.0885e-01,\n",
       "         -2.9071e-01,  1.9839e-03,  1.6935e-01,  1.6014e-01, -3.2612e-01,\n",
       "          8.5878e-02,  1.3476e-01,  3.1478e-01, -1.1667e-01,  1.0898e-01,\n",
       "          2.3602e-01, -6.8857e-02,  1.1445e-02, -2.7020e-01, -6.0355e-02,\n",
       "         -1.7766e-02,  4.9195e-02, -3.7369e-02,  4.9962e-01, -6.5381e-01,\n",
       "         -8.7281e-02,  4.8862e-03,  3.0087e-01,  1.2047e-03, -2.7068e-01,\n",
       "         -4.0817e-01,  3.6086e-02, -3.2374e-01,  7.6674e-02,  7.7231e-01,\n",
       "         -2.5564e-02, -1.0848e-02,  4.2809e-01,  1.5373e-01,  7.2590e-01,\n",
       "          2.4639e-01, -3.1152e-01, -3.4577e-01, -1.4060e-01,  5.6165e-01,\n",
       "          8.2028e-02,  1.3528e-02, -2.2418e-01,  6.9752e-02, -1.9291e-03,\n",
       "         -3.6465e-02, -1.9783e-01, -3.2173e-01,  1.8078e-01,  1.1366e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(max_pool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 30, 256, 256])\n",
      "torch.Size([1, 16, 30, 256, 256])\n",
      "run layer1\n",
      "None before downsample! torch.Size([1, 16, 15, 128, 128])\n",
      "after layer1 torch.Size([1, 16, 15, 128, 128])\n",
      "Sequential(\n",
      "  (0): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 32, 8, 64, 64])\n",
      "downsample!\n",
      "torch.Size([1, 32, 8, 64, 64]) after downsample!\n",
      "after layer2 torch.Size([1, 32, 8, 64, 64])\n",
      "Sequential(\n",
      "  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 64, 4, 32, 32])\n",
      "downsample!\n",
      "torch.Size([1, 64, 4, 32, 32]) after downsample!\n",
      "after layer3 torch.Size([1, 64, 4, 32, 32])\n",
      "Sequential(\n",
      "  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "  (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") before downsample! torch.Size([1, 128, 2, 16, 16])\n",
      "downsample!\n",
      "torch.Size([1, 128, 2, 16, 16]) after downsample!\n",
      "after layer4 torch.Size([1, 128, 2, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8473e-01, -6.4907e-02,  3.6893e-01,  4.9671e-01, -1.7213e-01,\n",
       "         -8.3560e-02, -8.9248e-01,  3.1131e-03,  5.1055e-01, -1.7141e-01,\n",
       "          1.0346e-01, -2.1664e-01,  2.0339e-02,  5.1559e-01, -1.2824e-01,\n",
       "          1.0238e-01,  3.8309e-01,  2.3624e-01,  3.9423e-02, -1.5755e-01,\n",
       "         -4.7512e-01, -5.4473e-01,  7.7803e-01,  2.8489e-01,  2.3800e-01,\n",
       "          1.6333e-02,  5.0854e-01, -3.5838e-01,  1.0055e+00, -2.9444e-01,\n",
       "          1.2111e-02,  2.3859e-01,  2.3122e-02, -1.2002e-01, -2.4459e-01,\n",
       "         -5.3830e-02,  2.9056e-01,  5.6434e-01, -1.5123e-01, -1.9140e-01,\n",
       "          9.2377e-02,  1.6459e-01, -1.2438e-01, -4.5056e-01,  3.6325e-01,\n",
       "          6.3100e-01, -4.9532e-01, -5.2606e-02,  4.9902e-01, -3.2693e-01,\n",
       "          2.8288e-02,  1.5961e-01,  2.6201e-01, -2.0470e-01, -1.4474e-01,\n",
       "         -5.6026e-01, -2.4526e-01,  1.6048e-02, -5.3531e-02, -3.6940e-02,\n",
       "          4.5647e-01,  3.5501e-01,  1.0190e-01, -3.0264e-01,  1.9326e-01,\n",
       "          3.3790e-02, -4.2823e-01,  7.3737e-03, -3.2416e-01, -6.6852e-01,\n",
       "          6.7662e-02, -4.2480e-01, -4.2929e-01, -7.8695e-02,  2.1156e-01,\n",
       "         -2.3971e-01, -1.8924e-01, -9.0235e-02,  2.6370e-01,  2.2355e-01,\n",
       "         -7.8105e-02, -1.1997e-01, -1.8967e-01, -2.4920e-01,  1.3249e-01,\n",
       "          1.8910e-01, -2.8477e-01, -3.3842e-01, -3.3305e-01,  1.7673e-01,\n",
       "         -7.3452e-02,  3.3214e-01, -3.9124e-02,  1.2048e-02,  1.4186e-02,\n",
       "         -3.1104e-01, -1.0171e-01,  1.1293e-01, -1.5577e-01, -4.1911e-01,\n",
       "         -4.1659e-01, -2.2580e-01,  4.3289e-01, -2.1075e-01, -1.7715e-02,\n",
       "          2.9083e-01,  1.0776e-02, -6.0416e-02,  7.1925e-02,  1.8279e-01,\n",
       "          3.4944e-01, -1.3431e-01, -1.3532e-01, -1.5259e-01, -1.7503e-01,\n",
       "          5.0386e-01, -5.4044e-01, -1.9355e-03,  4.1924e-02, -1.2069e-01,\n",
       "          1.8319e-01, -5.0158e-01, -1.2822e-01, -3.5364e-02, -4.0314e-01,\n",
       "          2.3329e-01, -2.2739e-01,  2.1263e-01,  6.8754e-01,  1.5841e-01,\n",
       "          4.7235e-01, -2.1103e-02,  2.5748e-01,  4.8561e-01, -2.6024e-01,\n",
       "         -1.6295e-01,  2.7916e-02,  2.0631e-02, -3.1213e-02,  1.3445e-01,\n",
       "          6.4328e-01,  3.1639e-01,  1.2991e-01, -1.4498e-01, -8.3840e-02,\n",
       "          8.2510e-02, -8.2880e-01, -2.1794e-01, -1.2448e-01,  8.4018e-02,\n",
       "         -2.4685e-01,  2.5586e-01,  4.2492e-01,  1.1320e-01,  2.8593e-01,\n",
       "         -3.5913e-01, -1.5622e-02,  1.5446e-02, -4.0030e-01,  2.5802e-02,\n",
       "         -3.9404e-02, -2.6351e-01,  2.0579e-01,  3.0828e-01,  8.2510e-02,\n",
       "         -2.6940e-01, -3.3216e-01,  1.7014e-01, -4.0710e-01,  5.8400e-02,\n",
       "          1.2537e-01,  3.2926e-01, -5.5793e-01,  5.3965e-01,  6.6922e-02,\n",
       "         -6.6584e-02, -3.0997e-02, -6.3242e-02,  5.9209e-01,  7.0870e-02,\n",
       "          8.1789e-02,  1.6430e-01,  4.4153e-02,  8.0620e-01, -3.9153e-01,\n",
       "          5.4578e-01, -1.8931e-01, -7.9776e-02, -1.5103e-01,  3.4962e-01,\n",
       "         -1.7507e-01,  5.6969e-03, -4.0536e-01, -3.7728e-02,  9.9883e-02,\n",
       "          1.0017e-01, -6.3556e-01, -1.6209e-01, -4.1983e-01, -1.7816e-01,\n",
       "          3.5144e-01,  5.6201e-02, -5.2745e-01, -1.2779e-02, -3.0018e-01,\n",
       "          2.7310e-01,  2.1650e-01,  2.2391e-01, -6.2040e-01, -2.1623e-01,\n",
       "          4.2314e-02,  1.4585e-01, -5.5742e-02, -4.9104e-01,  2.3871e-01,\n",
       "         -6.2562e-02,  2.2859e-02, -2.5299e-01,  1.6508e-02,  3.9942e-01,\n",
       "          7.4326e-02, -6.4851e-01, -4.1065e-01,  4.5689e-01, -2.2315e-01,\n",
       "         -1.7020e-01, -2.2807e-01, -3.1135e-01,  3.8952e-01,  5.3310e-02,\n",
       "          4.9277e-02,  2.9843e-01,  5.0789e-01, -2.3416e-01,  6.5600e-02,\n",
       "         -3.7161e-01,  1.5137e-01,  4.0495e-01,  1.3729e-01, -5.8348e-02,\n",
       "         -1.0556e-01,  4.7963e-01,  4.1064e-02,  1.7960e-01, -4.1282e-01,\n",
       "         -5.2730e-01,  5.6157e-02,  2.5352e-01,  3.1646e-01,  1.3077e-01,\n",
       "          5.8031e-01, -4.4598e-03, -1.0118e-01, -6.7297e-01, -4.7788e-03,\n",
       "          5.3695e-01, -6.8945e-01, -3.0399e-01, -5.6757e-02, -3.9777e-01,\n",
       "         -5.8173e-02,  1.3979e-01,  6.2780e-01, -1.0799e-01, -3.4794e-01,\n",
       "         -3.1472e-02,  3.3484e-01,  9.2554e-02,  2.4947e-01,  2.3240e-01,\n",
       "          6.8071e-01,  1.2280e-01,  4.1237e-01, -2.0456e-01, -1.4374e-02,\n",
       "         -2.5450e-01,  1.3580e-01, -1.5481e-01,  4.2879e-01,  1.9927e-01,\n",
       "          3.1180e-01, -1.2959e-02,  2.9173e-02, -9.5489e-02, -7.5095e-02,\n",
       "         -2.1807e-01,  1.4299e-01,  2.1637e-01,  7.2032e-02,  2.8921e-01,\n",
       "          5.6894e-01, -5.8124e-01, -3.0216e-02, -6.7444e-02, -2.5124e-01,\n",
       "         -2.4778e-01,  1.6189e-01,  4.4867e-01, -3.3876e-01,  4.3046e-02,\n",
       "          1.6309e-03, -1.8850e-01, -6.2708e-01,  3.8121e-01,  2.8515e-01,\n",
       "         -2.6265e-01,  3.9763e-02, -1.5772e-01, -4.6464e-01,  2.8813e-01,\n",
       "         -7.8883e-02, -2.0828e-01, -1.6172e-02,  4.4360e-01, -8.7027e-01,\n",
       "         -4.8169e-01, -6.5440e-02, -2.3336e-01,  2.6989e-01,  3.7897e-01,\n",
       "         -3.9755e-02,  2.8859e-01,  4.6110e-01,  2.2022e-01,  2.7952e-01,\n",
       "          5.3382e-01,  3.5267e-01, -4.0980e-01,  1.1232e-01,  5.1704e-01,\n",
       "          2.8811e-01, -5.1446e-01,  8.5020e-02, -1.9109e-01, -8.8672e-02,\n",
       "          9.5780e-02, -6.8200e-01, -1.0235e-01, -7.6232e-02,  4.7902e-01,\n",
       "          1.0092e-01,  1.5107e-01, -3.5256e-01,  5.5187e-02, -6.0735e-02,\n",
       "         -1.8424e-01, -1.0590e-01,  1.4065e-02,  1.8467e-01, -1.3137e-02,\n",
       "         -2.9474e-01, -8.4064e-02,  1.1153e-01, -3.6255e-01, -1.1049e-01,\n",
       "         -3.7428e-01,  2.0035e-01,  1.6055e-01, -6.1259e-04,  1.9010e-01,\n",
       "         -2.0749e-01,  2.8720e-01, -7.2598e-02,  6.0092e-02,  1.6404e-01,\n",
       "         -1.7278e-01,  4.3867e-01, -4.1378e-01,  1.8000e-01,  3.3125e-01,\n",
       "          3.7836e-01,  3.9376e-01,  2.6009e-01, -2.9801e-01, -5.1752e-01,\n",
       "         -3.5079e-02,  6.6026e-02, -4.6790e-01,  2.4048e-01,  1.7892e-01,\n",
       "         -3.0844e-01, -4.6058e-01,  7.2960e-01,  1.4549e-01,  3.9256e-02,\n",
       "          1.4674e-01,  2.7300e-01,  1.4489e-01, -4.0832e-01,  3.5124e-01,\n",
       "          3.8364e-01,  2.2748e-02,  3.6296e-02,  2.3150e-01,  1.0801e-01,\n",
       "          9.1402e-02,  3.7475e-01,  1.7714e-01,  1.1083e-01, -8.7439e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(max_pool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv3d(1, 16, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionBlock(\n",
       "      (conv3d_3): Sequential(\n",
       "        (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv3d_1): Sequential(\n",
       "        (0): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=128, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([16, 1, 7, 7, 7])\n",
      "bn1.weight torch.Size([16])\n",
      "bn1.bias torch.Size([16])\n",
      "layer1.0.conv1.weight torch.Size([16, 16, 3, 3, 3])\n",
      "layer1.0.bn1.weight torch.Size([16])\n",
      "layer1.0.bn1.bias torch.Size([16])\n",
      "layer1.0.conv2.weight torch.Size([16, 16, 3, 3, 3])\n",
      "layer1.0.bn2.weight torch.Size([16])\n",
      "layer1.0.bn2.bias torch.Size([16])\n",
      "layer1.1.conv1.weight torch.Size([16, 16, 3, 3, 3])\n",
      "layer1.1.bn1.weight torch.Size([16])\n",
      "layer1.1.bn1.bias torch.Size([16])\n",
      "layer1.1.conv2.weight torch.Size([16, 16, 3, 3, 3])\n",
      "layer1.1.bn2.weight torch.Size([16])\n",
      "layer1.1.bn2.bias torch.Size([16])\n",
      "layer2.0.conv1.weight torch.Size([32, 16, 3, 3, 3])\n",
      "layer2.0.bn1.weight torch.Size([32])\n",
      "layer2.0.bn1.bias torch.Size([32])\n",
      "layer2.0.conv2.weight torch.Size([32, 32, 3, 3, 3])\n",
      "layer2.0.bn2.weight torch.Size([32])\n",
      "layer2.0.bn2.bias torch.Size([32])\n",
      "layer2.0.downsample.0.weight torch.Size([32, 16, 1, 1, 1])\n",
      "layer2.0.downsample.0.bias torch.Size([32])\n",
      "layer2.0.downsample.1.weight torch.Size([32])\n",
      "layer2.0.downsample.1.bias torch.Size([32])\n",
      "layer2.1.conv1.weight torch.Size([32, 32, 3, 3, 3])\n",
      "layer2.1.bn1.weight torch.Size([32])\n",
      "layer2.1.bn1.bias torch.Size([32])\n",
      "layer2.1.conv2.weight torch.Size([32, 32, 3, 3, 3])\n",
      "layer2.1.bn2.weight torch.Size([32])\n",
      "layer2.1.bn2.bias torch.Size([32])\n",
      "layer3.0.conv1.weight torch.Size([64, 32, 3, 3, 3])\n",
      "layer3.0.bn1.weight torch.Size([64])\n",
      "layer3.0.bn1.bias torch.Size([64])\n",
      "layer3.0.conv2.weight torch.Size([64, 64, 3, 3, 3])\n",
      "layer3.0.bn2.weight torch.Size([64])\n",
      "layer3.0.bn2.bias torch.Size([64])\n",
      "layer3.0.downsample.0.weight torch.Size([64, 32, 1, 1, 1])\n",
      "layer3.0.downsample.0.bias torch.Size([64])\n",
      "layer3.0.downsample.1.weight torch.Size([64])\n",
      "layer3.0.downsample.1.bias torch.Size([64])\n",
      "layer3.1.conv1.weight torch.Size([64, 64, 3, 3, 3])\n",
      "layer3.1.bn1.weight torch.Size([64])\n",
      "layer3.1.bn1.bias torch.Size([64])\n",
      "layer3.1.conv2.weight torch.Size([64, 64, 3, 3, 3])\n",
      "layer3.1.bn2.weight torch.Size([64])\n",
      "layer3.1.bn2.bias torch.Size([64])\n",
      "layer4.0.conv1.weight torch.Size([128, 64, 3, 3, 3])\n",
      "layer4.0.bn1.weight torch.Size([128])\n",
      "layer4.0.bn1.bias torch.Size([128])\n",
      "layer4.0.conv2.weight torch.Size([128, 128, 3, 3, 3])\n",
      "layer4.0.bn2.weight torch.Size([128])\n",
      "layer4.0.bn2.bias torch.Size([128])\n",
      "layer4.0.downsample.0.weight torch.Size([128, 64, 1, 1, 1])\n",
      "layer4.0.downsample.0.bias torch.Size([128])\n",
      "layer4.0.downsample.1.weight torch.Size([128])\n",
      "layer4.0.downsample.1.bias torch.Size([128])\n",
      "layer4.1.gama torch.Size([1])\n",
      "layer4.1.conv3d_3.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "layer4.1.conv3d_3.0.bias torch.Size([128])\n",
      "layer4.1.conv3d_3.1.weight torch.Size([128])\n",
      "layer4.1.conv3d_3.1.bias torch.Size([128])\n",
      "layer4.1.conv3d_1.0.weight torch.Size([128, 128, 1, 1, 1])\n",
      "layer4.1.conv3d_1.0.bias torch.Size([128])\n",
      "layer4.1.conv3d_1.1.weight torch.Size([128])\n",
      "layer4.1.conv3d_1.1.bias torch.Size([128])\n",
      "layer4.2.conv1.weight torch.Size([128, 128, 3, 3, 3])\n",
      "layer4.2.bn1.weight torch.Size([128])\n",
      "layer4.2.bn1.bias torch.Size([128])\n",
      "layer4.2.conv2.weight torch.Size([128, 128, 3, 3, 3])\n",
      "layer4.2.bn2.weight torch.Size([128])\n",
      "layer4.2.bn2.bias torch.Size([128])\n",
      "layer4.3.gama torch.Size([1])\n",
      "layer4.3.conv3d_3.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "layer4.3.conv3d_3.0.bias torch.Size([128])\n",
      "layer4.3.conv3d_3.1.weight torch.Size([128])\n",
      "layer4.3.conv3d_3.1.bias torch.Size([128])\n",
      "layer4.3.conv3d_1.0.weight torch.Size([128, 128, 1, 1, 1])\n",
      "layer4.3.conv3d_1.0.bias torch.Size([128])\n",
      "layer4.3.conv3d_1.1.weight torch.Size([128])\n",
      "layer4.3.conv3d_1.1.bias torch.Size([128])\n",
      "fc.weight torch.Size([400, 128])\n",
      "fc.bias torch.Size([400])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CILM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
